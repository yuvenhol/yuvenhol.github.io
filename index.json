[
  {
    "content": "@Configuration+@Bean\n@Configuration public class AppConfig{ @Bean public JDBCTempalte t1(){ } @Bean public TranslationManager transactionManager(){ } @Bean public DataSource dataSource(){ xxx } } @Bean 修饰方法后，方法名作为beanname 加入叫spring容器 被Configuration修饰以后，该对象将变成代理对象，在获取bean修饰的方法时，如果spring容器有bean则会直接返回，没有会执行并生成bean\n",
    "description": "",
    "tags": null,
    "title": "@Configuration",
    "uri": "/spring/configuration/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "arthas",
    "uri": "/%E5%B7%A5%E5%85%B7/arthas/"
  },
  {
    "content": "操作字节码生成代理类\nClass UserServiceProxy extends UserService{ public void test(){ //切面逻辑 super.test() } //切面逻辑 }\n",
    "description": "",
    "tags": null,
    "title": "cglib",
    "uri": "/java/cglib/"
  },
  {
    "content": "领域驱动设计 概念 DP：抽象并封装自检和一些隐性的计算逻辑，属性都是无状态的。 Entity:封装单对象有状态的逻辑。（程序需要追踪其状态的变化） DomainService:封装多对象的有状态逻辑。 Repository:抽象封装外部数据访问逻辑。 UL：统一语言，意识拉齐\n流程： 1.首先对需要处理的业务问题进行总览。 2.然后领域对象(Entity)进行划分，明确每个领域对象的包含的信息和职责边界。 并进行跨对象，多对象的逻辑组织(Domain Service) 3.接着在上层应用中根据业务描述去编排Entity和Domain Service。 4.最后再做一些下水道工作，去对下层的数据访问，RPC调用去做一些具体实现。\nDP/VO DP(Domain Primitive) 定义：在DDD里，DP是一切模型、方法、结构的基础。 它是特定领域、拥有精准定义、可以自我验证、拥有行为的对象。可以认为是领域内最小的组成部分。\nDP的三条原则： 让隐性的概念显性化（手机号的运营商） 让隐性的上下文显性化（手机号的区号编码） 封装多对象行为\n",
    "description": "",
    "tags": null,
    "title": "DDD Domain-Driven Design",
    "uri": "/%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/ddd-domain-driven-design/"
  },
  {
    "content": "简介 docker compose用于更加方便的管理docker容器，采用yml文件配置的方式代替，敲入docker命令，配置时更加清晰，也更适合多个节点配置。\nhub.docker.com\n配置文件编写 docker compose 详解\n",
    "description": "",
    "tags": null,
    "title": "docker compose",
    "uri": "/dockerk8s/docker-compose/"
  },
  {
    "content": "统计字符出现个数 =LEN(G13)-LEN(SUBSTITUTE(G13,\"、\",\"\"))+1\n",
    "description": "",
    "tags": null,
    "title": "excel公式",
    "uri": "/office/excel%E5%85%AC%E5%BC%8F/"
  },
  {
    "content": "开启GC日志 打开gc日志：-XX:+PrintGCDetails 指定输入位置：-Xloggc:$LOGS_DIR/gc.log\n分析日志 GC (Allocation Failure)造成的young gc。\ngc日志头 解释 GC (Allocation Failure) Allocation Failure表示向young generation(eden)给新对象申请空间，但是young generation(eden)剩余的合适空间不够所需的大小导致的minor gc。 Full GC (Ergonomics) 默认使用 UseParallelGC 垃圾回收器，该垃圾回收器默认启动了 AdaptiveSizePolicy。 ",
    "description": "",
    "tags": null,
    "title": "gc日志分析",
    "uri": "/java/jvm/gc%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90/"
  },
  {
    "content": "命令 branch -m 重命名 git branch -m 原始名称 新名称\nrebase 把一个分支整合到另一个分支的办法有两种：merge（合并） 和 rebase（衍合）。 rebase相当于在fetch之后，重新提交数据。 千万不要在在public分支操作rebase，例如develop，不要用rebase合并自己的feature分支。 有一篇很好的文章讲merge和rebase https://www.atlassian.com/git/tutorials/merging-vs-rebasing#the-golden-rule-of-rebasing\ngit工作流程 git flow 配置 ignore #：注视 folder 同名的 folder 目录、src/folder 文件、src/utils/folder 文件都会被忽略，即：不会被提交到远程仓库中。 folder/ 只忽略文件夹 ! 表示取反，不忽略xxx 通配符 星号“*” ：匹配多个字符； 双星号“**” ：匹配多个字符； 问号“?”：匹配除 ‘/’外的任意一个字符； 方括号“[xxxx]”：匹配多个列表中的字符； ",
    "description": "",
    "tags": null,
    "title": "git",
    "uri": "/%E5%B7%A5%E5%85%B7/git/"
  },
  {
    "content": "Cookie \u0026 Session cookie的属性 HttpOnly: 如果您在cookie中设置了HttpOnly属性，那么通过js脚本将无法读取到cookie信息，这样能有效的防止XSS攻击 path：对应url的作用域，默认是当前路径 ex：/a/b 默认是/a max-age：指定的是从文档被访问后的存活时间，这个时间是个相对值(比如:3600s),相对的是文档第一次被请求时服务器记录的Request_time(请求时间) Expires：指定的时间可以是相对文件的最后访问时间(Atime)或者修改时间(MTime),而max-age相对对的是文档的请求时间(Atime)\n删除cookie 把cookie的过期时间设为0或者过去\n",
    "description": "",
    "tags": null,
    "title": "HTTP",
    "uri": "/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/http/"
  },
  {
    "content": "linux IO TCP网络通信整体流程 服务端准备连接流程 SOCKET函数 为了执行网络I/O，我们要做的第一件事情就是调用socket函数，指定期望的协议类型。该函数会创建一个通信的端点，并返回引用该端点的文件描述符，该文件描述符也称为套接字描述符(socket descriptor)，简称sockfd。\nBIND()函数 bind()函数把一个本地协议地址赋予一个套接字。\n如果一个TCP客户端或者服务器没有调用bind绑定端口，或者指定IP地址，那么内核就会为该套接字选择一个临时端口号。\nLISTEN()函数 通过socket()函数创建了套接字之后，再执行listen()函数，会把套接字转换为一个被动套接字，指示内核应该接收指向该套接字的连接请求，并导致套接字从CLOSED状态转换到LISTEN状态。\n在客户端请求服务器之后，服务器内核会把请求套接字放入到未完成队列中： 如下图：\n服务器接收到客户端SYN请求后，于是请求套接字进入未完成连接队列，等到服务端响应了ACK和SYN完成三次握手后，于是，套接字进入已完成连接队列。已完成连接队列中的套接字可以被服务器进程执行accept函数获取到。\nACCEPT()函数 服务器一旦执行了socket()、bind()、listen()函数之后，就表示已经初始化好了监听套接字，并且把自己变为了被动套接字，等待客户端的请求。这个时候，我们需要继续调用accept()函数，让服务器进入阻塞等待获取客户端的已连接套接字。\n当进程调用accept()时，已完成连接队列中的队头将返回给进程，或者如果队列为空，那么进程将被投入睡眠，直到TCP在该队列中放入一项才唤醒它。\n在调用accept()之后，阻塞等待客户连接到达，然后获取一个已连接套接字：\n关于监听套接字和已连接套接字\n注意，这里要区分好服务端的监听套接字和已连接套接字，服务端调用socket()返回的是监听套接字，bind()和listen()函数入参也是监听套接字。\n一旦有客户端请求过来了于是产生了一个已连接套接字，后续和客户端的交互是通过这个已连接套接字进行的。监听套接字只负责监听客户端请求并获取和客户端的已连接套接字。\n客户端发起连接流程 CONNECT()函数 connect()函数由客户端调用，请求与服务端建立连接，这个函数会触发三次握手。大致流程如下：\n客户端： connect调用是的当前套接字从CLOSED状态进入SYN_SENT状态，如果节而受到了服务器的SYN+ACK响应，则转移到ESTABLISHED状态； 如果connect失败，则表示套接字不在可用，必须关闭，不能再次尝试调用connect函数； 服务端： 每当接收到SYN时，TCP在未完成连接队列中创建一个新的条目，然后响应TCP三次握手的第二个分节； 每当收到三次握手的第三个分节的时候，就把条目从未完成队列移到已完成连接队列的队尾。此时，服务端accept调用将被唤醒并得到一个已连接套接字。 注意：客户在调用connect函数之前，不是一定要调用bind函数，这个时候内核会确定源IP地址，并选择一个临时端口号作为源端口号。\n所以大家在监控TCP连接的时候，可以发现请求客户端的端口都是没有什么规律的。因为这个端口号是临时端口号。\n当服务器队列满了，有新的客户端connect请求的SYN到达时怎么办？\n这个时候，TCP会忽略这个SYN分节，也不会向客户端发送RST，好让客户TCP有机会重发SYN，以便在不久之后可以在这些队列中找到可用的空间。\n如果直接响应RST，客户的connect()调用会立刻返回错误，导致应用进程必须要处理这种情况。\n因为从服务端的角度来看，经理一个RTT之后，TCP条目就会从未完成队列移动到已完成连接队列。所以，未完成连接队列中的任何一项的存留时间是一个RTT。\n一旦connect()成功之后，客户端和服务器就可以通过数据交换相关函数进行数据交换了。\n整体流程 概念说明 1. 内核态（内核空间）和用户态（用户空间）的区别和联系？ 用户空间是用户进程所在的内存区域，系统空间是操作系统所在的内存区域。 为了保证内核的安全，处于用户态的程序只能访问用户空间，而处于内核态的程序可以访问用户空间和内核空间。 2. 文件描述符fd Linux将所有设备都当做文件来处理，文件描述符来标识每个文件对象。 当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。 3. 缓存IO Linux的缓存IO机制中，操作系统会将IO的数据缓存在文件系统的页缓存中，也就是说，数据会先被拷贝到操作系统内核的缓冲区，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。\n涉及系统调用 recvfrom： 从socket读取数据\nselect： select() allow a program to monitor multiple file descriptors, waiting until one or more of the file descriptors become “ready” for some class of I/O operation select 监控多个io操作的文件描述符，直到一个或者多个文件描述符编程ready状态\npoll： 与select类似，链表实现的，没有上限限制\nepoll： epoll就是event poll ，基于事件驱动 主要用到三个函数调用： epoll_create：创建epoll对象 epoll_ctl：把文件描述符交给epoll对象监控 epoll_wait: waits for I/O events, blocking the calling thread if no events are currently available.\nIO模型 一般而言，一个输入操作，一般会经历如下处理过程：等待数据准备好，从内核复制到进程。这里的数据复制，一般是应用进程调用了某个IO方法之后，陷入系统调用，在内核态完成的。\nlinux系统产生了下面五种网络模式的方案：\n阻塞式I/O模型 如上图，在应用进程调用 recvfrom()之后，陷入内核态，直到数据报到达并且复制到应用进程缓冲区之后才返回到用户态。\n或者在系统调用期间发生错误，也会立刻返回。\n这种I/O称为阻塞I/O。\n非阻塞式I/O模型 如上图，当我们把套接字设置为非阻塞模式的时候，内核会这样处理I/O操作：当请求的I/O操作非得把本进程投入睡眠才能完成时，就不要投入睡眠，而是返回一个错误，在上面的例子中，调用recvfrom()之后，因为数据没有准备好，所以内核直接返回一个EWOULDBLOCK错误，直到数据准备好了，才复制数据到进程空间，并返回系统调用继续处理进程逻辑。\n而应用进程会不断循环调用recvfrom()函数，这种处理方式我们称为polling(轮训)，持续到轮训内核，查看数据是否准备好。这种方式的缺点是会消耗大量的CPU时间。\n注意：当recvfrom发起系统调用发现数据准备好了，将数据从内核复制到用户空间的时候，应用进程还是会被阻塞，只不过不会阻塞在等待数据准备好这个流程，从而减少了阻塞时间。\n这种轮训对于单进程或者单线程的程序特别有用。\nI/O复用模型 I/O复用(I/O multiplexing)，指的是通过一个支持同时感知多个描述符的函数系统调用，阻塞在这个系统调用上，等待某一个或者几个描述符准备就绪，就返回可读条件。常见的如select，poll，epoll系统调用可以实现此类功能功能。这种模型不用阻塞在真正的I/O系统调用上。\n工作原理如下图所示：\n如上图，这种模型与非阻塞式I/O相比，把轮训判断数据是否准备好的处理方式替换为了通过select()系统调用的方式来实现。\n**select()是实现I/O多路复用的经典系统调用函数。**select()可以同时等待多个套接字的变为可读，只要有任意一个套接字可读，那么就会立刻返回，处理已经准备好的套接字了。\n在多线中使用阻塞I/O，即每个文件描述符一个线程，与I/O复用模型很类似，每个线程可以自由调用阻塞式I/O系统调用。\n信号驱动式I/O模型 所谓信号驱动式I/O(signal-driven I/O)，就是指在描述符准备就绪的时候，让内核发送一个SIGIO信号通知应用进程进行后续的数据读取等处理。工作原理如下图所示：\n注册了SIGIO信号处理函数，开启了信号驱动式IO之后，就可以继续执行程序了，等到数据报准备好之后，内核会发送一个SIGIO信号给应用进程，然后应用进程在信号处理函数中调用recvfrom读取数据报。\n这种模型在内核等待数据报达到期间进程不会被阻塞，可以继续执行。\n异步I/O模型 可以发现，上面所有的I/O模型都会在某一个执行点阻塞，并不是真正的异步的。接下来我们就介绍下真正的异步I/O模型(asynchronous I/O)。如下图：\n通过异步处理函数如aio_read告知内核启动某个动作，并且让内核在整个操作完成之后再通知应用进程，内核会在把数据复制到用户空间缓冲区之后再进行通知。整个IO过程应用进程都不会被阻塞。\n五种I/O模型对比 下面我们通过一个表格来总结下这五种I/O模型 下面是执行流程的对比图：\n可以很清晰的看到各种I/O模型的不同表现。\n",
    "description": "",
    "tags": null,
    "title": "IO相关",
    "uri": "/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/io%E7%9B%B8%E5%85%B3/"
  },
  {
    "content": "redis 命令行客户端 https://gitee.com/mirrors/iredis#using-dsn\n",
    "description": "",
    "tags": null,
    "title": "iredis",
    "uri": "/%E5%B7%A5%E5%85%B7/iredis/"
  },
  {
    "content": "日志发展史 上古时代 jdk1.3之前 System.out.println(\"\") 问题： 没有日志级别，上线以后会有很多无关的日志，而且只能在控制台看，不方便定位。\n发展流程 log4j-\u003ejul-\u003ejcl-\u003eslf4j-\u003elog4j2-\u003elogback\nlog4j 作者ceki\n从控制台写到文件 日志信息按天和文件大小划分 划分日志等级，按日志等级记录文件 高等级日志发送邮件 异步io 格式控制\nlog4j发布以后，活的很好的反响，作者想让sun公司被纳入jdk，sun公司不接受，最后被apatch收纳。\njul jdk官方日志库 jul （java.util.logging） log4j火了以后，jdk官方自己开发了一个库jul，但是并没有被所有人 认可\nJCL 日志门面 jakarta（jdk内部的一个开发小组）Commons Logging jcl不实现日志功能，但是整合整合日志库\n依靠类加载器寻找日志库\nslf4j ceki发现JCL不好用，apache也不着急开发日志门面，自己出去单独搞了slf4j\n桥接器：slf4j 和日志框架直接 连接的工具 适配器：多个模块使用不同的日志门面和日志框架，可以别的日志框架转换到slf4j上\nlog4j2 apache 重写log4j，性能升级\nlogback ceki 也知道log4j性能问题，开发了替代log4j的高性能产品\n",
    "description": "",
    "tags": null,
    "title": "java日志",
    "uri": "/%E6%9D%82%E9%A1%B9/java%E6%97%A5%E5%BF%97/"
  },
  {
    "content": "强引用(FinalReference)： 普通引用 JVM停止运行时终止 软引用(SoftReference)： 在类似于浏览器访问页面缓存的场景，比如点击回退，如果缓存了页面就直接展示，缓存被清除了再加载也没事。 内存不足时终止 弱引用(WeakReference)： gc运行后终止 ThreadLocalMap的key，为了减少内存泄漏，在对象只有虚引用的时候，gc了就被清除了。 虚引用(PhantomReference)： 任何时候都可能\n",
    "description": "",
    "tags": null,
    "title": "java的引用类型",
    "uri": "/java/java%E7%9A%84%E5%BC%95%E7%94%A8%E7%B1%BB%E5%9E%8B/"
  },
  {
    "content": "查看程序中对象数量 jmap -histo pid |head -20\n",
    "description": "",
    "tags": null,
    "title": "jvm内存分析：",
    "uri": "/java/jvm/jvm%E5%86%85%E5%AD%98%E5%88%86%E6%9E%90/"
  },
  {
    "content": "![][https://note.youdao.com/yws/public/resource/e5863162eca29c2b31e8b59c9707817d/xmlnote/317C13052E514DA9B6229368DD48EDB5/105252]\nKafka核心总控制器Controller 在Kafka集群中会有一个或者多个broker，其中有一个broker会被选举为控制器(Kafka Controller)，它负责管理整个 集群中所有分区和副本的状态。\n当某个分区的leader副本出现故障时，由控制器负责为该分区选举新的leader副本。 当检测到某个分区的ISR集合发生变化时，由控制器负责通知所有broker更新其元数据信息。 当使用kafka-topics.sh脚本为某个topic增加分区数量时，同样还是由控制器负责让新分区被其他节点感知到。 Controller选举机制 在kafka集群启动的时候，会自动选举一台broker作为controller来管理整个集群，选举的过程是集群中每个broker都会 尝试在zookeeper上创建一个 /controller 临时节点，zookeeper会保证有且仅有一个broker能创建成功，这个broker就会成为集群的总控器controller。\n当这个controller角色的broker宕机了，此时zookeeper临时节点会消失，集群里其他broker会一直订阅这个临时节点，发现临时节点消失了，就竞争再次创建临时节点，就是我们上面说的选举机制，zookeeper又会保证有一个broker 成为新的controller。\n具备控制器身份的broker需要比其他普通的broker多一份职责，具体细节如下:\n监听broker相关的变化。为Zookeeper中的/brokers/ids/节点添加BrokerChangeListener，用来处理broker 增减的变化。\n监听topic相关的变化。为Zookeeper中的/brokers/topics节点添加TopicChangeListener，用来处理topic增减 的变化;为Zookeeper中的/admin/delete_topics节点添加TopicDeletionListener，用来处理删除topic的动作。\n从Zookeeper中读取获取当前所有与topic、partition以及broker有关的信息并进行相应的管理。对于所有topic 所对应的Zookeeper中的/brokers/topics/topic节点添加PartitionModificationsListener，用来监听topic中的 分区分配变化。\n更新集群的元数据信息，同步到其他普通的broker节点中。\nPartition副本选举Leader机制 controller感知到分区leader所在的broker挂了(controller监听了很多zk节点可以感知到broker存活)，controller会从 ISR列表(参数unclean.leader.election.enable=false的前提下)里挑第一个broker作为leader(第一个broker最先放进ISR 列表，可能是同步数据最多的副本)，如果参数unclean.leader.election.enable为true，代表在ISR列表里所有副本都挂 了的时候可以在ISR列表以外的副本中选leader，这种设置，可以提高可用性，但是选出的新leader有可能数据少很多。 副本进入ISR列表有两个条件:\n副本节点不能产生分区，必须能与zookeeper保持会话以及跟leader副本网络连通 副本能复制leader上的所有写操作，并且不能落后太多。(与leader副本同步滞后的副本，是由 replica.lag.time.max.ms 配置决定的，超过这个时间都没有跟leader同步过的一次的副本会被移出ISR列表) 消费者消费消息的offset记录机制 每个consumer会定期将自己消费分区的offset提交给kafka内部topic:__consumer_offsets，提交过去的时候，key是 consumerGroupId+topic+分区号，value就是当前offset的值，kafka会定期清理topic里的消息，最后就保留最新的 那条数据\n因为__consumer_offsets可能会接收高并发的请求，kafka默认给其分配50个分区(可以通过 offsets.topic.num.partitions设置)，这样可以通过加机器的方式抗大并发。\n消费者Rebalance机制 rebalance就是说如果消费组里的消费者数量有变化或消费的分区数有变化，kafka会重新分配消费者消费分区的关系。 比如consumer group中某个消费者挂了，此时会自动把分配给他的分区交给其他的消费者，如果他又重启了，那么又会 把一些分区重新交还给他。 注意:rebalance只针对subscribe这种不指定分区消费的情况，如果通过assign这种消费方式指定了分区，kafka不会进 行rebanlance。\n如下情况可能会触发消费者rebalance\n消费组里的consumer增加或减少了 2. 动态给topic增加了分区 消费组订阅了更多的topic rebalance过程中，消费者无法从kafka消费消息，这对kafka的TPS会有影响，如果kafka集群内节点较多，比如数百 个，那重平衡可能会耗时极多，所以应尽量避免在系统高峰期的重平衡发生。\nkafka在redis中存的内容 ",
    "description": "",
    "tags": null,
    "title": "kafka",
    "uri": "/%E4%B8%AD%E9%97%B4%E4%BB%B6/kafka/"
  },
  {
    "content": "LDAP是轻量目录访问协议,英文全称是Lightweight Directory Access Protocol,一般都简称为LDAP.\n现在市场上有关LDAP的产品已有很多,各大软件公司都在他们的产品中集成了LDAP服务,如Microsoft的ActiveDirectory、Lotus的Domino Directory、IBM的WebSphere中也集成了LDAP服务.LDAP的开源实现是OpenLDAP,它比商业产品一点也不差,而且源码开放.\nOpenLDAP是最常用的目录服务之一,它是一个由开源社区及志愿者开发和管理的一个开源项目,提供了目录服务的所有功能,包括目录搜索、身份认证、安全通道、过滤器等等.大多数的Linux发行版里面都带有OpenLDAP的安装包.OpenLDAP服务默认使用非加密的TCP/IP协议来接收服务的请求,并将查询结果传回到客户端.由于大多数目录服务都是用于系统的安全认证部分比如:用户登录和身份验证,所以它也支持使用基于 SSL/TLS 的加密协议来保证数据传送的保密性和完整性.OpenLDAP是使用OpenSSL来实现SSL/TLS加密通信的.\nLDAP的信息模型是建立在”条目”(entries)的基础上.一个条目是一些属性的集合,并且具有一个全局唯一的”可区分名称”DN,一个条目可以通过DN来引用.每一个条目的属性具有一个类型和一个或者多个值.类型通常是容易记忆的名称,比如”cn”是通用名称(common name),或者”mail”是电子邮件地址.条目的值的语法取决于属性类型.比如,cn属性可能具有一个值”Babs Jensen” .一个mail属性可能包含”bbs@example.com” .一个jpegphoto属性可能包含一幅JPEG(二进制)格式的图片.\nLDAP常用关键字列表 LDAP通过属性objectClass来控制哪一个属性必须出现或允许出现在一个条目中,它的值决定了该条目必须遵守的模式规则.\nEntry 条目,也叫记录项,是LDAP中最基本的颗粒,就像字典中的词条,或者是数据库中的记录.通常对LDAP的添加、删除、更改、检索都是以条目为基本对象的.\ndn:每一个条目都有一个唯一的标识名(distinguished Name,DN),如上述中一个 dn:”uid=mac,ou=People,dc=example,dc=cn”.通过DN的层次型语法结构,可以方便地表示出条目在LDAP树中的位置,通常用于检索. rdn:一般指dn逗号最左边的部分,如cn=baby.它与RootDN不同,RootDN通常与RootPW同时出现,特指管理LDAP中信息的最高权限用户. Base DN:LDAP目录树的最顶部就是根,也就是所谓的“Base DN”,如”dc=example,dc=com”. schema 对象类(ObjectClass)、属性类型(AttributeType)、语法(Syntax)分别约定了条目、属性、值,他们之间的关系如下图所示.所以这些构成了模式(Schema)——对象类的集合.条目数据在导入时通常需要接受模式检查,它确保了目录中所有的条目数据结构都是一致的.\nschema(一般在/etc/ldap/schema/目录)在导入时要注意前后顺序.\n对于LDAP目录中保存的信息,可以使用LDIF(LDAP Interchange Format)格式来保存.这是一种标准文本文件格式,使用这种格式保存得的LDAP服务器数据库中的数据可方便读取和修改,这也是其他大多数服务配置文件所采取的格式.\nAttribute 属性(Attribute)类似于程序设计中的变量,可以被赋值.在OpenLDAP中声明了许多常用的Attribute(用户也可自己定义Attribute).\n每个条目都可以有很多属性(Attribute),比如常见的人都有姓名、地址、电话等属性.每个属性都有名称及对应的值,属性值可以有单个、多个,比如你有多个邮箱.\n属性不是随便定义的,需要符合一定的规则,而这个规则可以通过schema制定.比如,如果一个entry没有包含在 inetorgperson 这个 schema 中的objectClass: inetOrgPerson,那么就不能为它指定employeeNumber属性,因为employeeNumber是在inetOrgPerson中定义的.\nLDAP为人员组织机构中常见的对象都设计了属性(比如commonName,surname).下面有一些常用的别名:\n属性\n别名\n语法\n描述\n值（举例）\ncommonName\ncn\nDirectory String\n姓名\nsean\nsurname\nsn\nDirectory String\n姓\nChow\norganizationalUnitName\nou\nDirectory String\n单位（部门）名称\nIT\norganization\no\nDirectory String\n组织（公司）名称\nexample\ntelephoneNumber\nTelephone Number\n电话号码\n110\nobjectClass\n内置熟悉\ntop\n常见的Attribute含义如下:\nc:国家. cn:common name,指一个对象的名字.如果指人,需要使用其全名. dc:domain Component,常用来指一个域名的一部分. givenName:指一个人的名字,不能用来指姓. l:指一个地名,如一个城市或者其他地理区域的名字. mail:电子信箱地址. o:organizationName,指一个组织的名字. ou:organizationalUnitName,指一个组织单元的名字. sn:surname,指一个人的姓. telephoneNumber:电话号码,应该带有所在的国家的代码. uid:userid,通常指某个用户的登录名,与Linux系统中用户的uid不同. 作者：华阳_3bcf\n链接：https://www.jianshu.com/p/3716b84c4c1d\n来源：简书\n著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。\nhttps://zhuanlan.zhihu.com/p/74512921\n在 LDAP 里， 一切都是等级化的，或者称之为层级化（hiearchical）。\n一棵树有树干，树枝和树叶；树叶长在树枝上，树枝依附于树干。这就是一个简单的层级结构。LDAP 的结构同一棵树类似。假设 LDAP 里存储的是公司的信息，那么可以把公司（company）本身理解为树干，公司里面的各个部门，比如组（group），理解为树干，把用户（user）理解为树叶。这样的结构称之为目录信息树（DIrectory Information Tree，DIT）。\n",
    "description": "",
    "tags": null,
    "title": "ldap-轻量目录访问协议",
    "uri": "/%E6%9D%83%E9%99%90%E6%8E%A7%E5%88%B6/ldap-%E8%BD%BB%E9%87%8F%E7%9B%AE%E5%BD%95%E8%AE%BF%E9%97%AE%E5%8D%8F%E8%AE%AE/"
  },
  {
    "content": "top 定义：display sorted information about processes ![[截屏2022-01-02 下午10.58.24.png]]\nload avg: 系统处于可运行状态和不可中断状态的平均活跃进程数。在多核CPU下，如果负载数大于逻辑cpu数量，代表有进程处于等待状态。\niotop 磁盘情况查看 lsof lsof - list open files 在linux下一切皆文件，一个网络连接也是一个文件。 lsof -i 查看网络连接的文件 在mac系统下netstat是简化版的，用lsof 替代\nnetstat netstat -an\nexport 环境变量相关操作 Linux export 命令用于设置或显示环境变量。\n在 shell 中执行程序时，shell 会提供一组环境变量。export 可新增，修改或删除环境变量，供后续执行的程序使用。export 的效力仅限于该次登陆操作，如果在配置文件中添加可以持续有效。 export [-fnp][变量名称]=[变量设置值]\n-f 代表[变量名称]中为函数名称。 -n 删除指定的变量。变量实际上并未删除，只是不会输出到后续指令的执行环境中。 -p 列出所有的shell赋予程序的环境变量。 例子 在.zprofile 里面 export WS=/Users/yuwenhao/Programs/work-space\ntouch 修改文件的创建和修改时间，现在常用于创建一个文件。\nfind find path -name “支持 * ？” [-delete]\nalias alias[别名]=[指令名称] 删除unlias 别名\nln ln -s 软连接 ln 硬连接，软连接更常用，不存在文件时也可以创建软连接，类似于快捷方式。硬连接是指向一个文件实体的指针，文件夹不创建硬连接，不同文件系统或者硬件不能创建硬连接，硬连接可以多人共享文件，防止误删。\n",
    "description": "",
    "tags": null,
    "title": "linux命令",
    "uri": "/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux%E5%91%BD%E4%BB%A4/"
  },
  {
    "content": " 目录 解释 /bin bin 是 Binaries (二进制文件) 的缩写, 这个目录存放着最经常使用的命令。 /sbin s 就是 Super User 的意思，是 Superuser Binaries (超级用户的二进制文件) 的缩写，这里存放的是系统管理员使用的系统管理程序。 /etc 存放系统管理和配置文件 /opt 额外安装的可选应用程序包所放置的位置。 /proc 虚拟文件系统目录，是系统内存的映射，可以查看正在运行程序的状态。 /boot 这里存放的是启动 Linux 时使用的一些核心文件，包括一些连接文件以及镜像文件。 /root 该目录为系统管理员，也称作超级权限者的用户主目录。 /dev dev 是 Device(设备) 的缩写, 该目录下存放的是 Linux 的外部设备，在 Linux 中访问设备的方式和访问文件的方式是相同的。 /lost+found 这个目录平时是空的，系统非正常关机而留下“无家可归”的文件（windows下叫什么.chk）就在这里 /var 用于存放运行时需要改变数据的文件，也是某些大文件的溢出区 /tmp 用于存放各种临时文件，是公用的临时文件存储点。 /mnt 临时挂载别的文件系统的，我们可以将光驱挂载在/mnt/上，然后进入该目录就可以查看光驱里的内容了。 /media linux 系统会自动识别一些设备，例如U盘、光驱等等，当识别后，Linux 会把识别的设备挂载到这个目录下。 /home 存放所有用户文件的根目录，是用户主目录的基点 /usr 用于存放系统应用程序，比较重要的目录。这是最庞大的目录，要用到的应用程序和文件几乎都在这个目录。 /usr/local 本地系统管理员软件安装目录（安装系统级的应用） /usr/doc linux文档 /usr/man 帮助文档 /usr/lib 常用的动态链接库和软件包的配置文件 /usr/sbin 超级用户的一些管理程序 /usr/include linux下开发和编译应用程序所需要的头文件 /usr/src 源代码，linux内核的源代码就放在/usr/src/linux里 usr/local/bin 本地增加的命令 /usr/local/lib 本地增加的库 ",
    "description": "",
    "tags": null,
    "title": "linux目录",
    "uri": "/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux%E7%9B%AE%E5%BD%95/"
  },
  {
    "content": "这次的史诗级漏洞是怎么回事呢？ 主角就是log4j2，黑客已经利用 Log4j 漏洞来接管受害者的计算机，以执行从加密货币挖矿、发送垃圾邮件、到通过大型僵尸网络发起分布式拒绝服务(DDoS)攻击的任何事情。\nlog4j2的强大之处在于，除了可以输出程序中的变量，它还提供了一个叫Lookup的东西，lookup相当于是一个接口，可以用来输出更多内容，lookup，顾名思义就是查找、搜索的意思，那在log4j2中，就是允许在输出日志的时候，通过某种方式去查找要输出的内容。\n假如某一个Java程序中，将浏览器的类型记录到了日志中：\nlogger.info(userAgent); User-Agent就属于外界输入的信息，而不是自己程序里定义出来的。只要是外界输入的，就有可能存在恶意的内容，假如有人发来了一个HTTP请求，他的User-Agent是这样一个字符串：\n${jndi:ldap://127.0.0.1/exploit}\n接下来，log4j2将会对这行要输出的字符串进行解析，它发现了字符串中有 ${，要单独处理，发现是JNDI扩展内容_（什么是JNDI？简单粗暴的理解下，它的作用类似于JDBC，JDBC（Java Data Base Connectivity,java数据库连接）是一种用于执行SQL语句的Java API，可以为多种关系数据库提供统一访问，JDBC为工具/数据库开发人员提供了一个标准的API，据此可以构建更高级的工具和接口，使数据库开发人员能够用纯 Java API 编写数据库应用程序。JNDI(Java Naming and Directory Interface)是一个应用程序设计的API，为开发人员提供了查找和访问各种命名和目录服务的通用、统一的接口，类似JDBC都是构建在抽象层上。）如图：_\n再对JNDI进一步解析，发现了是LDAP协议_（LDAP即Lightweight Directory Access Protocol（轻量级目录访问协议），目录是一个为查询、浏览和搜索而优化的专业分布式数据库，这个东西用在统一身份认证领域比较多，**简单理解就是：**一个类似于字典的数据源，你可以通过LDAP协议，传一个name进去，就能获取到数据。）_LDAP服务器在127.0.0.1，要查找的key是exploit，然后调用具体负责LDAP的模块去请求对应的数据。问题来了！JNDI支持一个叫命名引用的方式，也就是JNDI可以远程下载class文件来构建对象！！！下载后加载起来构建对象，咱就是一整个震惊住的那么一个大动作啊，如果远程下载的URL指向的是一个黑客的服务器，并且下载的class文件里面藏有恶意代码，那歇逼了，什么样的后果都可能出现，这是JNDI注入。\n这次“核弹”漏洞造成的影响 log4j2的使用面很广泛，现在Java技术栈在Web、后端开发、大数据等领域应用非常广泛，国内除了阿里巴巴、京东、美团等一大片以Java为主要技术栈的公司外，还有多如牛毛的中小企业选择Java。除此之外还有像kafka、elasticsearch、flink这样的大量中间件都是用Java语言开发的。它们大量使用了log4j2作为日志输出。如果输出的日志有外部输入混进来，那直接就是远程代码执行RCE，灭顶之灾！好吧这些是大佬们的遭遇和分析，至少目前为止对很多人，至少我这种菜鸟没有产生什么大的影响…\n有关解决和修复 方式一：禁用lookup或JNDI服务\n罪魁祸首就是lookup和JNDI，那么直接修改配置文件log4j2.formatMsgNoLookups=True或禁用JNDI服务，不过一般产生问题的服务都是线上已经在跑的服务，禁用的时候要注意评估一下是否允许。\n方式二：升级新版本\n新版的log4j2已经修复了这个问题，升级即可解决。修复后的log4j2在JNDI lookup中增加了很多的限制：\n1.默认不再支持二次跳转（也就是命名引用）的方式获取对象\n2.只有在log4j2.allowedLdapClasses列表中指定的class才能获取。\n3.只有远程地址是本地地址或者在log4j2.allowedLdapHosts列表中指定的地址才能获取\n这样处理等于是去掉了通过打印日志去远程加载class的方式。\n",
    "description": "",
    "tags": null,
    "title": "log4j漏洞",
    "uri": "/%E6%9D%82%E9%A1%B9/log4j%E6%BC%8F%E6%B4%9E/"
  },
  {
    "content": "功能 编译、打包、测试、依赖管理\n###POM介绍 pom basics\n\u003cproject xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\"\u003e \u003c!-- maven 模型版本--\u003e \u003cmodelVersion\u003e4.0.0\u003c/modelVersion\u003e \u003c!-- 分组编号一般是公司域名--\u003e \u003cgroupId\u003eorg.codehaus.mojo\u003c/groupId\u003e \u003c!-- 分组编号一般是项目名--\u003e \u003cartifactId\u003emy-project\u003c/artifactId\u003e \u003cversion\u003e1.0\u003c/version\u003e \u003c/project\u003e maven 约定大于配置 好处：\n省去配置 规范开发规范 文件规范 java 源文件：src/main/java 测试用例目录：src/test/java 输出文件： target/ 配置文件： src/main/resources/\npackage: package同时会执行compile\ntest Test开头的类名和test开头的方法名才会被执行 如果引入junit 包，上一条就失效\n",
    "description": "",
    "tags": null,
    "title": "maven",
    "uri": "/%E5%B7%A5%E5%85%B7/maven/"
  },
  {
    "content": "META-INFO ",
    "description": "",
    "tags": null,
    "title": "META-INF和WEB-INFO",
    "uri": "/java/meta-inf%E5%92%8Cweb-info/"
  },
  {
    "content": "mysql 逻辑框架图 ",
    "description": "",
    "tags": null,
    "title": "mysql",
    "uri": "/%E4%B8%AD%E9%97%B4%E4%BB%B6/mysql/"
  },
  {
    "content": "官网命令介绍 https://redis.io/commands/\n数据结构 字符串 常用命令： SET GET MSET（json的key） MGET SETNX（分布式锁） INCR（原子操作） INCRYBY （批量） GET\nhash结构 Hash常用操作 HSET key field value //存储一个哈希表key的键值 HSETNX key field value //存储一个不存在的哈希表key的键值 HMSET key field value [field value …] //在一个哈希表key中存储多个键值对 HGET key field //获取哈希表key对应的field键值 HMGET key field [field …] //批量获取哈希表key中多个field键值 HDEL key field [field …] //删除哈希表key中的field键值 HLEN key //返回哈希表key中field的数量 HGETALL key //返回哈希表key中所有的键值 HINCRBY key field increment //为哈希表key中field键的值加上增量increment\n相比较String 优点 同类数据归类整合储存，方便数据管理 相比string操作消耗内存与cpu更小 相比string储存更节省空间 缺点 过期功能不能使用在field上，只能用在key上 Redis集群架构下不适合大规模使用。大key容易造成数据分布不均匀 List结构 队列结构，最大2^32-1个元素，主要用于头尾添加访问元素。 LPUSH RPUSH LPOP RPOP LRANGE 返回获取 BLPOP Block LPOP，会阻塞 BRPOP\n应用 stack=LPUSH+LPOP queue=LPUSH+RPOP blocking queue=LPUSH+BRPOP\nSET结构 基础命令 SADD SREM 删除元素 SMEMBERS 查看全部元素 SRANDMEMBER key count 随机从key中抽取count个元素 SPOP 随机从key中抽取count个元素，并排除 pop·· SISMEMBER 是否包含 SCARD获取总数\n集合命令 SINTER 求交集 SUNION 并集 SDIFF 查集（第一个集合，在后续集合中不存在的元素）\n应用 抽奖 关注模型\n共同关注的人 SINTER 我关注的人也关注了他 SISMEMBER 可能喜欢 SDIFF ZSET 有序集合 常用操作： ZADD key score ZRANGE key start stop 排序 ZREVRANGE 倒序 ZUNIONSTORE 并集并放入一个key\n应用： 排行榜\nredis注意事项 redis最应该避免大key，不要一个key里面存太多数据。\n常见面试问题 Redis的单线程和高性能 Redis是单线程吗? Redis 的单线程主要是指 Redis 的网络 IO 和键值对读写是由一个线程来完成的，这也是 Redis 对外 提供键值存储服务的主要流程。但 Redis 的其他功能，比如持久化、异步删除、集群数据同步等，其实是由额外的线程执行的。\nRedis 单线程为什么还能这么快? 因为它所有的数据都在内存中，所有的运算都是内存级别的运算，而且单线程避免了多线程的切换性 能损耗问题。正因为 Redis 是单线程，所以要小心使用 Redis 指令，对于那些耗时的指令(比如 keys)，一定要谨慎使用，一不小心就可能会导致 Redis 卡顿。\nRedis 单线程如何处理那么多的并发客户端连接? Redis的IO多路复用:redis利用epoll来实现IO多路复用，将连接信息和事件放到队列中，依次放到 文件事件分派器，事件分派器将事件分发给事件处理器。 redis 一个命令过来大体分四步 1、建立连接 2、读取数据 3、执行命令 4、应答 连接建立优化先入队列，数据接收完成以后，传给事件处理器，不过需要注意命令的执行仍然会按照入队的顺序执行，只不过优化减少了IO时间。\n",
    "description": "",
    "tags": null,
    "title": "redis",
    "uri": "/%E4%B8%AD%E9%97%B4%E4%BB%B6/redis/"
  },
  {
    "content": "bash有几种不同的运行模式，login shell与non-login shell,.interactive shell.与non-interactive shell(比如执行shel脚本)。这两种 分类方法是交叉的，也就是说一个login shell7可能是一个interactive shell,也可能是个non-interactive shell。. 在下列情况下，我们可以获得一个login shell: 1.登录系统时获得的J顶层shell,无论是通过本地终端登录，还是通过网络ssh登录。这种情况下获得的login shell是一个交互式shell。. 2.在终端下使用-login选项调用bash,可以获得一个交互式login shell。. 3.在脚本中使用-login选项调用bash(比如在shell脚本第一行做如下指定：#！/bin/bash–login),此时得到一个非交互式的login shell。 4.使用\"su-“切换到指定用户时，获得此用户的login shell。如果不使用”.\"，则获得non-login shell。 login shell与non-login shell的主要区别在于它们启动时会读取不同的配置文件，从而导致环境不一样。 login shell的行为： login shell,启动时首先读取/etc/profile:全局配置，然后依次查找~/.bash_profile、~/.bash_login、~/.profile三个配置文件，并且 读取第一个找到的并且可读的文件。login shell退出时读取并执行~/.bash_logout中的命令。 non-login shell的行为： 交互式的non-login shell)启动时读取~.bashrc资源文件。非交互式的non–login shell不读取上述所有配置文件，而是查找环境变量 BASH ENV,读取并执行BASH ENV指向的文件中的命令。 如果使用命令\"sh\"调用bash,bash会尽可能保持向后兼容。作为login shellF启动时，bash依次读取/etc/profile和~l.profile配置文件。作为 non-login shell/启动时，bash读取环境变量ENV指向的文件。 通常我们要定制一些配置时，将配置写在.bashrc中，然后在/.bash_profile中读取~/.bashrc,这样可以保证login shell和交互式non-login shell得到相同的配置。至于/etc/profile就不要轻易去改啦，毕竟会影响系统全局的配置。\n",
    "description": "",
    "tags": null,
    "title": "shell 的login shell与non-login shell",
    "uri": "/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/shell-%E7%9A%84login-shell%E4%B8%8Enon-login-shell/"
  },
  {
    "content": "几篇还不错的文章： SLF4J和Logback和Log4j和Logging的区别与联系\njava日志体系\n",
    "description": "",
    "tags": null,
    "title": "slf4j",
    "uri": "/%E6%9D%82%E9%A1%B9/slf4j/"
  },
  {
    "content": "Sentinel 是什么 Sentinel 是面向分布式、多语言异构化服务架构的流量治理组件，主要以流量为切入点，从流量路由、流量控制、流量整形、熔断降级、系统自适应过载保护、热点流量防护等多个维度来帮助开发者保障微服务的稳定性。\nSentinel 的坑 dashboard 没有持久化，需要自己改造\n",
    "description": "",
    "tags": null,
    "title": "snetinel",
    "uri": "/%E5%BE%AE%E6%9C%8D%E5%8A%A1/snetinel/"
  },
  {
    "content": "spring mvc原理\n",
    "description": "",
    "tags": null,
    "title": "spring mvc",
    "uri": "/spring/spring-mvc/"
  },
  {
    "content": "为啥是去中心化的： 阿帕网当初设计的时候为了防止苏联人攻击损坏一个节点，其他节点不可用，所以做成了去中心化的。 IEEE和ISO\nOSI 七层模型是ISO提供的，都是学者相对学术 IEEE是 五工程师协会提出的，更加实际可实现\nIP地址和MAC地址的区别\nIP地址可以变动、mac地址是不变的，相同子网内寻址使用MAC地址，不同网络使用IP地址\nSYN(synchronous建立联机) ACK(acknowledgement 确认) PSH(push传送) FIN(finish结束) RST(reset重置) URG(urgent紧急)\nSequence number(顺序号码)\n",
    "description": "",
    "tags": null,
    "title": "TCP IP协议",
    "uri": "/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/tcp-ip%E5%8D%8F%E8%AE%AE/"
  },
  {
    "content": "栈上分配 为什么需要栈上分配\n在我们的应用程序中，其实有很多的对象的作用域都不会逃逸出方法外，也就是说该对象的生命周期会随着方法的调用开始而开始，方法的调用结束而结束，对于这种对象，是不是该考虑将对象不在分配在堆空间中呢？ 我们通过JVM内存分配可以知道JAVA中的对象都是在堆上进行分配，当对象没有被引用的时候，需要依靠GC进行回收内存，如果对象数量较多的时候，会给GC带来较大压力，也间接影响了应用的性能。\n什么是栈上分配\n所以,栈上分配是JVM提出的一种调优方案,JVM通过逃逸分析确定该对象不会被外部访问,如果不会逃逸可以将该对象在栈上分配内存，每个方法或者说每个线程都有属于自己独立的栈帧,随着方法的调用结束,这样该对象所占用的内存空间就可以随栈帧出栈而销毁，就减轻了垃圾回收的压力。\n对象逃逸分析：就是分析对象动态作用域，当一个对象在方法中被定义后，它可能被外部方法所引用，例如作为调用参数传递到其他地方中。\n分析如下案例:\npublic User test1(){ User user = new User(); user.setId(1); user.setName(“1”); return user; }\npublic void test2(){ User user = new User(); user.setId(1); user.setName(“1”);\n//保存数据库 //userMapper.save(user); } 很显然test1方法中的user对象被返回了，这个对象的作用域范围不确定，test2方法中的user对象我们可以确定当方法结束这个对象就可以认为是无效对象了，对于这样的对象我们其实可以将其分配在栈内存里，让其在方法结束时跟随栈内存一起被回收掉。\nJVM对于这种情况可以通过开启逃逸分析参数(-XX:+DoEscapeAnalysis)来优化对象内存分配位置，使其通过标量替换优先分配在栈上(栈上分配)，JDK7之后默认开启逃逸分析，如果要关闭使用参数(-XX:-DoEscapeAnalysis)\n标量替换：通过逃逸分析确定该对象不会被外部访问，并且对象可以被进一步分解时，JVM不会创建该对象，而是将该对象成员变量分解若干个被这个方法使用的成员变量所代替，这些代替的成员变量在栈帧或寄存器上分配空间，这样就不会因为没有一大块连续空间导致对象内存不够分配。开启标量替换参数(-XX:+EliminateAllocations)，JDK7之后默认开启。\n栈上分配的优点:\n1.可以在方法调用结束后自行销毁对象,无需垃圾回收器的介入,有效减小JVM的GC压力 2.栈上分配速度很快,有效提高程序性能\n栈上分配的缺点:\n1.栈的空间是有限的,栈空间存放不了大对象,遇到大对象的创建则还是会存放在堆空间中\nTLAB 可能很多人会有疑惑，已经提供了栈上分配，为什么还要有什么TLAB，甚至混淆了两者之间的差别，包括我自己，之前也存在很多疑惑，下面为大家揭开原因 全名: 本地线程分配缓冲(Thread Local Allocation Buffer,TLAB)，这是一个线程专用的内存分配区域。\n为什么需要TLAB\n在线程初始化时，同时也会申请一块指定大小的内存，只给当前线程使用，这样每个线程都单独拥有一个空间，如果需要分配内存，就在自己的空间上分配，这样就不存在竞争的情况，可以大大提升分配效率。\n如何开启TLAB\nJVM默认开启了TLAB功能，也可以使用-XX: +UseTLAB 显示开启\n如何观察TLAB使用情况\nJVM提供了-XX:+PrintTLAB 参数打开跟踪TLAB的使用情况\n如何调整TLAB默认大小 -XX:TLABSize 通过该参数指定分配给每一个线程的TLAB空间的大小\n简单理解\n为了避免多线程情况下抢占空间,每个线程会提前在EDEN区中,额外划分一块内存区域,指定对象直接进入区域使用, jdk8默认开启\nTLAB的缺点:\n1.TLAB空间一般不会很大(占用了Eden区),所以大对象也无法在TLAB上进行分配,遇到大对象最终也只能分配到堆空间中\n如下图:对象分配流程图\n最后栈上分配和TLAB的对比\n名称\t针对点\t处于对象分配流程的位置 栈上分配\t减少GC的负担\t1 TLAB\t加速堆上对象分配速度\t2\n",
    "description": "",
    "tags": null,
    "title": "TLAB \u0026 栈上分配",
    "uri": "/java/jvm/tlab-%E6%A0%88%E4%B8%8A%E5%88%86%E9%85%8D/"
  },
  {
    "content": "zookeeper 什么是zookeeper 它是一个分布式协调框架，是Apache Hadoop 的一个子项目，它主要是用来解决分布式应用中经常遇到的一些数据管理问题，如:统一命名服务、状态同 步服务、集群管理、分布式应用配置项的管理等。\n核心概念 简单的理解Zookeeper 是一个用于存储少量数据的基于内存 的数据库，主要有如下两个核心的概念:\n文件系统数据结构 监听通知机制。 文件系统数据结构 Zookeeper维护一个类似文件系统的数据结构: 每个子目录项都被称作为 znode(目录节点)，和文件系统类似，我们能够自由的增加、删除 znode，在一个znode下增加、删除子znode。\n有四种类型的znode:\nPERSISTENT­持久化目录节点 客户端与zookeeper断开连接后，该节点依旧存在，只要不手动删除该节点，他将永远存在\nPERSISTENT_SEQUENTIAL­持久化顺序编号目录节点 客户端与zookeeper断开连接后，该节点依旧存在，只是Zookeeper给该节点名称进行顺序编号\nEPHEMERAL­临时目录节点 客户端与zookeeper断开连接后，该节点被删除(和sessionId绑定的，session断开或者超时会被删除)\nEPHEMERAL_SEQUENTIAL­临时顺序编号目录节点 客户端与zookeeper断开连接后，该节点被删除，只是Zookeeper给该节点名称进行顺序编号\nContainer 节点(3.5.3 版本新增，如果Container节点下面没有子节点，则Container节点 在未来会被Zookeeper自动清除,定时任务默认60s 检查一次)\nTTL 节点( Time To Live 默认禁用，只能通过系统配置 zookeeper.extendedTypesEnabled=true 开启，不稳定)\n监听通知机制 客户端注册监听它关心的任意节点，或者目录节点及递归子目录节点\n如果注册的是对某个节点的监听，则当这个节点被删除，或者被修改时，对应的客户端将被通知 如果注册的是对某个目录的监听，则当这个目录有子节点被创建，或者有子节点被删除，对应的客户端将被通知 如果注册的是对某个目录的递归子节点进行监听，则当这个目录下面的任意子节点有目录结构 的变化(有子节点被创建，或被删除)或者根节点有数据变化时，对应的客户端将被通知。 get -w /xxx 监听只会监听当前节点，子节点修改不会被监听 注意:所有的通知都是一次性的，及无论是对节点还是对目录进行的监听，一旦触发，对应的监 听即被移除。递归子节点，监听是对所有子节点的，所以，每个子节点下面的事件同样只会被触发一次。\n应用场景 分布式配置中心 分布式注册中心 分布式锁 分布式队列 集群选举 分布式屏障 发布/订阅 节点元数据 可以通过stat命令，或者get -s cZxid:创建znode的事务ID(Zxid的值)。 mZxid:最后修改znode的事务ID。 pZxid:最后添加或删除子节点的事务ID(子节点列表发生变化才会发生改变)。 ctime:znode创建时间。 mtime:znode最近修改时间。\ndataVersion:znode的当前数据版本。 cversion:znode的子节点结果集版本(一个节点的子节点增加、删除都会影响这个版本）。 aclVersion：znode的acl版本 ephemeralOwner:znode是临时znode时，表示znode所有者的 session ID。 如果 znode不是临时znode，则该字段设置为零。 dataLength:znode数据字段的长度。 numChildren:znode的子znode的数量。\nACL 权限控制( Access Control List ) Zookeeper 的ACL 权限控制,可以控制节点的读写操作,保证数据的安全性，Zookeeper ACL 权 限设置分为 3 部分组成，分别是:权限模式(Scheme)、授权对象(ID)、权限信息 (Permission)。最终组成一条例如“scheme:id:permission”格式的 ACL 请求信息。\nScheme(权限模式):用来设置 ZooKeeper 服务器进行权限验证的方式。ZooKeeper 的权限 验证方式大体分为两种类型:\n一种是范围验证。所谓的范围验证就是说 ZooKeeper 可以针对一个 IP 或者一段 IP 地址授予某 种权限。比如我们可以让一个 IP 地址为“ip:192.168.0.110”的机器对服务器上的某个数据节 点具有写入的权限。或者也可以通过“ip:192.168.0.1/24”给一段 IP 地址的机器赋权。\n另一种权限模式就是口令验证，也可以理解为用户名密码的方式。在 ZooKeeper 中这种验证方 式是 Digest 认证，而 Digest 这种认证方式首先在客户端传送“username:password”这种形 式的权限表示符后，ZooKeeper 服务端会对密码 部分使用 SHA-1 和 BASE64 算法进行加密， 以保证安全性。\n还有一种Super权限模式, Super可以认为是一种特殊的 Digest 认证。具有 Super 权限的客户端 可以对 ZooKeeper 上的任意数据节点进行任意操作。\n授权对象(ID)\n授权对象就是说我们要把权限赋予谁，而对应于 4 种不同的权限模式来说，如果我们选择采用 IP 方式，使用的授权对象可以是一个 IP 地址或 IP 地址段;而如果使用 Digest 或 Super 方式，则 对应于一个用户名。如果是 World 模式，是授权系统中所有的用户。\n权限信息(Permission)\n权限就是指我们可以在数据节点上执行的操作种类，如下所示:在 ZooKeeper 中已经定义好的 权限有 5 种:\n数据节点(c: create)创建权限，授予权限的对象可以在数据节点下创建子节点; 数据节点(w: wirte)更新权限，授予权限的对象可以更新该数据节点;\n数据节点(r: read)读取权限，授予权限的对象可以读取该节点的内容以及子节点的列表信息; 数据节点(d: delete)删除权限，授予权限的对象可以删除该数据节点的子节点; 数据节点(a: admin)管理者权限，授予权限的对象可以对该数据节点体进行 ACL 权限设置。\n命令:\ngetAcl:获取某个节点的acl权限信息\nsetAcl:设置某个节点的acl权限信息\naddauth: 输入认证授权信息，相当于注册用户信息，注册时输入明文密码，zk将以密文的形式存 储\n可以通过系统参数zookeeper.skipACL=yes进行配置，默认是no,可以配置为true, 则配置过的 ACL将不再进行权限检测 ex： setAcl /test auth:yuvenhol:pwd:rwcd create /test xxdataxx ip:192.168.109.130:rw\n数据结构 //DataNode 是Zookeeper存储节点数据的最小单位 public class DataNode implements Record{ byte data[]; Long acl; public StatPersisted stat; private Set\u003cString\u003e children = null; } // public class DataTree{ private final ConcurrentHashMap\u003cString, DataNode\u003e nodes = new ConcurrentHashMap\u003cString, DataNode\u003e(); private final WatchManager dataWatches = new WatchManager(); private final WatchManager childWatches = new WatchManager(); } 事务日志\u0026数据快照 格式化后效果 事务日志： 针对每一次客户端的事务操作，Zookeeper都会将他们记录到事务日志中，当然，Zookeeper也 会将数据变更应用到内存数据库中。我们可以在zookeeper的主配置文件zoo.cfg 中配置内存中 的数据持久化目录，也就是事务日志的存储路径 dataLogDir. 如果没有配置dataLogDir(非必 填), 事务日志将存储到dataDir (必填项)目录 数据快照： 用于记录Zookeeper服务器上某一时刻的全量数据，并将其写入到指定的磁盘文件中。 可以通过配置snapCount配置每间隔事务请求个数，生成快照，数据存储在dataDir 指定的目录中\n事务日志文件名为: log.\u003c当时最大事务ID\u003e，应为日志文件时顺序写入的，所以这个最大事务 ID也将是整个事务日志文件中，最小的事务ID，日志满了即进行下一次事务日志文件的创建\n快照事务日志文件名为: snapshot.\u003c当时最大事务ID\u003e，日志满了即进行下一次事务日志文件的 创建\n",
    "description": "",
    "tags": null,
    "title": "zookeeper",
    "uri": "/%E5%BE%AE%E6%9C%8D%E5%8A%A1/zookeeper/"
  },
  {
    "content": "中间件是为应用提供通用服务和功能的软件。数据管理、应用服务、消息传递、身份验证和 API 管理通常都要通过中间件。\n中间件可以帮助开发人员更有效地构建应用。它就如同是应用、数据与用户之间的纽带。\n对于具有多云和容器化环境的企业而言，中间件可以助您大规模、经济高效地开发和运行应用。 一般而言中间件和框架的区别是，中间件是独立运行的用于处理某项专门业务的CS程序，会有配套的客户端和服务端，框架虽然也是处理某个专门业务的但是它不是独立程序，是寄宿在宿主程序进程内的一套类库。 作者：阿里巴巴淘系技术\n链接：https://www.zhihu.com/question/19730582/answer/1663627873\n来源：知乎\n著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。\n常用基础中间件 路由与web服务器：处理和转发其他服务器通信数据的服务器。 如被业界广泛使用的阿里基于 Nginx 研发的 Tengine、阿里内部的集中式路由服务 VipServer\nRPC框架：微服务时代的远程服务调用框架。如grpc, Thrift, 阿里的 HSF, Dubbo, SOFA-RPC\n消息中间件：支持在分布式系统之间发送和接收消息的软件。 如 Apache kafka, Apache RabbitMQ, NSQ, 阿里孵化开源的 Apache RocketMQ\n缓存服务: 分布式的高速数据存储层，一般是内存存储。如 阿里 Tair，业界的 Redis, Memcached, Ehcache\n配置中心：用来统一管理各个项目中所有配置的系统。如 阿里 Nacos、携程 Apollo、百度 Disconf\n分布式事务：事务的参与者、支持事务的服务器、资源服务器以及事务管理器分别位于不同的分布式系统的不同节点之上。 如 阿里 seata、腾讯 DTF\n任务调度：分布式环境下提供定时、任务编排、分布式跑批等功能的系统。如 阿里 SchedulerX、业界 xxl-job、当当 elastic-job、有赞 TSP\n数据库层 用于支持弹性扩容和分库分表的 TDDL，数据库连接池 Driud, Binlog 同步的 Canal 等。\n",
    "description": "",
    "tags": null,
    "title": "中间件的定义",
    "uri": "/%E4%B8%AD%E9%97%B4%E4%BB%B6/%E4%B8%AD%E9%97%B4%E4%BB%B6%E7%9A%84%E5%AE%9A%E4%B9%89/"
  },
  {
    "content": "逻辑划分：\nHot spot 实现\n虚拟机栈：\n每个方法被执行事会生成一个栈桢（Stack Frame）用于存储局部变量表，操作数栈、动态链接、方法出口等\n本地方法栈：\n与虚拟机栈功能相似，服务于native方法。Hot-spot把本地方法栈与虚拟机栈合二为一。\n堆：\n对象存储的地方，有些对象存储在栈上，依靠内存逃逸。\n方法区：\n存放类的信息，常量、静态变量、及时编译后的代码缓存。\n运行时常量池：\nJava程序要运行时，需要编译器先将源代码文件编译成字节码（.class)文件，然后在由JVM解释执行。\nclass文件中除了有类的版本、字段、方法、接口等描述信息外,还有一项信息是常量池(Constant pool table)，用于存放编译期生成的各种字面量和符号引用，这部分内容将在类加载后进入运行时常量池中存放。\n静态常量池就是上面说的class文件中的常量池。class常量池是在编译时每个class文件中都存在。不同的符号信息放置在不同标志的常量表中。\n",
    "description": "",
    "tags": null,
    "title": "内存结构",
    "uri": "/java/%E5%86%85%E5%AD%98%E7%BB%93%E6%9E%84/"
  },
  {
    "content": " title: “链表反转” date: 2021-08-08T21:42:40+08:00 draft: false 链表反转 链表\n1-\u003e2-\u003e3-\u003e4\n翻转\n4-\u003e3-\u003e2-\u003e1\n主要难点是防止Next被替换，下一个节点无法访问\n方式1： 使用临时变量保存Last和Next\n/** * Definition for singly-linked list. * type ListNode struct { * Val int * Next *ListNode * } */ func reverseList(head *ListNode) *ListNode { var lastNode,nextNode *ListNode for(head!=nil){ nextNode=head.Next head.Next=lastNode lastNode=head head=nextNode } //注意这里是返回前一个节点，因为head最后指向了nextNode是空的 return lastNode } 方式2：递归 从最末尾开始递归交换 3-4-\u003e4-3，1，2，(4，3)-\u003e1,(4,3),2\n",
    "description": "",
    "tags": null,
    "title": "双向链表",
    "uri": "/%E7%AE%97%E6%B3%95/%E5%8F%8C%E5%90%91%E9%93%BE%E8%A1%A8/"
  },
  {
    "content": "0day漏洞： 漏洞已被发现还没有发布解决补丁。\n桥接： 简单的说就是通过网桥可以把两个不同的物理局域网连接起来，是一种在链路层实现局域网互连的存储转发设备。网桥从一个局域网接收MAC帧，拆封、校对、校验之后 ，按另一个局域网的格式重新组装,发往它的物理层，通俗的说就是通过一台设备（可能不止一个）把几个网络串起来形成的连接，比如图中就是一种通过桥接来实现无路由双机上网的连接方案。 虚拟机中的网络模式 VMware 桥接模式 VMware桥接模式，也就是将虚拟机的虚拟网络适配器与主机的物理网络适配器进行交接，虚拟机中的虚拟网络适配器可通过主机中的物理网络适配器直接访问到外部网络(例如图中所示的局域网和Internet，下同)。简而言之，这就好像在上图所示的局域网中添加了一台新的、独立的计算机一样。因此，虚拟机也会占用局域网中的一个IP地址，并且可以和其他终端进行相互访问。桥接模式网络连接支持有线和无线主机网络适配器。如果你想把虚拟机当做一台完全独立的计算机看待，并且允许它和其他终端一样的进行网络通信，那么桥接模式通常是虚拟机访问网络的最简单途径。\nVMware NAT模式 NAT，是Network Address Translation的缩写，意即网络地址转换。NAT模式也是VMware创建虚拟机的默认网络连接模式。使用NAT模式网络连接时，VMware会在主机上建立单独的专用网络，用以在主机和虚拟机之间相互通信。虚拟机向外部网络发送的请求数据\"包裹\"，都会交由NAT网络适配器加上\"特殊标记\"并以主机的名义转发出去，外部网络返回的响应数据\"包裹\"，也是先由主机接收，然后交由NAT网络适配器根据\"特殊标记\"进行识别并转发给对应的虚拟机，因此，虚拟机在外部网络中不必具有自己的IP地址。从外部网络来看，虚拟机和主机在共享一个IP地址，默认情况下，外部网络终端也无法访问到虚拟机。\n",
    "description": "",
    "tags": null,
    "title": "奇怪的小知识",
    "uri": "/%E6%9D%82%E9%A1%B9/%E5%A5%87%E6%80%AA%E7%9A%84%E5%B0%8F%E7%9F%A5%E8%AF%86/"
  },
  {
    "content": "在线流程图 https://mermaid.live/\n正则可视化 https://tooltt.com/regulex/\npython官方学习文档 docs.python.org\n",
    "description": "",
    "tags": null,
    "title": "好用的网站",
    "uri": "/%E6%9D%82%E9%A1%B9/%E5%A5%BD%E7%94%A8%E7%9A%84%E7%BD%91%E7%AB%99/"
  },
  {
    "content": "\n",
    "description": "",
    "tags": null,
    "title": "微信授权登录",
    "uri": "/%E6%9D%82%E9%A1%B9/%E5%BE%AE%E4%BF%A1%E6%8E%88%E6%9D%83%E7%99%BB%E5%BD%95/"
  },
  {
    "content": "https://www.yuque.com/books/share/227872c0-1f19-4c83-960e-5e13e39343c8/fi6mb2\n为了防止出现内存地址碰撞，操作系统引入了虚拟内存，进程持有的虚拟地址会通过 CPU 芯片中的内存管理单元（MMU）的映射关系，来转换变成物理地址，然后再通过物理地址访问内存。\n互斥与同步： 互斥：不能同时执行 同步：要求按照顺序执行\n系统调用： http://c.biancheng.net/view/1195.html\n",
    "description": "",
    "tags": null,
    "title": "操作系统",
    "uri": "/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"
  },
  {
    "content": "Z\nRequestContextListener\nRequestContextListener监听器用于监听http请求，每当web应用接收到Http请求，该监听器就会调用初始化方法，将该请求保存在当前线程的ThreadLocalMap容器中。\nAbstractAnnotationConfigDispatcherServletInitializer 初始化器 会\n",
    "description": "",
    "tags": null,
    "title": "未命名",
    "uri": "/spring/mvc/%E6%9C%AA%E5%91%BD%E5%90%8D/"
  },
  {
    "content": "个人信息 于文浩/男/1994\n本科/泰山学院自动化专业\n籍贯：山东\n住址：朝阳-酒仙桥\n工作年限：5年\n求职方向：java服务端开发\n手机：18612836421\nEmail: yuvenhol@email.cn\n技能清单 后端框架：Spring Boot +Spring Cloud\n开发环境：Linux、Windows、MacOS\n消息队列：Kafka\n数据库：MySQL/ES/MongoDB/Redis\n版本管理：Svn/Git\n其他语言：Python、GO\n个人优点 有着良好的团队精神，积极参与需求讨论，能从用户角度考虑问题，并给予技术实现方案。\n能够主动承担任务，有较强执行力，及时为运营解决问题，与产品探讨优化方案，保证又快又好上线。\n工作经历 完美世界控股集团有限公司 （ 2018年8月 ~ 至今 ） 全未来项目（2020.3~至今） 所用技术： SpringCloud、MySQL、ElasticSearch、Kafka、Redis\n项目介绍： 全未来项目是一个为用户提供安排未来生活的资讯平台，包括剧本杀、密室逃脱等活动的组团约玩，演唱会、脱口秀、漫展、特殊影厅等活动门票售卖，以及线上线下的抽奖活动。基于SpringCloud，分为客户端主服务、社区服务、商城主服务、商城后台、运营后台、以及第三方服务等几个微服务系统。主要业务数据存储于MySQL中，复杂查询、基于位置信息查询、大文本的数据从MySQL中抽取聚合再刷到ES中，使用Redis做缓存和分布式锁，Kafka做消息队列对复杂处理削峰。\n工作内容： 主要负责app、小程序和中台接口的开发，第三方接口对接，以及工作任务的安排。\napp\u0026小程序:首页、附近页、详情页、客户端内容生产、发帖与评论相关接口。\n内容生成平台：主体内容生产、机器审核、人工审核，权限校验，个人信息与社区内容的审核。\n内容管理平台：运营工具、数据分发标签，地区、场所、商圈、品牌等基础数据管理，后台用户权限管理。\n商城后台：商品管理、订单管理、商家管理、用户权限管理。\n收获： 在这个项目中，我提升了视野，学会了从团队的角度思考问题。通过对业务的深度参与得到了更深的理解，这有助于对更精准的抽象数据结构和写出贴合实际的业务代码，减少与产品反复沟通，提高整体团队效率。我因此受益匪浅，也赢得了产品和领导们的一致好评。\n全历史项目（2018.8~2020~3） 所用技术： SpringCloud、MySQL、MongoDB、ElasticSearch、Kafka、Redis\n项目介绍： 全历史是一个为历史爱好者学习交流分享的平台，包含关系图谱、疆域变迁、历史规律、各种专业史、以及艺术作品等。项目基于SpringCloud，大文本和爬虫数据存住在MongoDB中，业务数据主要存住在MySQL，有复杂查询需求会同步数据到ES中，频繁访问以及处理时间较长的数据使用Redis做缓存，使用Kafka做消息队列对复杂处理削峰。\n工作内容： 我主要负责app和中台接口的开发，以及数据的爬取和清洗。项目的数据由运营人员编写和网络抓取数据组成。在爬虫开发资源不够的时候，我负责了网络数据爬取解析存储。后来开发了科技史、战争史、美术史等专业史的内容生产平台、外包审核系统、app端接口，以及一些文字转语音、音视频拼接、地理位置信息查询等第三方服务的对接。项目起初是单体服务，随着业务的发展逐渐显得过于臃肿对开发调试部署都带来了不便，我接手以后率先进行了微服务改造，梳理可拆分业务，旧服务代码剥离，切换到新服务。\n收获： 上手掌握了SpringCloud相关技术栈，养成了较良好的开发习惯，与各端开发人员、产品运营形成了默契的配合。\n北京康健德科技有限公司 （ 2018年4月 ~ 2018年8月 ） 健康评估项目 所用技术： SpringCloud、MySQL、Redis\n项目介绍： 与各大体检机构合作，对用户历年体检数据进行比对得到结合专业医师对用户身体发展状况进行评估，根据评估结果推送相关产品。项目是基于SpringBoot单体应用，使用mysql作为数据库，redis做缓存。\n工作内容： 数据评估工具开发，计算身体状况得分，推荐对应商品。\n浩鸿达科技发展股份公司 （ 2016年7月 ~ 2018年3月 ） 电子会计档案系统： 项目介绍： 开发专业具有收集归档、档案管理、保管、检索利⽤、鉴定销毁、统计、系统管理等模块 在内的功能完善的会计档案系统。并针不同财务系统开发数据抽取接口，对数据进行ETL，整理到档案系统⽣成PDF⽂件，加盖数字签章。\n工作内容： 针对各财务系统对接接口开发，数据库设计，⽂档维护，数据进行ETL，生成PDF文件加盖数字签章。\n— 致谢 感谢您花时间阅读我的简历，期待能有机会和您共事。\n",
    "description": "",
    "tags": null,
    "title": "简历",
    "uri": "/%E9%9D%A2%E8%AF%95/%E7%AE%80%E5%8E%86/"
  },
  {
    "content": "PUSH模式 为每个订阅的用户推消息 缺点：大V推送的用户太多\nPULL模式 用户上线以后去拉去新消息 缺点：比较复杂，而且要多次查询再排序\n",
    "description": "",
    "tags": null,
    "title": "类微博feed流",
    "uri": "/%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/%E7%B1%BB%E5%BE%AE%E5%8D%9Afeed%E6%B5%81/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "限流",
    "uri": "/%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/%E9%99%90%E6%B5%81/"
  },
  {
    "content": "Redis 缓存雪崩、缓存击穿、缓存穿透的概念和解决方案 缓存雪崩： 描述： 大量缓存集中失效，查询数据量很大，引起数据库压力过大。 解决方案：\n缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。 设置热点数据永远不过期。 缓存击穿： 描述: 缓存击穿是指缓存中没有但数据库中有的数据（一般是缓存时间到期），这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力 解决方案：\n设置热点数据永远不过期。 加互斥锁，解锁后重入。 缓存穿透： 描述 大量访问数据库中不存在缓存中也不存在的数据，导致数据库压力过大，也是攻击的一种手段。 解决方案：\n接口层增加校验，如用户鉴权校验，id做基础校验，id\u003c=0的直接拦截； 从缓存取不到的数据，在数据库中也没有取到，这时也可以将key-value对写为key-null，缓存有效时间可以设置短点，如30秒（设置太长会导致正常情况也没法使用）。这样可以防止攻击用户反复用同一个id暴力攻击 如何实现接口幂等 token方式 先下发token，完成之后再清除token\n乐观锁 基于乐观锁来控制版本\n分布式事务 1、2pc\n",
    "description": "",
    "tags": null,
    "title": "面试题整理",
    "uri": "/%E9%9D%A2%E8%AF%95/%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "Categories",
    "uri": "/categories/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "content",
    "uri": "/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "docker\u0026k8s",
    "uri": "/dockerk8s/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "java",
    "uri": "/java/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "jvm",
    "uri": "/java/jvm/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "mvc",
    "uri": "/spring/mvc/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "office",
    "uri": "/office/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "spring",
    "uri": "/spring/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "springboot",
    "uri": "/spring/springboot/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "Tags",
    "uri": "/tags/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "中间件",
    "uri": "/%E4%B8%AD%E9%97%B4%E4%BB%B6/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "工具",
    "uri": "/%E5%B7%A5%E5%85%B7/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "微服务",
    "uri": "/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "操作系统",
    "uri": "/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "杂项",
    "uri": "/%E6%9D%82%E9%A1%B9/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "权限控制",
    "uri": "/%E6%9D%83%E9%99%90%E6%8E%A7%E5%88%B6/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "算法",
    "uri": "/%E7%AE%97%E6%B3%95/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "解决方案",
    "uri": "/%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "计算机基础",
    "uri": "/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "面试",
    "uri": "/%E9%9D%A2%E8%AF%95/"
  }
]

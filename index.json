[
  {
    "content": "@Configuration+@Bean\n@Configuration public class AppConfig{ @Bean public JDBCTempalte t1(){ } @Bean public TranslationManager transactionManager(){ } @Bean public DataSource dataSource(){ xxx } } @Bean 修饰方法后，方法名作为beanname 加入叫spring容器 被Configuration修饰以后，该对象将变成代理对象，在获取bean修饰的方法时，如果spring容器有bean则会直接返回，没有会执行并生成bean\n",
    "description": "",
    "tags": null,
    "title": "@Configuration",
    "uri": "/spring/configuration/"
  },
  {
    "content": "题目 给定一个整数数组 nums 和一个整数目标值 target，请你在该数组中找出 和为目标值 target 的那 两个 整数，并返回它们的数组下标。\n你可以假设每种输入只会对应一个答案。但是，数组中同一个元素在答案里不能重复出现。\n你可以按任意顺序返回答案。\n示例 1：\n输入：nums = [2,7,11,15], target = 9 输出：[0,1] 解释：因为 nums[0] + nums[1] == 9 ，返回 [0, 1] 。 示例 2：\n输入：nums = [3,2,4], target = 6 输出：[1,2] 示例 3：\n输入：nums = [3,3], target = 6 输出：[0,1] 提示：\n2 \u003c= nums.length \u003c= 104 -109 \u003c= nums[i] \u003c= 109 -109 \u003c= target \u003c= 109 只会存在一个有效答案 题解 ",
    "description": "",
    "tags": null,
    "title": "1.两数之和",
    "uri": "/%E7%AE%97%E6%B3%95%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/leetcode%E7%BB%8F%E5%85%B8100%E9%A2%98/1.%E4%B8%A4%E6%95%B0%E4%B9%8B%E5%92%8C/"
  },
  {
    "content": "#bit-manipulation\n题目 给定一个非空整数数组，除了某个元素只出现一次以外，其余每个元素均出现两次。找出那个只出现了一次的元素。\n说明：\n你的算法应该具有线性时间复杂度。 你可以不使用额外空间来实现吗？\n示例 1:\n输入: [2,2,1] 输出: 1 示例 2:\n输入: [4,1,2,1,2] 输出: 4 题解 这道题有很多解法，暴力双循环、hashmap、但是要实现时间O(n) 空间O(1)，还得是位运算，这里用的是异或。 class Solution: def singleNumber(self, nums: List[int]) -\u003e int: result=0 for num in nums: result=num^result return result ",
    "description": "",
    "tags": null,
    "title": "136.只出现一次的数字",
    "uri": "/%E7%AE%97%E6%B3%95%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/leetcode%E7%BB%8F%E5%85%B8100%E9%A2%98/136.%E5%8F%AA%E5%87%BA%E7%8E%B0%E4%B8%80%E6%AC%A1%E7%9A%84%E6%95%B0%E5%AD%97/"
  },
  {
    "content": "题目 给定一个只包括 '('，')'，'{'，'}'，'['，']' 的字符串 s ，判断字符串是否有效。\n有效字符串需满足：\n左括号必须用相同类型的右括号闭合。 左括号必须以正确的顺序闭合。 每个右括号都有一个对应的相同类型的左括号。 示例 1：\n输入：s = \"()\" 输出：true 示例 2：\n输入：s = \"()[]{}\" 输出：true 示例 3：\n输入：s = \"(]\" 输出：false 提示：\n1 \u003c= s.length \u003c= 104 s 仅由括号 '()[]{}' 组成 题解 class Solution: def isValid(self, s: str) -\u003e bool: if len(s) % 2 != 0: return False # 首先括号以键值对的形式存在，想到用dict存储，简化判断 dic = {\"{\": \"}\", \"[\": \"]\", \"(\": \")\"} # 这里用一个栈的思想，保存成对括号bracket的入和出 # 这里数组里放一个字符 stack = [\"?\"] for c in s: if c in dic: stack.append(dic[c]) else: if stack[-1] == c: stack.pop() else: return False return len(stack) \u003c= 1 ",
    "description": "",
    "tags": null,
    "title": "20.有效的括号",
    "uri": "/%E7%AE%97%E6%B3%95%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/leetcode%E7%BB%8F%E5%85%B8100%E9%A2%98/20.%E6%9C%89%E6%95%88%E7%9A%84%E6%8B%AC%E5%8F%B7/"
  },
  {
    "content": "将两个升序链表合并为一个新的 升序 链表并返回。新链表是通过拼接给定的两个链表的所有节点组成的。 示例 1： 输入： l1 = [1,2,4], l2 = [1,3,4] 输出： [1,1,2,3,4,4]\n示例 2：\n输入： l1 = [], l2 = [] 输出：[]\n示例 3：\n**输入：**l1 = [], l2 = [0] 输出：[0]\n提示：\n两个链表的节点数目范围是 [0, 50] -100 \u003c= Node.val \u003c= 100 l1 和 l2 均按 非递减顺序 排列 class Solution: def mergeTwoLists(self, list1: Optional[ListNode], list2: Optional[ListNode]) -\u003e Optional[ListNode]: pre_header=ListNode(-1) pre = pre_header while list1 and list2: if list1.val \u003c= list2.val: pre.next=list1 list1=list1.next else: pre.next=list2 list2=list2.next pre=pre.next pre.next = list1 if list1 is not None else list2 return pre_header.next ",
    "description": "",
    "tags": null,
    "title": "21.合并两个有序链表",
    "uri": "/%E7%AE%97%E6%B3%95%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/leetcode%E7%BB%8F%E5%85%B8100%E9%A2%98/21.%E5%90%88%E5%B9%B6%E4%B8%A4%E4%B8%AA%E6%9C%89%E5%BA%8F%E9%93%BE%E8%A1%A8/"
  },
  {
    "content": "#backtrack [[回溯（DFS）]]\n题目 数字 n 代表生成括号的对数，请你设计一个函数，用于能够生成所有可能的并且 有效的 括号组合。\n示例 1：\n输入：n = 3 输出：[\"((()))\",\"(()())\",\"(())()\",\"()(())\",\"()()()\"] 示例 2：\n输入：n = 1 输出：[\"()\"]\n提示：\n1 \u003c= n \u003c= 8\n题解 回溯法 class Solution: def generateParenthesis(self, n: int) -\u003e List[str]: result = [] def backtrack(path, left: int, right: int): # 退出条件 if len(path) == n*2: result.append(''.join(path)) return # 条件选择 if left\u003cn: path.append(\"(\") backtrack(path,left+1,right) #恢复 path.pop() if right\u003cleft: path.append(\")\") backtrack(path,left,right+1) path.pop() backtrack([], 0, 0) return result ",
    "description": "",
    "tags": null,
    "title": "22.括号生成",
    "uri": "/%E7%AE%97%E6%B3%95%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/leetcode%E7%BB%8F%E5%85%B8100%E9%A2%98/22.%E6%8B%AC%E5%8F%B7%E7%94%9F%E6%88%90/"
  },
  {
    "content": "#双指针\n题目： 给你一个 升序排列 的数组 nums ，请你 原地 删除重复出现的元素，使每个元素 只出现一次 ，返回删除后数组的新长度。元素的 相对顺序 应该保持 一致 。\n由于在某些语言中不能改变数组的长度，所以必须将结果放在数组nums的第一部分。更规范地说，如果在删除重复项之后有 k 个元素，那么 nums 的前 k 个元素应该保存最终结果。\n将最终结果插入 nums 的前 k 个位置后返回 k 。\n不要使用额外的空间，你必须在 原地 修改输入数组 并在使用 O(1) 额外空间的条件下完成。\n示例 2：\n输入：nums = [0,0,1,1,1,2,2,3,3,4] 输出：5, nums = [0,1,2,3,4] 解释：函数应该返回新的长度 5 ， 并且原数组 nums 的前五个元素被修改为 0, 1, 2, 3, 4 。不需要考虑数组中超出新长度后面的元素。 题解： # # @lc app=leetcode.cn id=26 lang=python3 # # [26] 删除有序数组中的重复项 # # @lc code=start class Solution: def removeDuplicates(self, nums: List[int]) -\u003e int: ol=len(nums) # 快慢指针 s,i=0,0; l=1; while(i\u003col-1): i+=1 if nums[s]==nums[i]: continue s+=1 temp=nums[s] nums[s]=nums[i] nums[i]=temp l+=1 return l ",
    "description": "",
    "tags": null,
    "title": "26.删除有序数组中的重复项",
    "uri": "/%E7%AE%97%E6%B3%95%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/leetcode%E7%BB%8F%E5%85%B8100%E9%A2%98/26.%E5%88%A0%E9%99%A4%E6%9C%89%E5%BA%8F%E6%95%B0%E7%BB%84%E4%B8%AD%E7%9A%84%E9%87%8D%E5%A4%8D%E9%A1%B9/"
  },
  {
    "content": "#动态规划\n题目 给你一个整数数组 nums ，找到其中最长严格递增子序列的长度。\n子序列 是由数组派生而来的序列，删除（或不删除）数组中的元素而不改变其余元素的顺序。例如，[3,6,2,7] 是数组 [0,3,1,6,2,2,7] 的子序列。\n示例 1：\n输入：nums = [10,9,2,5,3,7,101,18] 输出：4 解释：最长递增子序列是 [2,3,7,101]，因此长度为 4 。 示例 2：\n输入：nums = [0,1,0,3,2,3] 输出：4 示例 3：\n输入：nums = [7,7,7,7,7,7,7] 输出：1\n提示：\n1 \u003c= nums.length \u003c= 2500 -104 \u003c= nums[i] \u003c= 104\n题解 自己的第一反应是错误的 我第一反应最长的增长应该是连续的ex:[3,1,2,5]。 实际上可能中间会穿插ex:[1,5,2,3]。\nclass Solution: max=0; def setMax(self,max): if self.max\u003cmax: self.max=max; def lengthOfLIS(self, nums: List[int]) -\u003e int: for i in range(len(nums)): max_value=-1 max_length=0 for j in range(i,len(nums)): if nums[j]\u003emax_value: max_value=nums[j] max_length+=1 self.setMax(max_length) return self.max 所以暴力循环的时间复杂度可能是n^3，这太恐怖了\n动态规划 ",
    "description": "",
    "tags": null,
    "title": "300. 最长递增子序列",
    "uri": "/%E7%AE%97%E6%B3%95%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/leetcode%E7%BB%8F%E5%85%B8100%E9%A2%98/300.-%E6%9C%80%E9%95%BF%E9%80%92%E5%A2%9E%E5%AD%90%E5%BA%8F%E5%88%97/"
  },
  {
    "content": "#动态规划\n题目 假设你正在爬楼梯。需要 n 阶你才能到达楼顶。\n每次你可以爬 1 或 2 个台阶。你有多少种不同的方法可以爬到楼顶呢？\n示例 1：\n输入：n = 2 输出：2 解释：有两种方法可以爬到楼顶。 1. 1 阶 + 1 阶 2. 2 阶 示例 2：\n输入：n = 3 输出：3 解释：有三种方法可以爬到楼顶。 1. 1 阶 + 1 阶 + 1 阶 2. 1 阶 + 2 阶 3. 2 阶 + 1 阶 提示：\n1 \u003c= n \u003c= 45 题解 f(n)=f(n-1)+f(n-2)\nclass Solution: def climbStairs(self, n: int) -\u003e int: # 这道题使用递归会超过最大调用深度，所以比dp数组的形式解决 dp = [1, 2] if n \u003c= 2: return dp[n-1] # 数组下标 for i in range(2, n): dp.append(dp[i-1]+dp[i-2]) return dp[-1] ",
    "description": "",
    "tags": null,
    "title": "70.爬楼梯",
    "uri": "/%E7%AE%97%E6%B3%95%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/leetcode%E7%BB%8F%E5%85%B8100%E9%A2%98/70.%E7%88%AC%E6%A5%BC%E6%A2%AF/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "AOP使用",
    "uri": "/spring/aop/aop%E4%BD%BF%E7%94%A8/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "arthas",
    "uri": "/%E5%B7%A5%E5%85%B7/arthas/"
  },
  {
    "content": " cat 全称 Compact and aligned text ，紧凑\u0026对齐文本\nIntroduction json对计算机来说是方便。但是人类尝试找从数据中关联是不容易的，即使pretty-print。在看终端时，特别需要紧凑\u0026对齐的文本展示。\n所有的cat命令都是以/_cat 开头，如果什么都不输入那么将展示所有可用的命令。\n通用命令 详细说明verbose 命令中如果加上v，那么将详细输出（verbose output），可以展示表头。\nex：\nGET _cat/master?v=true respond with:\nid host ip node u_n93zwxThWHi1PDBJAGAg 127.0.0.1 127.0.0.1 u_n93zw 帮助文档 在命令后加入help则展示帮助 GET _cat/master?help\nid | | node id host | h | host name ip | | ip address node | n | node name 排序 GET _cat/indices?s=store.size:desc\nindices 返回索引在集群内的高级信息 主要展示信息\nShard count Document count Deleted document count Primary store size Total store size of all shards, including shard replicas ex: GET _cat/indices/*kibana*?v=true 详细输出，模糊匹配key中带有kibana的index信息\n",
    "description": "",
    "tags": null,
    "title": "CAT API",
    "uri": "/%E4%B8%AD%E9%97%B4%E4%BB%B6/elasticsearch/cat-api/"
  },
  {
    "content": "操作字节码生成代理类\nClass UserServiceProxy extends UserService{ public void test(){ //切面逻辑 super.test() } //切面逻辑 }\n",
    "description": "",
    "tags": null,
    "title": "cglib",
    "uri": "/java/lib/cglib/"
  },
  {
    "content": "#classpath #java基础 搬运：https://stackoverflow.com/questions/2396493/what-is-a-classpath-and-how-do-i-set-it/2396759#2396759\n什么是classpath 当我们在写java程序的时候，常常会引用其他的class文件，ex：\nimport org.javaguy.coolframework.MyClass; 当解析到，使用到饮用的class时，JVM将会根据import找到你编译以后的class文件。\nMyClass mine = new MyClass(); 当然VM不可能搜索所有你电脑上的文件，所以你需要提供一个路径的列表给VM去搜索。classpath就是提供一个jar file或者文件夹列表。\n如何设置classpath 假设目前我们要引入一个==lib/CoolFramework.jar==的jar包，我们可以怎么做呢。\n我们可以通过环境变量，像这样来搞定。\nexport CLASSPATH=/home/myaccount/myproject/lib/CoolFramework.jar 但是环境变量是全局的，经常会引起冲突等等问题，所以这并不是一个好的方案。\n我们也可以在command内指定引入的包。ex：\njava -cp \"/home/myaccount/myproject/lib/CoolFramework.jar:/home/myaccount/myproject/output/\" MyMainClass 当然这样也很麻烦，我们在使用spring boot时，打成一个jar包，而jar包内则描述好了，classpath。\nManifest-Version: 1.0 Spring-Boot-Classpath-Index: BOOT-INF/classpath.idx Built-By: sczyh30 Spring-Boot-Layers-Index: BOOT-INF/layers.idx Start-Class: com.alibaba.csp.sentinel.dashboard.DashboardApplication Spring-Boot-Classes: BOOT-INF/classes/ Spring-Boot-Lib: BOOT-INF/lib/ Spring-Boot-Version: 2.5.12 Created-By: Apache Maven 3.8.1 Build-Jdk: 1.8.0_152 Main-Class: org.springframework.boot.loader.JarLauncher ",
    "description": "",
    "tags": null,
    "title": "classpath",
    "uri": "/java/classpath/"
  },
  {
    "content": "官方文档： https://docs.python.org/zh-cn/3/library/csv.html\n读取 CSV 文件最简单的一个例子:\nimport csv with open(‘some.csv’, newline=’’) as f: reader = csv.reader(f) for row in reader: print(row)\n读取其他格式的文件:\nimport csv with open(‘passwd’, newline=’’) as f: reader = csv.reader(f, delimiter=’:’, quoting=csv.QUOTE_NONE) for row in reader: print(row)\n相应最简单的写入示例是:\nimport csv with open(‘some.csv’, ‘w’, newline=’’) as f: writer = csv.writer(f) writer.writerows(someiterable)\nSince open() is used to open a CSV file for reading, the file will by default be decoded into unicode using the system default encoding (see locale.getencoding()). To decode a file using a different encoding, use the encoding argument of open:\nimport csv with open(‘some.csv’, newline=’’, encoding=‘utf-8’) as f: reader = csv.reader(f) for row in reader: print(row)\n这同样适用于写入非系统默认编码的内容：打开输出文件时，指定 encoding 参数。\n注册一个新的变种:\nimport csv csv.register_dialect(‘unixpwd’, delimiter=’:’, quoting=csv.QUOTE_NONE) with open(‘passwd’, newline=’’) as f: reader = csv.reader(f, ‘unixpwd’)\nReader 的更高级用法——捕获并报告错误:\nimport csv, sys filename = ‘some.csv’ with open(filename, newline=’’) as f: reader = csv.reader(f) try: for row in reader: print(row) except csv.Error as e: sys.exit(‘file {}, line {}: {}’.format(filename, reader.line_num, e))\n尽管该模块不直接支持解析字符串，但仍可如下轻松完成:\nimport csv for row in csv.reader([‘one,two,three’]): print(row)\n",
    "description": "",
    "tags": null,
    "title": "csv",
    "uri": "/python/csv/"
  },
  {
    "content": "领域驱动设计 Domain-driven design (DDD) is a major software design approach, focusing on modelling software to match a domain according to input from that domain’s experts. —wikipedia\n领域驱动是一种软件设计方式，聚焦于软件模型和领域专家（十分了解具体业务的人）的输出相匹配。\n解决的问题-系统老化 软件总是从简单发展到复杂，老化的原因主要是，真实世界和软件世界存在差异，并随着需求变更逐渐拉大。\n传统数据驱动设计存在的问题 传统MVC架构倾向于从数据库ER图开始进行设计。随着业务越来越多，变化越来越，事务脚本会越来越复杂，可能一个类里面有大量的逻辑。这时候系统将逐渐老化。 数据驱动到领域驱动 Data Driven Design –\u003e Domain Driven Design\n领域驱动设计是一种面向变化的一种设计，设计的核心模型从数据驱动的数据库表转移到领域模型。领域模型将由开发人员和领域专家共同设计，这样实际的模型将更贴近真实世界。\n优点 代码更贴近真实世界，需求调整变更 更容易 逻辑更内聚，代码复用度更高，也更易于测试 业务逻辑不再需要背负技术债，根据业务场景变化开发即可 缺点 DDD并非银弹\n概念多，学习成本高，难上手，新手往往不知所措。如果不熟悉DDD的思想，生硬地照搬ddd的规范，写出来的代码可能比传统的三层架构还糟糕，得不偿失。 实现一个功能写的代码量比传统的三层架构多 模型之间转换操作比较多，编码繁琐 概念 *领域：某一类业务相关知识的集合，在一个领域下应使用统一语言对概念描述 *统一语言（UL）：从业务中提炼出来的概念术语，领域专家、产品、开发可以互相理解的沟通语言 *子域：一个子域是领域的一部分 *实体（Entity）：具有唯一标识，有状态（程序需要追踪其状态的变化），具有生命周期、mutable的领域对象 *值对象（valueObject）：没有唯一标识、无状态、无生命周期、可复用、immutable的领域对象，类似基本类型int、long、String *聚合：一组具有关联关系领域对象，可包含实体和值对象 *聚合根：聚合的根，可以理解为可以代表整体概念的实体，操作子实体和值对象需要通过聚合根遍历，类似树形数据结构的根节点，这样可以保证数据的完整性 *领域事件：某个操作触发的事件，领域事件可以跟踪领域对象生命周期的状态变化过程。例如一个实体经过多次修改，每次产生一个实体修改事件，把所有实体修改事件按发生的顺序可以重建某个时间点的快照对象。领域事件也是同一个用例操作多个聚合的实现方式 *领域服务：同一个操作中需要操作到多个聚合根对象的逻辑需要抽到领域服务，或者同一个聚合中可以被多个用例复用的公共逻辑 实体和值对象如何区别： 主要是通过有没有唯一标识确定，相同的对象在不同场景可能表现不同，比如用户的收货地址和订单的收货地址，用户的收货地址是实体，而订单的收货地址可能就是值对象，如果用户的收货地址改变，订单的收货地址是不会变的。\n开发流程：\n首先对需要处理的业务问题进行总览。 然后领域对象(Entity)进行划分，明确每个领域对象的包含的信息和职责边界。 并进行跨对象，多对象的逻辑组织(Domain Service) 接着在上层应用中根据业务描述去编排Entity和Domain Service。 最后再做一些下水道工作，去对下层的数据访问，RPC调用去做一些具体实现。 CQRS ： 按照领域建模固然很好，但是面对各种各样的查询条件和表单时，仅仅依赖领域对象和聚合来组织代码时，往往会显得很笨拙，但是如果我们放宽对查询的要求，可以在不破坏模型的情况下，尽可能的保证查询的效率和灵活性。这就引出了CQRS\nCQRS全称Command Query Responsibility Segregation，即命令查询职责分离，顾名思义，将命令和查询分离。\n查询，就是查询数据（CRUD中的R），不会对数据产生变化，因此它是幂等的,不用担心对系统产生影响，因此也可以针对查询添加缓存操作提升查询性能。\n那命令是啥呢？这里命令则是对数据产生变化的操作的总称（CRUD中的CUD）。\n大多数软件系统中，查询频率要远大于命令操作，这是将查询与命令分离的根本原因。\n通过CQRS模式将读模型和写模型分离，使得我们可以优化读性能和写性能之外，还可以让我们的代码更加清晰简洁，更加体现出领域，更易维护。\n一些比较好的例子 CQRS：https://zhuanlan.zhihu.com/p/505023604 https://developer.aliyun.com/article/719251 https://juejin.cn/post/7131186996277411876 https://developer.aliyun.com/article/716908?spm=a2c6h.13262185.profile.62.3729653boxTzr3\n",
    "description": "",
    "tags": null,
    "title": "DDD Domain-Driven Design",
    "uri": "/%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/ddd-domain-driven-design/"
  },
  {
    "content": "直接内存访问（Direct Memory Access，DMA）是计算机科学中的一种内存访问技术。它允许某些电脑内部的硬件子系统（电脑外设），可以独立地直接读写系统内存，而不需中央处理器（CPU）介入处理 。在同等程度的处理器负担下，DMA是一种快速的数据传送方式。很多硬件的系统会使用DMA，包含硬盘控制器、绘图显卡、网卡和声卡。\n",
    "description": "",
    "tags": null,
    "title": "DMA",
    "uri": "/%E7%A1%AC%E4%BB%B6/dma/"
  },
  {
    "content": "简介 docker compose用于更加方便的管理docker容器，采用yml文件配置的方式代替，敲入docker命令，配置时更加清晰，也更适合多个节点配置。\nhub.docker.com\n配置文件编写 stdin_open 保持标准输入，如果容器没有启动\n网络配置 四类网络模式 Docker网络模式\n配置\n说明\nhost模式\n–net=host\n容器和宿主机共享Network namespace。\ncontainer模式\n–net=container:NAME_or_ID\n容器和另外一个容器共享Network namespace。 kubernetes中的pod就是多个容器共享一个Network namespace。\nnone模式\n–net=none\n容器有独立的Network namespace，但并没有对其进行任何网络设置，如分配veth pair 和网桥连接，配置IP等。\nbridge模式\n–net=bridge\n（默认为该模式）\nhost模式 如果启动容器的时候使用host模式，那么这个容器将不会获得一个独立的Network Namespace，而是和宿主机共用一个Network Namespace。容器将不会虚拟出自己的网卡，配置自己的IP等，而是使用宿主机的IP和端口。但是，容器的其他方面，如文件系统、进程列表等还是和宿主机隔离的。\n使用host模式的容器可以直接使用宿主机的IP地址与外界通信，容器内部的服务端口也可以使用宿主机的端口，不需要进行NAT，host最大的优势就是网络性能比较好，但是docker host上已经使用的端口就不能再用了，网络的隔离性不好。\nHost模式如下图所示：\ncontainer模式 这个模式指定新创建的容器和已经存在的一个容器共享一个 Network Namespace，而不是和宿主机共享。新创建的容器不会创建自己的网卡，配置自己的 IP，而是和一个指定的容器共享 IP、端口范围等。同样，两个容器除了网络方面，其他的如文件系统、进程列表等还是隔离的。两个容器的进程可以通过 lo 网卡设备通信。\nContainer模式示意图：\nnone模式 使用none模式，Docker容器拥有自己的Network Namespace，但是，并不为Docker容器进行任何网络配置。也就是说，这个Docker容器没有网卡、IP、路由等信息。需要我们自己为Docker容器添加网卡、配置IP等。\n这种网络模式下容器只有lo回环网络，没有其他网卡。none模式可以在容器创建时通过–network=none来指定。这种类型的网络没有办法联网，封闭的网络能很好的保证容器的安全性。\nNone模式示意图:\nbridge模式 当Docker进程启动时，会在主机上创建一个名为docker0的虚拟网桥，此主机上启动的Docker容器会连接到这个虚拟网桥上。虚拟网桥的工作方式和物理交换机类似，这样主机上的所有容器就通过交换机连在了一个二层网络中。\n从docker0子网中分配一个IP给容器使用，并设置docker0的IP地址为容器的默认网关。在主机上创建一对虚拟网卡veth pair设备，Docker将veth pair设备的一端放在新创建的容器中，并命名为eth0（容器的网卡），另一端放在主机中，以vethxxx这样类似的名字命名，并将这个网络设备加入到docker0网桥中。可以通过brctl show命令查看。\nbridge模式是docker的默认网络模式，不写–net参数，就是bridge模式。使用docker run -p时，docker实际是在iptables做了DNAT规则，实现端口转发功能。可以使用iptables -t nat -vnL查看。\nbridge模式如下图所示：\n示例 rocketmq cluster 注意docker要容器直接访问端口必须加ports，可以不指定宿主机端口，但是必须指定容器\nversion: '3.8' services: namesrv1: image: apache/rocketmq hostname: namesrv1 ports: - 9876 command: \"/home/rocketmq/rocketmq-4.9.4/bin/mqnamesrv\" namesrv2: image: apache/rocketmq hostname: namesrv2 ports: - 9876 command: \"/home/rocketmq/rocketmq-4.9.4/bin/mqnamesrv\" namesrv3: image: apache/rocketmq hostname: namesrv3 ports: - 9876 command: \"/home/rocketmq/rocketmq-4.9.4/bin/mqnamesrv\" broker1: image: apache/rocketmq hostname: broker1 command: \"/home/rocketmq/rocketmq-4.9.4/bin/mqbroker\" ports: - 10911 - 10909 - 10912 environment: - NAMESRV_ADDR=namesrv1:9876;namesrv2:9876;namesrv3:9876 broker2: image: apache/rocketmq hostname: broker2 command: \"/home/rocketmq/rocketmq-4.9.4/bin/mqbroker\" ports: - 10911 - 10909 - 10912 environment: - NAMESRV_ADDR=namesrv1:9876;namesrv2:9876;namesrv3:9876 broker3: image: apache/rocketmq hostname: broker3 command: \"/home/rocketmq/rocketmq-4.9.4/bin/mqbroker\" ports: - 10911 - 10909 - 10912 environment: - NAMESRV_ADDR=namesrv1:9876;namesrv2:9876;namesrv3:9876 test: image: apache/rocketmq environment: - NAMESRV_ADDR=namesrv1:9876;namesrv2:9876;namesrv3:9876 stdin_open: true ",
    "description": "",
    "tags": null,
    "title": "docker compose",
    "uri": "/dockerk8s/docker-compose/"
  },
  {
    "content": "Docker 官方文档地址:https://www.docker.com/get-started\n中文参考手册:https://docker_practice.gitee.io/zh-cn/\n1.什么是 Docker 1.1 官方定义 最新官网首页 # 1.官方介绍 - We have a complete container solution for you - no matter who you are and where you are on your containerization journey. - 翻译: 我们为你提供了一个完整的容器解决方案,不管你是谁,不管你在哪,你都可以开始容器的的旅程。 - 官方定义: docker是一个容器技术。 1.2 Docker的起源 Docker 最初是 dotCloud 公司创始人 Solomon Hykes 在法国期间发起的一个公司内部项目，它是基于 dotCloud 公司多年云服务技术的一次革新，并于 2013 年 3 月以 Apache 2.0 授权协议开源，主要项目代码在 GitHub 上进行维护。Docker 项目后来还加入了 Linux 基金会，并成立推动 开放容器联盟（OCI）。 Docker 自开源后受到广泛的关注和讨论，至今其 GitHub 项目 已经超过 5 万 7 千个星标和一万多个 fork。甚至由于 Docker 项目的火爆，在 2013 年底，dotCloud 公司决定改名为 Docker。Docker 最初是在 Ubuntu 12.04 上开发实现的；Red Hat 则从 RHEL 6.5 开始对 Docker 进行支持；Google 也在其 PaaS 产品中广泛应用 Docker。 Docker 使用 Google 公司推出的 Go 语言 进行开发实现，基于 Linux 内核的 cgroup，namespace，以及 OverlayFS 类的 Union FS 等技术，对进程进行封装隔离，属于操作系统层面的虚拟化技术。由于隔离的进程独立于宿主和其它的隔离的进程，因此也称其为容器。 2.为什么是Docker 在开发的时候，在本机测试环境可以跑，生产环境跑不起来\n这里我们拿java Web应用程序举例，我们一个java Web应用程序涉及很多东西，比如jdk、tomcat、mysql等软件环境。当这些其中某一项版本不一致的时候，可能就会导致应用程序跑不起来这种情况。Docker则将程序以及使用软件环境直接打包在一起，无论在那个机器上保证了环境一致。\n优势1: 一致的运行环境,更轻松的迁移\n服务器自己的程序挂了，结果发现是别人程序出了问题把内存吃完了，自己程序因为内存不够就挂了\n这种也是一种比较常见的情况，如果你的程序重要性不是特别高的话，公司基本上不可能让你的程序独享一台服务器的，这时候你的服务器就会跟公司其他人的程序共享一台服务器，所以不可避免地就会受到其他程序的干扰，导致自己的程序出现问题。Docker就很好解决了环境隔离的问题，别人程序不会影响到自己的程序。\n优势2：对进程进行封装隔离,容器与容器之间互不影响,更高效的利用系统资源\n公司要弄一个活动，可能会有大量的流量进来，公司需要再多部署几十台服务器\n在没有Docker的情况下，要在几天内部署几十台服务器，这对运维来说是一件非常折磨人的事，而且每台服务器的环境还不一定一样，就会出现各种问题，最后部署地头皮发麻。用Docker的话，我只需要将程序打包到镜像，你要多少台服务，我就给力跑多少容器，极大地提高了部署效率。\n优势3: 通过镜像复制N多个环境一致容器\n3.Docker和虚拟机区别 关于Docker与虚拟机的区别，我在网上找到的一张图，非常直观形象地展示出来，话不多说，直接上图。\n比较上面两张图，我们发现虚拟机是携带操作系统，本身很小的应用程序却因为携带了操作系统而变得非常大，很笨重。Docker是不携带操作系统的，所以Docker的应用就非常的轻巧。另外在调用宿主机的CPU、磁盘等等这些资源的时候，拿内存举例，虚拟机是利用Hypervisor去虚拟化内存，整个调用过程是虚拟内存-\u003e虚拟物理内存-\u003e真正物理内存，但是Docker是利用Docker Engine去调用宿主的的资源，这时候过程是虚拟内存-\u003e真正物理内存。\n传统虚拟机\nDocker容器\n磁盘占用\n几个GB到几十个GB左右\n几十MB到几百MB左右\nCPU内存占用\n虚拟操作系统非常占用CPU和内存\nDocker引擎占用极低\n启动速度\n（从开机到运行项目）几分钟\n（从开启容器到运行项目）几秒\n安装管理\n需要专门的运维技术\n安装、管理方便\n应用部署\n每次部署都费时费力\n从第二次部署开始轻松简捷\n耦合性\n多个应用服务安装到一起，容易互相影响\n每个应用服务一个容器，达成隔离\n系统依赖\n无\n需求相同或相似的内核，目前推荐是Linux\n4.Docker的安装 4.1 安装docker(centos7.x) 卸载原始docker\n$ sudo yum remove docker \\ docker-client \\ docker-client-latest \\ docker-common \\ docker-latest \\ docker-latest-logrotate \\ docker-logrotate \\ docker-engine 安装docker依赖\n$ sudo yum install -y yum-utils \\ device-mapper-persistent-data \\ lvm2 设置docker的yum源\n$ sudo yum-config-manager \\ --add-repo \\ https://download.docker.com/linux/centos/docker-ce.repo 安装最新版的docker\n$ sudo yum install docker-ce docker-ce-cli containerd.io 指定版本安装docker\n$ yum list docker-ce --showduplicates | sort -r $ sudo yum install docker-ce-\u003cVERSION_STRING\u003e docker-ce-cli-\u003cVERSION_STRING\u003e containerd.io $ sudo yum install docker-ce-18.09.5-3.el7 docker-ce-cli-18.09.5-3.el7 containerd.io 启动docker\n$ sudo systemctl enable docker $ sudo systemctl start docker 关闭docker\n$ sudo systemctl stop docker 测试docker安装\n$ sudo docker run hello-world 4.2 bash安装(通用所有平台) 在测试或开发环境中 Docker 官方为了简化安装流程，提供了一套便捷的安装脚本，CentOS 系统上可以使用这套脚本安装，另外可以通过 --mirror 选项使用国内源进行安装：执行这个命令后，脚本就会自动的将一切准备工作做好，并且把 Docker 的稳定(stable)版本安装在系统中。\n$ curl -fsSL get.docker.com -o get-docker.sh $ sudo sh get-docker.sh --mirror Aliyun 启动docker\n$ sudo systemctl enable docker $ sudo systemctl start docker 创建docker用户组\n$ sudo groupadd docker 将当前用户加入docker组\n$ sudo usermod -aG docker $USER 测试docker安装是否正确\n$ docker run hello-world 5.Docker 的核心架构 镜像: 一个镜像代表一个应用环境,他是一个只读的文件,如 mysql镜像,tomcat镜像,nginx镜像等 容器: 镜像每次运行之后就是产生一个容器,就是正在运行的镜像,特点就是可读可写 仓库:用来存放镜像的位置,类似于maven仓库,也是镜像下载和上传的位置 dockerFile:docker生成镜像配置文件,用来书写自定义镜像的一些配置 tar:一个对镜像打包的文件,日后可以还原成镜像 6. Docker 配置阿里镜像加速服务 6.1 docker 运行流程 6.2 docker配置阿里云镜像加速 访问阿里云登录自己账号查看docker镜像加速服务 sudo mkdir -p /etc/docker sudo tee /etc/docker/daemon.json \u003c\u003c-'EOF' { \"registry-mirrors\": [\"https://lz2nib3q.mirror.aliyuncs.com\"] } EOF sudo systemctl daemon-reload sudo systemctl restart docker \"registry-mirrors\": [ \"https://m910xfnq.mirror.aliyuncs.com\" ] 验证docker的镜像加速是否生效 [root@localhost ~]# docker info .......... 127.0.0.0/8 Registry Mirrors: 'https://lz2nib3q.mirror.aliyuncs.com/' Live Restore Enabled: false Product License: Community Engine 7.Docker的入门应用 7.1 docker 的第一个程序 docker run hello-world\n[root@localhost ~]# docker run hello-world Hello from Docker! This message shows that your installation appears to be working correctly. To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub. (amd64) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal. To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bash Share images, automate workflows, and more with a free Docker ID: https://hub.docker.com/ For more examples and ideas, visit: https://docs.docker.com/get-started/ 8.常用命令 6.1 辅助命令 # 1.安装完成辅助命令 docker version\t--------------------------\t查看docker的信息 docker info\t--------------------------\t查看更详细的信息 docker --help\t--------------------------\t帮助命令 6.2 Images 镜像命令 # 1.查看本机中所有镜像 docker images\t--------------------------\t列出本地所有镜像 -a\t列出所有镜像（包含中间映像层） -q\t只显示镜像id # 2.搜索镜像 docker search [options] 镜像名\t-------------------\t去dockerhub上查询当前镜像 -s 指定值\t列出收藏数不少于指定值的镜像 --no-trunc\t显示完整的镜像信息 # 3.从仓库下载镜像 docker pull 镜像名[:TAG|@DIGEST]\t----------------- 下载镜像 # 4.删除镜像 docker rmi 镜像名\t-------------------------- 删除镜像 -f\t强制删除 # 5.查看镜像历史（ex docker file） docker history 镜像名 6.3 Contrainer 容器命令 # 1.运行容器 docker run 镜像名\t--------------------------\t镜像名新建并启动容器 --name 别名为容器起一个名字 -d\t启动守护式容器（在后台启动容器） -p 映射端口号：原始端口号\t指定端口号启动 例：docker run -it --name myTomcat -p 8888:8080 tomcat docker run -d --name myTomcat -P tomcat # 2.查看运行的容器 docker ps\t--------------------------\t列出所有正在运行的容器 -a\t正在运行的和历史运行过的容器 -q\t静默模式，只显示容器编号 # 3.停止|关闭|重启容器 docker start 容器名字或者容器id --------------- 开启容器 docker restart 容器名或者容器id --------------- 重启容器 docker stop 容器名或者容器id ------------------ 正常停止容器运行 docker kill 容器名或者容器id ------------------ 立即停止容器运行 # 4.删除容器 docker rm -f 容器id和容器名 docker rm -f $(docker ps -aq)\t--------------------------\t删除所有容器 # 5.查看容器内进程 docker top 容器id或者容器名 ------------------ 查看容器内的进程 # 6.查看查看容器内部细节 docker inspect 容器id ------------------ 查看容器内部细节 # 7.查看容器的运行日志 docker logs [OPTIONS] 容器id或容器名\t------------------ 查看容器日志 -t\t加入时间戳 -f\t跟随最新的日志打印 --tail 数字\t显示最后多少条 # 8.进入容器内部 docker exec [options] 容器id 容器内命令 ------------------ 进入容器执行命令 -i\t以交互模式运行容器，通常与-t一起使用 -t\t分配一个伪终端 shell窗口 bash # 9.容器和宿主机之间复制文件 docker cp 文件|目录 容器id:容器路径 ----------------- 将宿主机复制到容器内部 docker cp 容器id:容器内资源路径 宿主机目录路径 ----------------- 将容器内资源拷贝到主机上 # 10.数据卷(volum)实现与宿主机共享目录 docker run -v 宿主机的路径|任意别名:/容器内的路径 镜像名 注意: 1.如果是宿主机路径必须是绝对路径,宿主机目录会覆盖容器内目录内容 2.如果是别名则会在docker运行容器时自动在宿主机中创建一个目录,并将容器目录文件复制到宿主机中 # 11.打包镜像 docker save 镜像名 -o 名称.tar # 12.载入镜像 docker load -i 名称.tar # 13.容器打包成新的镜像 docker commit -m \"描述信息\" -a \"作者信息\" （容器id或者名称）打包的镜像名称:标签 7.docker的镜像原理 7.1 镜像是什么？ 镜像是一种轻量级的，可执行的独立软件包，用来打包软件运行环境和基于运行环境开发的软件，它包含运行某个软件所需的所有内容，包括代码、运行时所需的库、环境变量和配置文件。\n7.2 为什么一个镜像会那么大？ 镜像就是花卷\nUnionFS（联合文件系统）:\nUnion文件系统是一种分层，轻量级并且高性能的文件系统，它支持对文件系统的修改作为一次提交来一层层的叠加，同时可以将不同目录挂载到同一个虚拟文件系统下。Union文件系统是Docker镜像的基础。这种文件系统特性:就是一次同时加载多个文件系统，但从外面看起来，只能看到一个文件系统，联合加载会把各层文件系统叠加起来，这样最终的文件系统会包含所有底层的文件和目录 。\n7.3 Docker镜像原理 docker的镜像实际是由一层一层的文件系统组成。\nbootfs（boot file system）主要包含bootloader和kernel，bootloader主要是引导加载kernel，Linux刚启动时会加载bootfs文件系统。在docker镜像的最底层就是bootfs。这一层与Linux/Unix 系统是一样的，包含boot加载器（bootloader）和内核（kernel）。当boot加载完,后整个内核就都在内存中了，此时内存的使用权已由bootfs转交给内核，此时会卸载bootfs。\nrootfs（root file system），在bootfs之上，包含的就是典型的linux系统中的/dev，/proc，/bin，/etc等标准的目录和文件。rootfs就是各种不同的操作系统发行版，比如Ubuntu/CentOS等等。\n我们平时安装进虚拟机的centos都有1到几个GB，为什么docker这里才200MB？对于一个精简的OS，rootfs可以很小，只需要包括最基本的命令，工具，和程序库就可以了，因为底层直接使用Host的Kernal，自己只需要提供rootfs就行了。由此可见不同的linux发行版，他们的bootfs是一致的，rootfs会有差别。因此不同的发行版可以共用bootfs。\n7.4 为什么docker镜像要采用这种分层结构呢? 最大的一个好处就是资源共享\n比如：有多个镜像都是从相同的base镜像构建而来的，那么宿主机只需在磁盘中保存一份base镜像。同时内存中也只需要加载一份base镜像，就可以为所有容器服务了。而且镜像的每一层都可以被共享。Docker镜像都是只读的。当容器启动时，一个新的可写层被加载到镜像的顶部。这一层通常被称为容器层，容器层之下都叫镜像层。 8.Docker安装常用服务 8.1 安装mysql # 1.拉取mysql镜像到本地 docker pull mysql:tag (tag不加默认最新版本) # 2.运行mysql服务 docker run --name mysql -e MYSQL_ROOT_PASSWORD=root -d mysql:tag --没有暴露外部端口外部不能连接 docker run --name mysql -e MYSQL_ROOT_PASSWORD=root -p 3306:3306 -d mysql:tag --没有暴露外部端口 # 3.进入mysql容器 docker exec -it 容器名称|容器id bash # 4.外部查看mysql日志 docker logs 容器名称|容器id # 5.使用自定义配置参数 docker run --name mysql -v /root/mysql/conf.d:/etc/mysql/conf.d -e MYSQL_ROOT_PASSWORD=root -d mysql:tag # 6.将容器数据位置与宿主机位置挂载保证数据安全 docker run --name mysql -v /root/mysql/data:/var/lib/mysql -v /root/mysql/conf.d:/etc/mysql/conf.d -e MYSQL_ROOT_PASSWORD=root -p 3306:3306 -d mysql:tag # 7.通过其他客户端访问 如在window系统|macos系统使用客户端工具访问 # 8.将mysql数据库备份为sql文件 docker exec mysql|容器id sh -c 'exec mysqldump --all-databases -uroot -p\"$MYSQL_ROOT_PASSWORD\"' \u003e /root/all-databases.sql --导出全部数据 docker exec mysql sh -c 'exec mysqldump --databases 库表 -uroot -p\"$MYSQL_ROOT_PASSWORD\"' \u003e /root/all-databases.sql --导出指定库数据 docker exec mysql sh -c 'exec mysqldump --no-data --databases 库表 -uroot -p\"$MYSQL_ROOT_PASSWORD\"' \u003e /root/all-databases.sql --导出指定库数据不要数据 # 9.执行sql文件到mysql中 docker exec -i mysql sh -c 'exec mysql -uroot -p\"$MYSQL_ROOT_PASSWORD\"' \u003c /root/xxx.sql 8.2 安装Redis服务 # 1.在docker hub搜索redis镜像 docker search redis # 2.拉取redis镜像到本地 docker pull redis # 3.启动redis服务运行容器 docker run --name redis -d redis:tag (没有暴露外部端口) docker run --name redis -p 6379:6379 -d redis:tag (暴露外部宿主机端口为6379进行连接) # 4.查看启动日志 docker logs -t -f 容器id|容器名称 # 5.进入容器内部查看 docker exec -it 容器id|名称 bash # 6.加载外部自定义配置启动redis容器 默认情况下redis官方镜像中没有redis.conf配置文件 需要去官网下载指定版本的配置文件 1. wget http://download.redis.io/releases/redis-5.0.8.tar.gz 下载官方安装包 2. 将官方安装包中配置文件进行复制到宿主机指定目录中如 /root/redis/redis.conf文件 3. 修改需要自定义的配置 bind 0.0.0.0 开启远程权限 appenonly yes 开启aof持久化 4. 加载配置启动 docker run --name redis -v /root/redis:/usr/local/etc/redis -p 6379:6379 -d redis redis-server /usr/local/etc/redis/redis.conf # 7.将数据目录挂在到本地保证数据安全 docker run --name redis -v /root/redis/data:/data -v /root/redis/redis.conf:/usr/local/etc/redis/redis.conf -p 6379:6379 -d redis redis-server /usr/local/etc/redis/redis.conf 8.3 安装Nginx # 1.在docker hub搜索nginx docker search nginx # 2.拉取nginx镜像到本地 [root@localhost ~]# docker pull nginx Using default tag: latest latest: Pulling from library/nginx afb6ec6fdc1c: Pull complete b90c53a0b692: Pull complete 11fa52a0fdc0: Pull complete Digest: sha256:30dfa439718a17baafefadf16c5e7c9d0a1cde97b4fd84f63b69e13513be7097 Status: Downloaded newer image for nginx:latest docker.io/library/nginx:latest # 3.启动nginx容器 docker run -p 80:80 --name nginx01 -d nginx # 4.进入容器 docker exec -it nginx01 /bin/bash 查找目录: whereis nginx 配置文件: /etc/nginx/nginx.conf # 5.复制配置文件到宿主机 docker cp nginx01(容器id|容器名称):/etc/nginx/nginx.conf 宿主机名录 # 6.挂在nginx配置以及html到宿主机外部 docker run --name nginx02 -v /root/nginx/nginx.conf:/etc/nginx/nginx.conf -v /root/nginx/html:/usr/share/nginx/html -p 80:80 -d nginx\t8.4 安装Tomcat # 1.在docker hub搜索tomcat docker search tomcat # 2.下载tomcat镜像 docker pull tomcat # 3.运行tomcat镜像 docker run -p 8080:8080 -d --name mytomcat tomcat # 4.进入tomcat容器 docker exec -it mytomcat /bin/bash # 5.将webapps目录挂载在外部 docker run -p 8080:8080 -v /root/webapps:/usr/local/tomcat/webapps -d --name mytomcat tomcat 8.5 安装MongoDB数据库 # 1.运行mongDB docker run -d -p 27017:27017 --name mymongo mongo ---无须权限 docker logs -f mymongo --查看mongo运行日志 # 2.进入mongodb容器 docker exec -it mymongo /bin/bash 直接执行mongo命令进行操作 # 3.常见具有权限的容器 docker run --name mymongo -p 27017:27017 -d mongo --auth # 4.进入容器配置用户名密码 mongo use admin 选择admin库 db.createUser({user:\"root\",pwd:\"root\",roles:[{role:'root',db:'admin'}]}) //创建用户,此用户创建成功,则后续操作都需要用户认证 exit # 5.将mongoDB中数据目录映射到宿主机中 docker run -d -p 27017:27017 -v /root/mongo/data:/data/db --name mymongo mongo 8.6 安装ElasticSearch 注意:调高JVM线程数限制数量 0.拉取镜像运行elasticsearch # 1.dockerhub 拉取镜像 docker pull elasticsearch:6.4.2 # 2.查看docker镜像 docker images # 3.运行docker镜像 docker run -p 9200:9200 -p 9300:9300 elasticsearch:6.4.2 启动出现如下错误 1. 预先配置 # 1.在centos虚拟机中，修改配置sysctl.conf vim /etc/sysctl.conf # 2.加入如下配置 vm.max_map_count=262144 # 3.启用配置 sysctl -p 注：这一步是为了防止启动容器时，报出如下错误： bootstrap checks failed max virtual memory areas vm.max_map_count [65530] likely too low, increase to at least [262144] 2.启动EleasticSearch容器 # 0.复制容器中data目录到宿主机中 docker cp 容器id:/usr/share/share/elasticsearch/data /root/es # 1.运行ES容器 指定jvm内存大小并指定ik分词器位置 docker run -d --name es -p 9200:9200 -p 9300:9300 -e ES_JAVA_OPTS=\"-Xms128m -Xmx128m\" -v /root/es/plugins:/usr/share/elasticsearch/plugins -v /root/es/data:/usr/share/elasticsearch/data elasticsearch:6.4.2 3.安装IK分词器 # 1.下载对应版本的IK分词器 wget https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v6.4.2/elasticsearch-analysis-ik-6.4.2.zip # 2.解压到plugins文件夹中 yum install -y unzip unzip -d ik elasticsearch-analysis-ik-6.4.2.zip # 3.添加自定义扩展词和停用词 cd plugins/elasticsearch/config vim IKAnalyzer.cfg.xml \u003cproperties\u003e \u003ccomment\u003eIK Analyzer 扩展配置\u003c/comment\u003e \u003c!--用户可以在这里配置自己的扩展字典 --\u003e \u003centry key=\"ext_dict\"\u003eext_dict.dic\u003c/entry\u003e \u003c!--用户可以在这里配置自己的扩展停止词字典--\u003e \u003centry key=\"ext_stopwords\"\u003eext_stopwords.dic\u003c/entry\u003e \u003c/properties\u003e # 4.在ik分词器目录下config目录中创建ext_dict.dic文件 编码一定要为UTF-8才能生效 vim ext_dict.dic 加入扩展词即可 # 5. 在ik分词器目录下config目录中创建ext_stopword.dic文件 vim ext_stopwords.dic 加入停用词即可 # 6.重启容器生效 docker restart 容器id # 7.将此容器提交成为一个新的镜像 docker commit -a=\"xiaochen\" -m=\"es with IKAnalyzer\" 容器id xiaochen/elasticsearch:6.4.2 4. 安装Kibana # 1.下载kibana镜像到本地 docker pull kibana:6.4.2 # 2.启动kibana容器 docker run -d --name kibana -e ELASTICSEARCH_URL=http://10.15.0.3:9200 -p 5601:5601 kibana:6.4.2 10.Docker中出现如下错误解决方案 [root@localhost ~]# docker search mysql 或者 docker pull 这些命令无法使用 Error response from daemon: Get https://index.docker.io/v1/search?q=mysql\u0026n=25: x509: certificate has expired or is not yet valid 注意:这个错误的原因在于是系统的时间和docker hub时间不一致,需要做系统时间与网络时间同步 # 1.安装时间同步 sudo yum -y install ntp ntpdate # 2.同步时间 sudo ntpdate cn.pool.ntp.org # 3.查看本机时间 date # 4.从新测试 9.Dockerfile 9.1 什么是Dockerfile Dockerfile可以认为是Docker镜像的描述文件，是由一系列命令和参数构成的脚本。主要作用是用来构建docker镜像的构建文件。\n通过架构图可以看出通过DockerFile可以直接构建镜像 9.2 Dockerfile解析过程 9.3 Dockerfile的保留命令 官方说明:https://docs.docker.com/engine/reference/builder/\n保留字\n作用\nFROM\n当前镜像是基于哪个镜像的 第一个指令必须是FROM\nMAINTAINER\n镜像维护者的姓名和邮箱地址\nRUN\n构建镜像时需要运行的指令\nEXPOSE\n当前容器对外暴露出的端口号\nWORKDIR\n指定在创建容器后，终端默认登录进来的工作目录，一个落脚点\nENV\n用来在构建镜像过程中设置环境变量\nADD\n将宿主机目录下的文件拷贝进镜像且ADD命令会自动处理URL和解压tar包\nCOPY\n类似于ADD，拷贝文件和目录到镜像中\n将从构建上下文目录中\u003c原路径\u003e的文件/目录复制到新的一层的镜像内的\u003c目标路径\u003e位置\nVOLUME\n容器数据卷，用于数据保存和持久化工作\nCMD\n指定一个容器启动时要运行的命令\nDockerfile中可以有多个CMD指令，但只有最后一个生效，CMD会被docker run之后的参数替换\nENTRYPOINT\n指定一个容器启动时要运行的命令\nENTRYPOINT的目的和CMD一样，都是在指定容器启动程序及其参数\n9.3.1 FROM 命令 基于那个镜像进行构建新的镜像,在构建时会自动从docker hub拉取base镜像 必须作为Dockerfile的第一个指令出现\n语法:\nFROM \u003cimage\u003e FROM \u003cimage\u003e[:\u003ctag\u003e] 使用版本不写为latest FROM \u003cimage\u003e[@\u003cdigest\u003e] 使用摘要 9.3.2 MAINTAINER 命令 镜像维护者的姓名和邮箱地址[废弃]\n语法:\nMAINTAINER \u003cname\u003e 9.3.3 RUN 命令 RUN指令将在当前映像之上的新层中执行任何命令并提交结果。生成的提交映像将用于Dockerfile中的下一步\n语法:\nRUN \u003ccommand\u003e (shell form, the command is run in a shell, which by default is /bin/sh -c on Linux or cmd /S /C on Windows) RUN echo hello RUN [\"executable\", \"param1\", \"param2\"] (exec form) RUN [\"/bin/bash\", \"-c\", \"echo hello\"] 9.3.4 EXPOSE 命令 用来指定构建的镜像在运行为容器时对外暴露的端口\n语法:\nEXPOSE 80/tcp 如果没有显示指定则默认暴露都是tcp EXPOSE 80/udp 9.3.5 CMD 命令 用来为启动的容器指定执行的命令,在Dockerfile中只能有一条CMD指令。如果列出多个命令，则只有最后一个命令才会生效。\n注意: Dockerfile中只能有一条CMD指令。如果列出多个命令，则只有最后一个命令才会生效。\n语法:\nCMD [\"executable\",\"param1\",\"param2\"] (exec form, this is the preferred form) CMD [\"param1\",\"param2\"] (as default parameters to ENTRYPOINT) CMD command param1 param2 (shell form) 9.3.6 WORKDIR 命令 用来为Dockerfile中的任何RUN、CMD、ENTRYPOINT、COPY和ADD指令设置工作目录。如果WORKDIR不存在，即使它没有在任何后续Dockerfile指令中使用，它也将被创建。\n语法:\nWORKDIR /path/to/workdir WORKDIR /a WORKDIR b WORKDIR c `注意:WORKDIR指令可以在Dockerfile中多次使用。如果提供了相对路径，则该路径将与先前WORKDIR指令的路径相对` 9.3.7 ENV 命令 用来为构建镜像设置环境变量。这个值将出现在构建阶段中所有后续指令的环境中。\n语法：\nENV \u003ckey\u003e \u003cvalue\u003e ENV \u003ckey\u003e=\u003cvalue\u003e ... 9.3.8 ADD 命令 用来从context上下文复制新文件、目录或远程文件url，并将它们添加到位于指定路径的映像文件系统中。\n语法:\nADD hom* /mydir/ 通配符添加多个文件 ADD hom?.txt /mydir/ 通配符添加 ADD test.txt relativeDir/ 可以指定相对路径 ADD test.txt /absoluteDir/ 也可以指定绝对路径 ADD url 9.3.9 COPY 命令 用来将context目录中指定文件复制到镜像的指定目录中\n语法:\nCOPY src dest COPY [\"\u003csrc\u003e\",... \"\u003cdest\u003e\"] 9.3.10 VOLUME 命令 用来定义容器运行时可以挂在到宿主机的目录\n语法:\nVOLUME [\"/data\"] 9.3.11 ENTRYPOINT命令 用来指定容器启动时执行命令和CMD类似\n语法:\n[\"executable\", \"param1\", \"param2\"] ENTRYPOINT command param1 param2 ENTRYPOINT指令，往往用于设置容器启动后的第一个命令，这对一个容器来说往往是固定的。 CMD指令，往往用于设置容器启动的第一个命令的默认参数，这对一个容器来说可以是变化的。\n9.3.11 ENTRYPOINT命令 9.4 Dockerfile构建springboot项目部署 1.准备springboot可运行项目 2.将可运行项目放入linux虚拟机中 3.编写Dockerfile FROM openjdk:8 WORKDIR /ems ADD ems.jar /ems EXPOSE 8989 ENTRYPOINT [\"java\",\"-jar\"] CMD [\"ems.jar\"] 4.构建镜像 [root@localhost ems]# docker build -t ems . 5.运行镜像 [root@localhost ems]# docker run -p 8989:8989 ems 6.访问项目 http://10.15.0.8:8989/ems/login.html 10.高级网络配置 10.1 说明 当 Docker 启动时，会自动在主机上创建一个 docker0 虚拟网桥，实际上是 Linux 的一个 bridge，可以理解为一个软件交换机。它会在挂载到它的网口之间进行转发。\n同时，Docker 随机分配一个本地未占用的私有网段（在 RFC1918 中定义）中的一个地址给 docker0 接口。比如典型的 172.17.42.1，掩码为 255.255.0.0。此后启动的容器内的网口也会自动分配一个同一网段（172.17.0.0/16）的地址。\n当创建一个 Docker 容器的时候，同时会创建了一对 veth pair 接口（当数据包发送到一个接口时，另外一个接口也可以收到相同的数据包）。这对接口一端在容器内，即 eth0；另一端在本地并被挂载到 docker0 网桥，名称以 veth 开头（例如 vethAQI2QT）。通过这种方式，主机可以跟容器通信，容器之间也可以相互通信。Docker 就创建了在主机和所有容器之间一个虚拟共享网络。\n10.2 查看网络信息 # docker network ls 10.3 创建一个网桥 # docker network create -d bridge 网桥名称 10.4 删除一个网桥 # docker network rm 网桥名称 10.5 容器之前使用网络通信 # 1.查询当前网络配置 - docker network ls NETWORK ID NAME DRIVER SCOPE 8e424e5936b7 bridge bridge local 17d974db02da docker_gwbridge bridge local d6c326e433f7 host host local # 2.创建桥接网络 - docker network create -d bridge info [root@centos ~]# docker network create -d bridge info 6e4aaebff79b1df43a064e0e8fdab08f52d64ce34db78dd5184ce7aaaf550a2f [root@centos ~]# docker network ls NETWORK ID NAME DRIVER SCOPE 8e424e5936b7 bridge bridge local 17d974db02da docker_gwbridge bridge local d6c326e433f7 host host local 6e4aaebff79b info bridge local # 3.启动容器指定使用网桥 - docker run -d -p 8890:80 --name nginx001 --network info nginx - docker run -d -p 8891:80 --name nginx002 --network info nginx `注意:一旦指定网桥后--name指定名字就是主机名,多个容器指定在同一个网桥时,可以在任意一个容器中使用主机名与容器进行互通` [root@centos ~]# docker run -d -p 8890:80 --name nginx001 --network info nginx c315bcc94e9ddaa36eb6c6f16ca51592b1ac8bf1ecfe9d8f01d892f3f10825fe [root@centos ~]# docker run -d -p 8891:80 --name nginx002 --network info nginx f8682db35dd7fb4395f90edb38df7cad71bbfaba71b6a4c6e2a3a525cb73c2a5 [root@centos ~]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES f8682db35dd7 nginx \"/docker-entrypoint.…\" 3 seconds ago Up 2 seconds 0.0.0.0:8891-\u003e80/tcp nginx002 c315bcc94e9d nginx \"/docker-entrypoint.…\" 7 minutes ago Up 7 minutes 0.0.0.0:8890-\u003e80/tcp nginx001 b63169d43792 mysql:5.7.19 \"docker-entrypoint.s…\" 7 minutes ago Up 7 minutes 3306/tcp mysql_mysql.1.s75qe5kkpwwttyf0wrjvd2cda [root@centos ~]# docker exec -it f8682db35dd7 /bin/bash root@f8682db35dd7:/# curl http://nginx001 \u003c!DOCTYPE html\u003e \u003chtml\u003e \u003chead\u003e \u003ctitle\u003eWelcome to nginx!\u003c/title\u003e ..... 11.高级数据卷配置 11.1 说明 数据卷 是一个可供一个或多个容器使用的特殊目录，它绕过 UFS，可以提供很多有用的特性：\n数据卷 可以在容器之间共享和重用 对 数据卷 的修改会立马生效 对 数据卷 的更新，不会影响镜像 数据卷 默认会一直存在，即使容器被删除 注意：数据卷 的使用，类似于 Linux 下对目录或文件进行 mount，镜像中的被指定为挂载点的目录中的文件会复制到数据卷中（仅数据卷为空时会复制）。\n11.2 创建数据卷 [root@centos ~]# docker volume create my-vol my-vol 11.3 查看数据卷 [root@centos ~]# docker volume inspect my-vol [ { \"CreatedAt\": \"2020-11-25T11:43:56+08:00\", \"Driver\": \"local\", \"Labels\": {}, \"Mountpoint\": \"/var/lib/docker/volumes/my-vol/_data\", \"Name\": \"my-vol\", \"Options\": {}, \"Scope\": \"local\" } ] 11.4 挂载数据卷 [root@centos ~]# docker run -d -P --name web -v my-vol:/usr/share/nginx/html nginx [root@centos ~]# docker inspect web \"Mounts\": [ { \"Type\": \"volume\", \"Name\": \"my-vol\", \"Source\": \"/var/lib/docker/volumes/my-vol/_data\", \"Destination\": \"/usr/share/nginx/html\", \"Driver\": \"local\", \"Mode\": \"z\", \"RW\": true, \"Propagation\": \"\" } ], 11.5 删除数据卷 docker volume rm my-vol 12.Docker Compose 12.1 简介 Compose 项目是 Docker 官方的开源项目，负责实现对 Docker 容器集群的快速编排。从功能上看，跟 OpenStack 中的 Heat 十分类似。\n其代码目前在 https://github.com/docker/compose 上开源。\nCompose 定位是 「定义和运行多个 Docker 容器的应用（Defining and running multi-container Docker applications）」，其前身是开源项目 Fig。\n通过第一部分中的介绍，我们知道使用一个 Dockerfile 模板文件，可以让用户很方便的定义一个单独的应用容器。然而，在日常工作中，经常会碰到需要多个容器相互配合来完成某项任务的情况。例如要实现一个 Web 项目，除了 Web 服务容器本身，往往还需要再加上后端的数据库服务容器，甚至还包括负载均衡容器等。\nCompose 恰好满足了这样的需求。它允许用户通过一个单独的 docker-compose.yml 模板文件（YAML 格式）来定义一组相关联的应用容器为一个项目（project）。\nCompose 中有两个重要的概念：\n服务 (service)：一个应用的容器，实际上可以包括若干运行相同镜像的容器实例。 项目 (project)：由一组关联的应用容器组成的一个完整业务单元，在 docker-compose.yml 文件中定义。 Compose 的默认管理对象是项目，通过子命令对项目中的一组容器进行便捷地生命周期管理。\nCompose 项目由 Python 编写，实现上调用了 Docker 服务提供的 API 来对容器进行管理。因此，只要所操作的平台支持 Docker API，就可以在其上利用 Compose 来进行编排管理。\n12.2 安装与卸载 1.linux 在 Linux 上的也安装十分简单，从 官方 GitHub Release 处直接下载编译好的二进制文件即可。例如，在 Linux 64 位系统上直接下载对应的二进制包。 $ sudo curl -L https://github.com/docker/compose/releases/download/1.25.5/docker-compose-`uname -s`-`uname -m` \u003e /usr/local/bin/docker-compose $ sudo chmod +x /usr/local/bin/docker-compose 2.macos、window Compose 可以通过 Python 的包管理工具 pip 进行安装，也可以直接下载编译好的二进制文件使用，甚至能够直接在 Docker 容器中运行。Docker Desktop for Mac/Windows 自带 docker-compose 二进制文件，安装 Docker 之后可以直接使用。 3.bash命令补全 $ curl -L https://raw.githubusercontent.com/docker/compose/1.25.5/contrib/completion/bash/docker-compose \u003e /etc/bash_completion.d/docker-compose 4.卸载 如果是二进制包方式安装的，删除二进制文件即可。 $ sudo rm /usr/local/bin/docker-compose 5.测试安装成功 $ docker-compose --version docker-compose version 1.25.5, build 4667896b 12.3 docker compose使用 # 1.相关概念 首先介绍几个术语。\n服务 (service)：一个应用容器，实际上可以运行多个相同镜像的实例。 项目 (project)：由一组关联的应用容器组成的一个完整业务单元。∂一个项目可以由多个服务（容器）关联而成，Compose 面向项目进行管理。 # 2.场景 最常见的项目是 web 网站，该项目应该包含 web 应用和缓存。\nspringboot应用 mysql服务 redis服务 elasticsearch服务 ……. # 3.docker-compose模板 - 参考文档:https://docker_practice.gitee.io/zh-cn/compose/compose_file.html version: \"3.0\" services: mysqldb: image: mysql:5.7.19 container_name: mysql ports: - \"3306:3306\" volumes: - /root/mysql/conf:/etc/mysql/conf.d - /root/mysql/logs:/logs - /root/mysql/data:/var/lib/mysql environment: MYSQL_ROOT_PASSWORD: root networks: - ems depends_on: - redis redis: image: redis:4.0.14 container_name: redis ports: - \"6379:6379\" networks: - ems volumes: - /root/redis/data:/data command: redis-server networks: ems: # 4.通过docker-compose运行一组容器 - 参考文档:https://docker_practice.gitee.io/zh-cn/compose/commands.html [root@centos ~]# docker-compose up //前台启动一组服务 [root@centos ~]# docker-compose up -d //后台启动一组服务 12.4 docker-compose 模板文件 模板文件是使用 Compose 的核心，涉及到的指令关键字也比较多。但大家不用担心，这里面大部分指令跟 docker run 相关参数的含义都是类似的。\n默认的模板文件名称为 docker-compose.yml，格式为 YAML 格式。\nversion: \"3\" services: webapp: image: examples/web ports: - \"80:80\" volumes: - \"/data\" 注意每个服务都必须通过 image 指令指定镜像或 build 指令（需要 Dockerfile）等来自动构建生成镜像。\n如果使用 build 指令，在 Dockerfile 中设置的选项(例如：CMD, EXPOSE, VOLUME, ENV 等) 将会自动被获取，无需在 docker-compose.yml 中重复设置。\n下面分别介绍各个指令的用法。\nbuild 指定 Dockerfile 所在文件夹的路径（可以是绝对路径，或者相对 docker-compose.yml 文件的路径）。 Compose 将会利用它自动构建这个镜像，然后使用这个镜像。\nversion: '3' services: webapp: build: ./dir 你也可以使用 context 指令指定 Dockerfile 所在文件夹的路径。\n使用 dockerfile 指令指定 Dockerfile 文件名。\n使用 arg 指令指定构建镜像时的变量。\nversion: '3' services: webapp: build: context: ./dir dockerfile: Dockerfile-alternate args: buildno: 1 command 覆盖容器启动后默认执行的命令。\ncommand: echo \"hello world\" container_name 指定容器名称。默认将会使用 项目名称_服务名称_序号 这样的格式。\ncontainer_name: docker-web-container 注意: 指定容器名称后，该服务将无法进行扩展（scale），因为 Docker 不允许多个容器具有相同的名称。\ndepends_on 解决容器的依赖、启动先后的问题。以下例子中会先启动 redis db 再启动 web\nversion: '3' services: web: build: . depends_on: - db - redis redis: image: redis db: image: postgres 注意：web 服务不会等待 redis db 「完全启动」之后才启动。\nenv_file 从文件中获取环境变量，可以为单独的文件路径或列表。\n如果通过 docker-compose -f FILE 方式来指定 Compose 模板文件，则 env_file 中变量的路径会基于模板文件路径。\n如果有变量名称与 environment 指令冲突，则按照惯例，以后者为准。\nenv_file: .env env_file: - ./common.env - ./apps/web.env - /opt/secrets.env 环境变量文件中每一行必须符合格式，支持 # 开头的注释行。\n# common.env: Set development environment PROG_ENV=development environment 设置环境变量。你可以使用数组或字典两种格式。\n只给定名称的变量会自动获取运行 Compose 主机上对应变量的值，可以用来防止泄露不必要的数据。\nenvironment: RACK_ENV: development SESSION_SECRET: environment: - RACK_ENV=development - SESSION_SECRET 如果变量名称或者值中用到 true|false，yes|no 等表达 布尔 含义的词汇，最好放到引号里，避免 YAML 自动解析某些内容为对应的布尔语义。这些特定词汇，包括\ny|Y|yes|Yes|YES|n|N|no|No|NO|true|True|TRUE|false|False|FALSE|on|On|ON|off|Off|OFF healthcheck 通过命令检查容器是否健康运行。\nhealthcheck: test: [\"CMD\", \"curl\", \"-f\", \"http://localhost\"] interval: 1m30s timeout: 10s retries: 3 image 指定为镜像名称或镜像 ID。如果镜像在本地不存在，Compose 将会尝试拉取这个镜像。\nimage: ubuntu image: orchardup/postgresql image: a4bc65fd networks 配置容器连接的网络。\nversion: \"3\" services: some-service: networks: - some-network - other-network networks: some-network: other-network: ports 暴露端口信息。\n使用宿主端口：容器端口 (HOST:CONTAINER) 格式，或者仅仅指定容器的端口（宿主将会随机选择端口）都可以。\nports: - \"3000\" - \"8000:8000\" - \"49100:22\" - \"127.0.0.1:8001:8001\" 注意：当使用 HOST:CONTAINER 格式来映射端口时，如果你使用的容器端口小于 60 并且没放到引号里，可能会得到错误结果，因为 YAML 会自动解析 xx:yy 这种数字格式为 60 进制。为避免出现这种问题，建议数字串都采用引号包括起来的字符串格式。\nsysctls 配置容器内核参数。\nsysctls: net.core.somaxconn: 1024 net.ipv4.tcp_syncookies: 0 sysctls: - net.core.somaxconn=1024 - net.ipv4.tcp_syncookies=0 ulimits 指定容器的 ulimits 限制值。\n例如，指定最大进程数为 65535，指定文件句柄数为 20000（软限制，应用可以随时修改，不能超过硬限制） 和 40000（系统硬限制，只能 root 用户提高）。\nulimits: nproc: 65535 nofile: soft: 20000 hard: 40000 volumes 数据卷所挂载路径设置。可以设置为宿主机路径(HOST:CONTAINER)或者数据卷名称(VOLUME:CONTAINER)，并且可以设置访问模式 （HOST:CONTAINER:ro）。\n该指令中路径支持相对路径。\nvolumes: - /var/lib/mysql - cache/:/tmp/cache - ~/configs:/etc/configs/:ro 如果路径为数据卷名称，必须在文件中配置数据卷。\nversion: \"3\" services: my_src: image: mysql:8.0 volumes: - mysql_data:/var/lib/mysql volumes: mysql_data: 12.5 docker-compose 常用命令 1. 命令对象与格式 对于 Compose 来说，大部分命令的对象既可以是项目本身，也可以指定为项目中的服务或者容器。如果没有特别的说明，命令对象将是项目，这意味着项目中所有的服务都会受到命令影响。\n执行 docker-compose [COMMAND] --help 或者 docker-compose help [COMMAND] 可以查看具体某个命令的使用格式。\ndocker-compose 命令的基本的使用格式是\ndocker-compose [-f=\u003carg\u003e...] [options] [COMMAND] [ARGS...] 2. 命令选项 -f, --file FILE 指定使用的 Compose 模板文件，默认为 docker-compose.yml，可以多次指定。 -p, --project-name NAME 指定项目名称，默认将使用所在目录名称作为项目名。 --x-networking 使用 Docker 的可拔插网络后端特性 --x-network-driver DRIVER 指定网络后端的驱动，默认为 bridge --verbose 输出更多调试信息。 -v, --version 打印版本并退出。 3.命令使用说明 up 格式为 docker-compose up [options] [SERVICE...]。\n该命令十分强大，它将尝试自动完成包括构建镜像，（重新）创建服务，启动服务，并关联服务相关容器的一系列操作。\n链接的服务都将会被自动启动，除非已经处于运行状态。\n可以说，大部分时候都可以直接通过该命令来启动一个项目。\n默认情况，docker-compose up 启动的容器都在前台，控制台将会同时打印所有容器的输出信息，可以很方便进行调试。\n当通过 Ctrl-C 停止命令时，所有容器将会停止。\n如果使用 docker-compose up -d，将会在后台启动并运行所有的容器。一般推荐生产环境下使用该选项。\n默认情况，如果服务容器已经存在，docker-compose up 将会尝试停止容器，然后重新创建（保持使用 volumes-from 挂载的卷），以保证新启动的服务匹配 docker-compose.yml 文件的最新内容\ndown 此命令将会停止 up 命令所启动的容器，并移除网络 exec 进入指定的容器。 ps 格式为 docker-compose ps [options] [SERVICE...]。\n列出项目中目前的所有容器。\n选项：\n-q 只打印容器的 ID 信息。 restart 格式为 docker-compose restart [options] [SERVICE...]。\n重启项目中的服务。\n选项：\n-t, --timeout TIMEOUT 指定重启前停止容器的超时（默认为 10 秒）。 rm 格式为 docker-compose rm [options] [SERVICE...]。\n删除所有（停止状态的）服务容器。推荐先执行 docker-compose stop 命令来停止容器。\n选项：\n-f, --force 强制直接删除，包括非停止状态的容器。一般尽量不要使用该选项。 -v 删除容器所挂载的数据卷。 start 格式为 docker-compose start [SERVICE...]。\n启动已经存在的服务容器。\nstop 格式为 docker-compose stop [options] [SERVICE...]。\n停止已经处于运行状态的容器，但不删除它。通过 docker-compose start 可以再次启动这些容器。\n选项：\n-t, --timeout TIMEOUT 停止容器时候的超时（默认为 10 秒）。 top 查看各个服务容器内运行的进程。\nunpause 格式为 docker-compose unpause [SERVICE...]。\n恢复处于暂停状态中的服务。\n13.docker可视化工具 13.1 安装Portainer 官方安装说明：https://www.portainer.io/installation/\n[root@ubuntu1804 ~]#docker pull portainer/portainer [root@ubuntu1804 ~]#docker volume create portainer_data portainer_data [root@ubuntu1804 ~]#docker run -d -p 8000:8000 -p 9000:9000 --name=portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer 20db26b67b791648c2ef6aee444a5226a9c897ebcf0160050e722dbf4a4906e3 [root@ubuntu1804 ~]#docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 20db26b67b79 portainer/portainer \"/portainer\" 5 seconds ago Up 4 seconds 0.0.0.0:8000-\u003e8000/tcp, 0.0.0.0:9000-\u003e9000/tcp portainer 13.2 登录和使用Portainer 用浏览器访问：http://localhost:9000\n",
    "description": "",
    "tags": null,
    "title": "docker基础知识",
    "uri": "/dockerk8s/docker%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"
  },
  {
    "content": "镜像加速： 我自己的阿里云镜像仓库：\n",
    "description": "",
    "tags": null,
    "title": "docker设置",
    "uri": "/dockerk8s/docker%E8%AE%BE%E7%BD%AE/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "dubbo",
    "uri": "/%E5%88%86%E5%B8%83%E5%BC%8F/dubbo/"
  },
  {
    "content": " 官方使用文档：https://www.elastic.co/guide/en/elasticsearch/reference/7.17/cat-indices.html\n",
    "description": "",
    "tags": null,
    "title": "es介绍",
    "uri": "/%E4%B8%AD%E9%97%B4%E4%BB%B6/elasticsearch/es%E4%BB%8B%E7%BB%8D/"
  },
  {
    "content": "统计字符出现个数 =LEN(G13)-LEN(SUBSTITUTE(G13,\"、\",\"\"))+1\n",
    "description": "",
    "tags": null,
    "title": "excel公式",
    "uri": "/office/excel%E5%85%AC%E5%BC%8F/"
  },
  {
    "content": "Future模式和Callable模式 创建线程的方式只有两种：继承Thread或者实现Runnable接口。 但是这两种方法都存在一个缺陷，没有返回值，也就是说我们无法得知线程执行结果。虽然简单场景下已经满足，但是当我们需要返回值的时候怎么办呢？ Java 1.5 以后的Callable和Future接口就解决了这个问题，我们可以通过向线程池提交一个Callable来获取一个包含返回值的Future对象，从此，我们的程序逻辑就不再是同步顺序。\n上图中，A为Callable模式、B为Future模式。当然他们并不是互斥的，Future通常使用的时候要配置Callable。\nFuture相关 Future接口： cancel（boolean） 暂停任务，参数为true则如果任务已经拿到线程开始执行了，仍然可以中断Interrupt任务。 isCanncelled()配合cancel（boolean） isDone() 任务是否已经结束，如果被cancel 则返回True。 get() throws InterruptedException, ExecutionException;同步等待获取任务结果 get(long,TimeUinit) throws InterruptedException, ExecutionException, TimeoutException;设置同步等待时间，如果超时返回TimeoutException。 Future的实现类之一 ：FutureTask 类图：\n简单使用一下：\nFutureTask\u003cString\u003e future = new FutureTask\u003c\u003e(() -\u003e \"run a task\"); Executors.newSingleThreadExecutor().execute(future); System.out.println(\"futureResult: \" + future.get()); Future的局限性 从本质上说，Future表示一个异步计算的结果。它提供了isDone()来检测计算是否已经完成， 并且在计算结束后，可以通过get()方法来获取计算结果。在异步计算中，Future确实是个非常 优秀的接口。但是，它的本身也确实存在着许多限制：\n并发执行多任务：Future只提供了get()方法来获取结果，并且是阻塞的。所以，除 了等待你别无他法； 无法对多个任务进行链式调用：如果你希望在计算任务完成后执行特定动作，比如 发邮件，但Future却没有提供这样的能力； 无法组合多个任务：如果你运行了10个任务，并期望在它们全部执行结束后执行特 定动作，那么在Future中这是无能为力的； 没有异常处理：Future接口中没有关于异常处理的方法； CompletableFuture 完善的Future Future并不完善，所以在后续版本中又推出了CompletableFuture，客服了Future的局限。\n常用API 来个例子 著名数学家华罗庚先生在《统筹方法》这篇文章里介绍了一个烧水泡茶的例子，文中提到最优的工序应该是下面这样：\n对于烧水泡茶这个程序，一种最优的分工方案：用两个线程 T1 和 T2 来完成烧水泡茶程序，T1 负责洗水壶、烧开水、泡茶这三道工序，T2 负责洗茶壶、洗茶杯、拿茶叶三道工序，其中 T1 在执行泡茶这道工序时需要等待 T2 完成拿茶叶的工序。\n基于Future实现\npublic class FutureTaskDemo3{ public static void main(String[] args) throws ExecutionException, InterruptedException { // 创建任务T2的FutureTask FutureTask\u003cString\u003e ft2 = new FutureTask\u003c\u003e(new T2Task()); // 创建任务T1的FutureTask FutureTask\u003cString\u003e ft1 = new FutureTask\u003c\u003e(new T1Task(ft2)); // 线程T1执行任务ft1 Thread T1 = new Thread(ft1); T1.start(); // 线程T2执行任务ft2 Thread T2 = new Thread(ft2); T2.start(); // 等待线程T1执行结果 System.out.println(ft1.get()); } } // T1Task需要执行的任务： // 洗水壶、烧开水、泡茶 class T1Task implements Callable\u003cString\u003e { FutureTask\u003cString\u003e ft2; // T1任务需要T2任务的FutureTask T1Task(FutureTask\u003cString\u003e ft2){ this.ft2 = ft2; } @Override public String call() throws Exception { System.out.println(\"T1:洗水壶...\"); TimeUnit.SECONDS.sleep(1); System.out.println(\"T1:烧开水...\"); TimeUnit.SECONDS.sleep(15); // 获取T2线程的茶叶 String tf = ft2.get(); System.out.println(\"T1:拿到茶叶:\"+tf); System.out.println(\"T1:泡茶...\"); return \"上茶:\" + tf; } } 基于CompletableFuture实现\npublic class CompletableFutureDemo2 { public static void main(String[] args) { //任务1：洗水壶-\u003e烧开水 CompletableFuture\u003cVoid\u003e f1 = CompletableFuture .runAsync(() -\u003e { System.out.println(\"T1:洗水壶...\"); sleep(1, TimeUnit.SECONDS); System.out.println(\"T1:烧开水...\"); sleep(15, TimeUnit.SECONDS); }); //任务2：洗茶壶-\u003e洗茶杯-\u003e拿茶叶 CompletableFuture\u003cString\u003e f2 = CompletableFuture .supplyAsync(() -\u003e { System.out.println(\"T2:洗茶壶...\"); sleep(1, TimeUnit.SECONDS); System.out.println(\"T2:洗茶杯...\"); sleep(2, TimeUnit.SECONDS); System.out.println(\"T2:拿茶叶...\"); sleep(1, TimeUnit.SECONDS); return \"龙井\"; }); //任务3：任务1和任务2完成后执行：泡茶 CompletableFuture\u003cString\u003e f3 = f1.thenCombine(f2, (__, tf) -\u003e { System.out.println(\"T1:拿到茶叶:\" + tf); System.out.println(\"T1:泡茶...\"); return \"上茶:\" + tf; }); //等待任务3执行结果 System.out.println(f3.join()); //当然这里也可以 CompletableFuture.allOf(f1,f2).join(); System.out.println(\"拿到茶叶:\" + tf); System.out.println(\"泡茶...\"); } ",
    "description": "",
    "tags": null,
    "title": "Future、CompletableFuture",
    "uri": "/java/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/futurecompletablefuture/"
  },
  {
    "content": "开启GC日志 打开gc日志：-XX:+PrintGCDetails 指定输入位置：-Xloggc:$LOGS_DIR/gc.log\n分析日志 GC (Allocation Failure)造成的young gc。\ngc日志头 解释 GC (Allocation Failure) Allocation Failure表示向young generation(eden)给新对象申请空间，但是young generation(eden)剩余的合适空间不够所需的大小导致的minor gc。 Full GC (Ergonomics) 默认使用 UseParallelGC 垃圾回收器，该垃圾回收器默认启动了 AdaptiveSizePolicy。 ",
    "description": "",
    "tags": null,
    "title": "gc日志分析",
    "uri": "/java/jvm/gc%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90/"
  },
  {
    "content": "命令 命令 参数 描述 示例 checkout -b 检出一个新分支 checkout - 切换到上一个分支 branch -m 重命名分支 git branch -m 原始名称 新名称 branch -u –set-upstream 设置当前分支对应的远程分支 git branch -u origin/dev branch –unset-upstream 反向操作 git branch –unset-upstream push -f 强制本地分支推送远程分支 push -u –set-upstream push 并且 设置当前分支对应的远程分支 git branch –unset-upstream origin [分支名] rebase 把一个分支整合到另一个分支的办法有两种：merge（合并） 和 rebase（衍合）。 rebase相当于在fetch之后，重新提交数据。 千万不要在在public分支操作rebase，例如develop，不要用rebase合并自己的feature分支。 有一篇很好的文章讲merge和rebase https://www.atlassian.com/git/tutorials/merging-vs-rebasing#the-golden-rule-of-rebasing\ngit工作流程 git flow 配置 ignore 注视 folder 同名的 folder 目录、src/folder 文件、src/utils/folder 文件都会被忽略，即：不会被提交到远程仓库中。 folder/ 只忽略文件夹 ! 表示取反，不忽略xxx 通配符 星号“*” ：匹配多个字符； 双星号“**” ：匹配多个字符； 问号“?”：匹配除 ‘/’外的任意一个字符； 方括号“[xxxx]”：匹配多个列表中的字符； ",
    "description": "",
    "tags": null,
    "title": "git",
    "uri": "/%E5%B7%A5%E5%85%B7/git/"
  },
  {
    "content": "https://docs.jboss.org/hibernate/validator/6.2/reference/en-US/html_single/#validator-gettingstarted\n",
    "description": "",
    "tags": null,
    "title": "hibernate-validator 校验器",
    "uri": "/java/lib/hibernate-validator-%E6%A0%A1%E9%AA%8C%E5%99%A8/"
  },
  {
    "content": "Cookie \u0026 Session cookie的属性 HttpOnly: 如果您在cookie中设置了HttpOnly属性，那么通过js脚本将无法读取到cookie信息，这样能有效的防止[[XSS跨站脚本攻击]] path：对应url的作用域，默认是当前路径 ex：/a/b 默认是/a max-age：指定的是从文档被访问后的存活时间，这个时间是个相对值(比如:3600s),相对的是文档第一次被请求时服务器记录的Request_time(请求时间) Expires：指定的时间可以是相对文件的最后访问时间(Atime)或者修改时间(MTime),而max-age相对对的是文档的请求时间(Atime)\n删除cookie 把cookie的过期时间设为0或者过去\n",
    "description": "",
    "tags": null,
    "title": "HTTP",
    "uri": "/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/http/"
  },
  {
    "content": "X.509 是证书的标准格式。 x509是一个证书格式，证书的版本信息包含有：\n证书的序列号，每个证书都有一个唯一的证书序列号；\n证书所使用的签名算法；\n证书的发行机构名称，命名规则一般采用X.500格式；\n证书的有效期，现在通用的证书一般采用UTC时间格式，它的计时范围为1950-2049;\n证书所有人的名称，命名规则一般采用X.500格式；\n证书所有人的公开密钥；\n证书发行者对证书的签名。\nX.509文件格式\nCer/crt用于保存证书，并以没有私钥的二进制数存储。\npem和cer/crt区别是它以Ascii来表示，可以用于存放证书或者私钥。\npfx/p12用于存放个人证书/私钥。通常包含保护密码，2进制方式。\np10是证书请求。\np7r是CA对证书请求的回复，只用于导入。\np7b以树状展示证书链，同时支持单个证书，不含私钥。\n",
    "description": "",
    "tags": null,
    "title": "HTTPS",
    "uri": "/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/https/"
  },
  {
    "content": "编译大项目gc over limit 调整堆大小 keymap key note ctrl+space 代码补全 ",
    "description": "",
    "tags": null,
    "title": "idea",
    "uri": "/%E5%B7%A5%E5%85%B7/idea/"
  },
  {
    "content": "TCP 建立连接 断开连接 报文内容 SYN(synchronous建立联机)\nACK(acknowledgement 确认)\nPSH(push传送)\nFIN(finish结束)\nRST(reset重置)\nURG(urgent紧急)\n每个请求都有一个顺序号 Sequence number(顺序号码)\nlinux IO TCP网络通信整体流程 服务端准备连接流程 SOCKET函数 为了执行网络I/O，我们要做的第一件事情就是调用socket函数，指定期望的协议类型。该函数会创建一个通信的端点，并返回引用该端点的文件描述符，该文件描述符也称为套接字描述符(socket descriptor)，简称sockfd。\nBIND()函数 bind()函数把一个本地协议地址赋予一个套接字。\n如果一个TCP客户端或者服务器没有调用bind绑定端口，或者指定IP地址，那么内核就会为该套接字选择一个临时端口号。\nLISTEN()函数 通过socket()函数创建了套接字之后，再执行listen()函数，会把套接字转换为一个被动套接字，指示内核应该接收指向该套接字的连接请求，并导致套接字从CLOSED状态转换到LISTEN状态。\n在客户端请求服务器之后，服务器内核会把请求套接字放入到未完成队列中： 如下图：\n服务器接收到客户端SYN请求后，于是请求套接字进入未完成连接队列，等到服务端响应了ACK和SYN完成三次握手后，于是，套接字进入已完成连接队列。已完成连接队列中的套接字可以被服务器进程执行accept函数获取到。\nACCEPT()函数 服务器一旦执行了socket()、bind()、listen()函数之后，就表示已经初始化好了监听套接字，并且把自己变为了被动套接字，等待客户端的请求。这个时候，我们需要继续调用accept()函数，让服务器进入阻塞等待获取客户端的已连接套接字。\n当进程调用accept()时，已完成连接队列中的队头将返回给进程，或者如果队列为空，那么进程将被投入睡眠，直到TCP在该队列中放入一项才唤醒它。\n在调用accept()之后，阻塞等待客户连接到达，然后获取一个已连接套接字：\n关于监听套接字和已连接套接字\n注意，这里要区分好服务端的监听套接字和已连接套接字，服务端调用socket()返回的是监听套接字，bind()和listen()函数入参也是监听套接字。\n一旦有客户端请求过来了于是产生了一个已连接套接字，后续和客户端的交互是通过这个已连接套接字进行的。监听套接字只负责监听客户端请求并获取和客户端的已连接套接字。\n客户端发起连接流程 CONNECT()函数 connect()函数由客户端调用，请求与服务端建立连接，这个函数会触发三次握手。大致流程如下：\n客户端： connect调用是的当前套接字从CLOSED状态进入SYN_SENT状态，如果节而受到了服务器的SYN+ACK响应，则转移到ESTABLISHED状态； 如果connect失败，则表示套接字不在可用，必须关闭，不能再次尝试调用connect函数； 服务端： 每当接收到SYN时，TCP在未完成连接队列中创建一个新的条目，然后响应TCP三次握手的第二个分节； 每当收到三次握手的第三个分节的时候，就把条目从未完成队列移到已完成连接队列的队尾。此时，服务端accept调用将被唤醒并得到一个已连接套接字。 注意：客户在调用connect函数之前，不是一定要调用bind函数，这个时候内核会确定源IP地址，并选择一个临时端口号作为源端口号。\n所以大家在监控TCP连接的时候，可以发现请求客户端的端口都是没有什么规律的。因为这个端口号是临时端口号。\n当服务器队列满了，有新的客户端connect请求的SYN到达时怎么办？\n这个时候，TCP会忽略这个SYN分节，也不会向客户端发送RST，好让客户TCP有机会重发SYN，以便在不久之后可以在这些队列中找到可用的空间。\n如果直接响应RST，客户的connect()调用会立刻返回错误，导致应用进程必须要处理这种情况。\n因为从服务端的角度来看，经理一个RTT之后，TCP条目就会从未完成队列移动到已完成连接队列。所以，未完成连接队列中的任何一项的存留时间是一个RTT。\n一旦connect()成功之后，客户端和服务器就可以通过数据交换相关函数进行数据交换了。\n整体流程 概念说明 1. 内核态（内核空间）和用户态（用户空间）的区别和联系？ 用户空间是用户进程所在的内存区域，系统空间是操作系统所在的内存区域。 为了保证内核的安全，处于用户态的程序只能访问用户空间，而处于内核态的程序可以访问用户空间和内核空间。 2. 文件描述符fd Linux将所有设备都当做文件来处理，文件描述符来标识每个文件对象。 当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。 3. 缓存IO Linux的缓存IO机制中，操作系统会将IO的数据缓存在文件系统的页缓存中，也就是说，数据会先被拷贝到操作系统内核的缓冲区，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。\n涉及系统调用 recvfrom： 从socket读取数据\nselect： select() allow a program to monitor multiple file descriptors, waiting until one or more of the file descriptors become “ready” for some class of I/O operation select 监控多个io操作的文件描述符，直到一个或者多个文件描述符编程ready状态\npoll： 与select类似，链表实现的，没有上限限制\nepoll： epoll就是event poll ，基于事件驱动 主要用到三个函数调用： epoll_create：创建epoll对象 epoll_ctl：把文件描述符交给epoll对象监控 epoll_wait: waits for I/O events, blocking the calling thread if no events are currently available.\nIO模型 一般而言，一个输入操作，一般会经历如下处理过程：等待数据准备好，从内核复制到进程。这里的数据复制，一般是应用进程调用了某个IO方法之后，陷入系统调用，在内核态完成的。\nlinux系统产生了下面五种网络模式的方案：\n阻塞式I/O模型 如上图，在应用进程调用 recvfrom()之后，陷入内核态，直到数据报到达并且复制到应用进程缓冲区之后才返回到用户态。\n或者在系统调用期间发生错误，也会立刻返回。\n这种I/O称为阻塞I/O。\n非阻塞式I/O模型 如上图，当我们把套接字设置为非阻塞模式的时候，内核会这样处理I/O操作：当请求的I/O操作非得把本进程投入睡眠才能完成时，就不要投入睡眠，而是返回一个错误，在上面的例子中，调用recvfrom()之后，因为数据没有准备好，所以内核直接返回一个EWOULDBLOCK错误，直到数据准备好了，才复制数据到进程空间，并返回系统调用继续处理进程逻辑。\n而应用进程会不断循环调用recvfrom()函数，这种处理方式我们称为polling(轮训)，持续到轮训内核，查看数据是否准备好。这种方式的缺点是会消耗大量的CPU时间。\n注意：当recvfrom发起系统调用发现数据准备好了，将数据从内核复制到用户空间的时候，应用进程还是会被阻塞，只不过不会阻塞在等待数据准备好这个流程，从而减少了阻塞时间。\n这种轮训对于单进程或者单线程的程序特别有用。\nI/O复用模型 I/O复用(I/O multiplexing)，指的是通过一个支持同时感知多个描述符的函数系统调用，阻塞在这个系统调用上，等待某一个或者几个描述符准备就绪，就返回可读条件。常见的如select，poll，epoll系统调用可以实现此类功能功能。这种模型不用阻塞在真正的I/O系统调用上。\n工作原理如下图所示：\n如上图，这种模型与非阻塞式I/O相比，把轮训判断数据是否准备好的处理方式替换为了通过select()系统调用的方式来实现。\n**select()是实现I/O多路复用的经典系统调用函数。**select()可以同时等待多个套接字的变为可读，只要有任意一个套接字可读，那么就会立刻返回，处理已经准备好的套接字了。\n在多线中使用阻塞I/O，即每个文件描述符一个线程，与I/O复用模型很类似，每个线程可以自由调用阻塞式I/O系统调用。\n信号驱动式I/O模型 所谓信号驱动式I/O(signal-driven I/O)，就是指在描述符准备就绪的时候，让内核发送一个SIGIO信号通知应用进程进行后续的数据读取等处理。工作原理如下图所示：\n注册了SIGIO信号处理函数，开启了信号驱动式IO之后，就可以继续执行程序了，等到数据报准备好之后，内核会发送一个SIGIO信号给应用进程，然后应用进程在信号处理函数中调用recvfrom读取数据报。\n这种模型在内核等待数据报达到期间进程不会被阻塞，可以继续执行。\n异步I/O模型 可以发现，上面所有的I/O模型都会在某一个执行点阻塞，并不是真正的异步的。接下来我们就介绍下真正的异步I/O模型(asynchronous I/O)。如下图：\n通过异步处理函数如aio_read告知内核启动某个动作，并且让内核在整个操作完成之后再通知应用进程，内核会在把数据复制到用户空间缓冲区之后再进行通知。整个IO过程应用进程都不会被阻塞。\n五种I/O模型对比 下面我们通过一个表格来总结下这五种I/O模型 下面是执行流程的对比图：\n可以很清晰的看到各种I/O模型的不同表现。\nIO多路复用 「多路复用」原常用于通讯，多个线路通过复用器共用一个高速线路，以此来减少线路的使用。 所以「IO多路复用」，也是一个类似的概念，通过一个线程来实现多个io流的管理，但是这里只是管理，具体读写还是具体线程实现的。\n",
    "description": "",
    "tags": null,
    "title": "IO相关",
    "uri": "/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/io%E7%9B%B8%E5%85%B3/"
  },
  {
    "content": "redis 命令行客户端 https://gitee.com/mirrors/iredis#using-dsn\n",
    "description": "",
    "tags": null,
    "title": "iredis",
    "uri": "/%E5%B7%A5%E5%85%B7/iredis/"
  },
  {
    "content": "反序列化范型无效问题和解决 像下面的代码，反序列化回报错，\npublic void json(){ String json =\"{\\n\" + \" \\\"a\\\":{\\n\" + \" \\\"a\\\":\\\"b\\\"\\n\" + \" }\\n\" + \"}\"; ClazzA\u003cHosMapPhoneVO\u003e of = JsonUtil.of(json,ClazzA.class); of.getA().get(0).getForward(); System.out.println(of); } ",
    "description": "",
    "tags": null,
    "title": "jackson",
    "uri": "/java/lib/jackson/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "java启动参数",
    "uri": "/java/jvm/java%E5%90%AF%E5%8A%A8%E5%8F%82%E6%95%B0/"
  },
  {
    "content": "日志发展史 上古时代 jdk1.3之前 System.out.println(\"\") 问题： 没有日志级别，上线以后会有很多无关的日志，而且只能在控制台看，不方便定位。\n发展流程 log4j-\u003ejul-\u003ejcl-\u003eslf4j-\u003elog4j2-\u003elogback\nlog4j 作者ceki\n从控制台写到文件 日志信息按天和文件大小划分 划分日志等级，按日志等级记录文件 高等级日志发送邮件 异步io 格式控制\nlog4j发布以后，活的很好的反响，作者想让sun公司被纳入jdk，sun公司不接受，最后被apatch收纳。\njul jdk官方日志库 jul （java.util.logging） log4j火了以后，jdk官方自己开发了一个库jul，但是并没有被所有人 认可\nJCL 日志门面 jakarta（jdk内部的一个开发小组）Commons Logging jcl不实现日志功能，但是整合整合日志库\n依靠类加载器寻找日志库\nslf4j ceki发现JCL不好用，apache也不着急开发日志门面，自己出去单独搞了slf4j\n桥接器：slf4j 和日志框架直接 连接的工具 适配器：多个模块使用不同的日志门面和日志框架，可以别的日志框架转换到slf4j上\nlog4j2 apache 重写log4j，性能升级\nlogback ceki 也知道log4j性能问题，开发了替代log4j的高性能产品\n",
    "description": "",
    "tags": null,
    "title": "java日志",
    "uri": "/%E6%9D%82%E9%A1%B9/java%E6%97%A5%E5%BF%97/"
  },
  {
    "content": "强引用(FinalReference)： 普通引用 JVM停止运行时终止 软引用(SoftReference)： 在类似于浏览器访问页面缓存的场景，比如点击回退，如果缓存了页面就直接展示，缓存被清除了再加载也没事。 内存不足时终止 弱引用(WeakReference)： gc运行后终止 ThreadLocalMap的key，为了减少内存泄漏，在对象只有虚引用的时候，gc了就被清除了。 虚引用(PhantomReference)： 任何时候都可能\n",
    "description": "",
    "tags": null,
    "title": "java的引用类型",
    "uri": "/java/java%E7%9A%84%E5%BC%95%E7%94%A8%E7%B1%BB%E5%9E%8B/"
  },
  {
    "content": "G1 GC收集器 -XX:MaxGCPauseMillis 期望的最大GC暂停时间，默认为：200ms。 -XX:ParallelGCThreads 默认根据运行JVM计算机的可用线程数决定 -XX:G1NewSizePercent 新生代初大小，默认为：5%。 -XX:G1MaxNewSizePercent 新生代最大大小，默认为：60%。\n",
    "description": "",
    "tags": null,
    "title": "java程序的启动",
    "uri": "/java/jvm/java%E7%A8%8B%E5%BA%8F%E7%9A%84%E5%90%AF%E5%8A%A8/"
  },
  {
    "content": "bean shell ",
    "description": "",
    "tags": null,
    "title": "jmeter",
    "uri": "/%E5%B7%A5%E5%85%B7/jmeter/"
  },
  {
    "content": "Java Specification Requests Pluggable Annotation Processing API\n",
    "description": "",
    "tags": null,
    "title": "JSR",
    "uri": "/java/jsr/"
  },
  {
    "content": "查看程序中对象数量 jmap -histo pid |head -20\n",
    "description": "",
    "tags": null,
    "title": "jvm内存分析：",
    "uri": "/java/jvm/jvm%E5%86%85%E5%AD%98%E5%88%86%E6%9E%90/"
  },
  {
    "content": "![][https://note.youdao.com/yws/public/resource/e5863162eca29c2b31e8b59c9707817d/xmlnote/317C13052E514DA9B6229368DD48EDB5/105252]\nKafka核心总控制器Controller 在Kafka集群中会有一个或者多个broker，其中有一个broker会被选举为控制器(Kafka Controller)，它负责管理整个 集群中所有分区和副本的状态。\n当某个分区的leader副本出现故障时，由控制器负责为该分区选举新的leader副本。 当检测到某个分区的ISR集合发生变化时，由控制器负责通知所有broker更新其元数据信息。 当使用kafka-topics.sh脚本为某个topic增加分区数量时，同样还是由控制器负责让新分区被其他节点感知到。 Controller选举机制 在kafka集群启动的时候，会自动选举一台broker作为controller来管理整个集群，选举的过程是集群中每个broker都会 尝试在zookeeper上创建一个 /controller 临时节点，zookeeper会保证有且仅有一个broker能创建成功，这个broker就会成为集群的总控器controller。\n当这个controller角色的broker宕机了，此时zookeeper临时节点会消失，集群里其他broker会一直订阅这个临时节点，发现临时节点消失了，就竞争再次创建临时节点，就是我们上面说的选举机制，zookeeper又会保证有一个broker 成为新的controller。\n具备控制器身份的broker需要比其他普通的broker多一份职责，具体细节如下:\n监听broker相关的变化。为Zookeeper中的/brokers/ids/节点添加BrokerChangeListener，用来处理broker 增减的变化。\n监听topic相关的变化。为Zookeeper中的/brokers/topics节点添加TopicChangeListener，用来处理topic增减 的变化;为Zookeeper中的/admin/delete_topics节点添加TopicDeletionListener，用来处理删除topic的动作。\n从Zookeeper中读取获取当前所有与topic、partition以及broker有关的信息并进行相应的管理。对于所有topic 所对应的Zookeeper中的/brokers/topics/topic节点添加PartitionModificationsListener，用来监听topic中的 分区分配变化。\n更新集群的元数据信息，同步到其他普通的broker节点中。\nPartition副本选举Leader机制 controller感知到分区leader所在的broker挂了(controller监听了很多zk节点可以感知到broker存活)，controller会从 ISR列表(参数unclean.leader.election.enable=false的前提下)里挑第一个broker作为leader(第一个broker最先放进ISR 列表，可能是同步数据最多的副本)，如果参数unclean.leader.election.enable为true，代表在ISR列表里所有副本都挂 了的时候可以在ISR列表以外的副本中选leader，这种设置，可以提高可用性，但是选出的新leader有可能数据少很多。 副本进入ISR列表有两个条件:\n副本节点不能产生分区，必须能与zookeeper保持会话以及跟leader副本网络连通 副本能复制leader上的所有写操作，并且不能落后太多。(与leader副本同步滞后的副本，是由 replica.lag.time.max.ms 配置决定的，超过这个时间都没有跟leader同步过的一次的副本会被移出ISR列表) 消费者消费消息的offset记录机制 每个consumer会定期将自己消费分区的offset提交给kafka内部topic:__consumer_offsets，提交过去的时候，key是 consumerGroupId+topic+分区号，value就是当前offset的值，kafka会定期清理topic里的消息，最后就保留最新的 那条数据\n因为__consumer_offsets可能会接收高并发的请求，kafka默认给其分配50个分区(可以通过 offsets.topic.num.partitions设置)，这样可以通过加机器的方式抗大并发。\n消费者Rebalance机制 rebalance就是说如果消费组里的消费者数量有变化或消费的分区数有变化，kafka会重新分配消费者消费分区的关系。 比如consumer group中某个消费者挂了，此时会自动把分配给他的分区交给其他的消费者，如果他又重启了，那么又会 把一些分区重新交还给他。 注意:rebalance只针对subscribe这种不指定分区消费的情况，如果通过assign这种消费方式指定了分区，kafka不会进 行rebanlance。\n如下情况可能会触发消费者rebalance\n消费组里的consumer增加或减少了 2. 动态给topic增加了分区 消费组订阅了更多的topic rebalance过程中，消费者无法从kafka消费消息，这对kafka的TPS会有影响，如果kafka集群内节点较多，比如数百 个，那重平衡可能会耗时极多，所以应尽量避免在系统高峰期的重平衡发生。\nkafka在redis中存的内容 ",
    "description": "",
    "tags": null,
    "title": "kafka",
    "uri": "/%E4%B8%AD%E9%97%B4%E4%BB%B6/kafka/"
  },
  {
    "content": "LDAP是轻量目录访问协议,英文全称是Lightweight Directory Access Protocol,一般都简称为LDAP.\n现在市场上有关LDAP的产品已有很多,各大软件公司都在他们的产品中集成了LDAP服务,如Microsoft的ActiveDirectory、Lotus的Domino Directory、IBM的WebSphere中也集成了LDAP服务.LDAP的开源实现是OpenLDAP,它比商业产品一点也不差,而且源码开放.\nOpenLDAP是最常用的目录服务之一,它是一个由开源社区及志愿者开发和管理的一个开源项目,提供了目录服务的所有功能,包括目录搜索、身份认证、安全通道、过滤器等等.大多数的Linux发行版里面都带有OpenLDAP的安装包.OpenLDAP服务默认使用非加密的TCP/IP协议来接收服务的请求,并将查询结果传回到客户端.由于大多数目录服务都是用于系统的安全认证部分比如:用户登录和身份验证,所以它也支持使用基于 SSL/TLS 的加密协议来保证数据传送的保密性和完整性.OpenLDAP是使用OpenSSL来实现SSL/TLS加密通信的.\nLDAP的信息模型是建立在”条目”(entries)的基础上.一个条目是一些属性的集合,并且具有一个全局唯一的”可区分名称”DN,一个条目可以通过DN来引用.每一个条目的属性具有一个类型和一个或者多个值.类型通常是容易记忆的名称,比如”cn”是通用名称(common name),或者”mail”是电子邮件地址.条目的值的语法取决于属性类型.比如,cn属性可能具有一个值”Babs Jensen” .一个mail属性可能包含”bbs@example.com” .一个jpegphoto属性可能包含一幅JPEG(二进制)格式的图片.\nLDAP常用关键字列表 LDAP通过属性objectClass来控制哪一个属性必须出现或允许出现在一个条目中,它的值决定了该条目必须遵守的模式规则.\nEntry 条目,也叫记录项,是LDAP中最基本的颗粒,就像字典中的词条,或者是数据库中的记录.通常对LDAP的添加、删除、更改、检索都是以条目为基本对象的.\ndn:每一个条目都有一个唯一的标识名(distinguished Name,DN),如上述中一个 dn:”uid=mac,ou=People,dc=example,dc=cn”.通过DN的层次型语法结构,可以方便地表示出条目在LDAP树中的位置,通常用于检索. rdn:一般指dn逗号最左边的部分,如cn=baby.它与RootDN不同,RootDN通常与RootPW同时出现,特指管理LDAP中信息的最高权限用户. Base DN:LDAP目录树的最顶部就是根,也就是所谓的“Base DN”,如”dc=example,dc=com”. schema 对象类(ObjectClass)、属性类型(AttributeType)、语法(Syntax)分别约定了条目、属性、值,他们之间的关系如下图所示.所以这些构成了模式(Schema)——对象类的集合.条目数据在导入时通常需要接受模式检查,它确保了目录中所有的条目数据结构都是一致的.\nschema(一般在/etc/ldap/schema/目录)在导入时要注意前后顺序.\n对于LDAP目录中保存的信息,可以使用LDIF(LDAP Interchange Format)格式来保存.这是一种标准文本文件格式,使用这种格式保存得的LDAP服务器数据库中的数据可方便读取和修改,这也是其他大多数服务配置文件所采取的格式.\nAttribute 属性(Attribute)类似于程序设计中的变量,可以被赋值.在OpenLDAP中声明了许多常用的Attribute(用户也可自己定义Attribute).\n每个条目都可以有很多属性(Attribute),比如常见的人都有姓名、地址、电话等属性.每个属性都有名称及对应的值,属性值可以有单个、多个,比如你有多个邮箱.\n属性不是随便定义的,需要符合一定的规则,而这个规则可以通过schema制定.比如,如果一个entry没有包含在 inetorgperson 这个 schema 中的objectClass: inetOrgPerson,那么就不能为它指定employeeNumber属性,因为employeeNumber是在inetOrgPerson中定义的.\nLDAP为人员组织机构中常见的对象都设计了属性(比如commonName,surname).下面有一些常用的别名:\n属性\n别名\n语法\n描述\n值（举例）\ncommonName\ncn\nDirectory String\n姓名\nsean\nsurname\nsn\nDirectory String\n姓\nChow\norganizationalUnitName\nou\nDirectory String\n单位（部门）名称\nIT\norganization\no\nDirectory String\n组织（公司）名称\nexample\ntelephoneNumber\nTelephone Number\n电话号码\n110\nobjectClass\n内置熟悉\ntop\n常见的Attribute含义如下:\nc:国家. cn:common name,指一个对象的名字.如果指人,需要使用其全名. dc:domain Component,常用来指一个域名的一部分. givenName:指一个人的名字,不能用来指姓. l:指一个地名,如一个城市或者其他地理区域的名字. mail:电子信箱地址. o:organizationName,指一个组织的名字. ou:organizationalUnitName,指一个组织单元的名字. sn:surname,指一个人的姓. telephoneNumber:电话号码,应该带有所在的国家的代码. uid:userid,通常指某个用户的登录名,与Linux系统中用户的uid不同. 作者：华阳_3bcf\n链接：https://www.jianshu.com/p/3716b84c4c1d\n来源：简书\n著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。\nhttps://zhuanlan.zhihu.com/p/74512921\n在 LDAP 里， 一切都是等级化的，或者称之为层级化（hiearchical）。\n一棵树有树干，树枝和树叶；树叶长在树枝上，树枝依附于树干。这就是一个简单的层级结构。LDAP 的结构同一棵树类似。假设 LDAP 里存储的是公司的信息，那么可以把公司（company）本身理解为树干，公司里面的各个部门，比如组（group），理解为树干，把用户（user）理解为树叶。这样的结构称之为目录信息树（DIrectory Information Tree，DIT）。\n",
    "description": "",
    "tags": null,
    "title": "ldap-轻量目录访问协议",
    "uri": "/%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/%E6%9D%83%E9%99%90%E6%8E%A7%E5%88%B6/ldap-%E8%BD%BB%E9%87%8F%E7%9B%AE%E5%BD%95%E8%AE%BF%E9%97%AE%E5%8D%8F%E8%AE%AE/"
  },
  {
    "content": "figlet 字符画制作工具 figlet -w yuvenhol~\n__ __ __ __ _ _ /\\/| \\ \\ / / _ _ \\ \\ / / ___ _ __ | |__ ___ | | |/\\/ \\ V / | | | | \\ \\ / / / _ \\ | '_ \\ | '_ \\ / _ \\ | | | | | |_| | \\ V / | __/ | | | | | | | | | (_) | | | |_| \\__,_| \\_/ \\___| |_| |_| |_| |_| \\___/ |_| alias alias[别名]=[指令名称] 删除unalias 别名\nnohup nohup command \u003e myout.file 2\u003e\u00261 \u0026 2表示异常输出 1表示标准输出 2\u003e\u00261 异常输出打到标准输出里。\n",
    "description": "",
    "tags": null,
    "title": "linux工具",
    "uri": "/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/linux%E5%B7%A5%E5%85%B7/"
  },
  {
    "content": " 目录 解释 /bin bin 是 Binaries (二进制文件) 的缩写, 这个目录存放着最经常使用的命令。 /sbin s 就是 Super User 的意思，是 Superuser Binaries (超级用户的二进制文件) 的缩写，这里存放的是系统管理员使用的系统管理程序。 /etc 存放系统管理和配置文件 /opt 额外安装的可选应用程序包所放置的位置。 /proc 虚拟文件系统目录，是系统内存的映射，可以查看正在运行程序的状态。 /boot 这里存放的是启动 Linux 时使用的一些核心文件，包括一些连接文件以及镜像文件。 /root 该目录为系统管理员，也称作超级权限者的用户主目录。 /dev dev 是 Device(设备) 的缩写, 该目录下存放的是 Linux 的外部设备，在 Linux 中访问设备的方式和访问文件的方式是相同的。 /lost+found 这个目录平时是空的，系统非正常关机而留下“无家可归”的文件（windows下叫什么.chk）就在这里 /var 用于存放运行时需要改变数据的文件，也是某些大文件的溢出区 /tmp 用于存放各种临时文件，是公用的临时文件存储点。 /mnt 临时挂载别的文件系统的，我们可以将光驱挂载在/mnt/上，然后进入该目录就可以查看光驱里的内容了。 /media linux 系统会自动识别一些设备，例如U盘、光驱等等，当识别后，Linux 会把识别的设备挂载到这个目录下。 /home 存放所有用户文件的根目录，是用户主目录的基点 /usr 用于存放系统应用程序，比较重要的目录。这是最庞大的目录，要用到的应用程序和文件几乎都在这个目录。 /usr/local 本地系统管理员软件安装目录（安装系统级的应用） /usr/doc linux文档 /usr/man 帮助文档 /usr/lib 常用的动态链接库和软件包的配置文件 /usr/sbin 超级用户的一些管理程序 /usr/include linux下开发和编译应用程序所需要的头文件 /usr/src 源代码，linux内核的源代码就放在/usr/src/linux里 usr/local/bin 本地增加的命令 /usr/local/lib 本地增加的库 ",
    "description": "",
    "tags": null,
    "title": "linux目录",
    "uri": "/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/linux%E7%9B%AE%E5%BD%95/"
  },
  {
    "content": "这次的史诗级漏洞是怎么回事呢？ 主角就是log4j2，黑客已经利用 Log4j 漏洞来接管受害者的计算机，以执行从加密货币挖矿、发送垃圾邮件、到通过大型僵尸网络发起分布式拒绝服务(DDoS)攻击的任何事情。\nlog4j2的强大之处在于，除了可以输出程序中的变量，它还提供了一个叫Lookup的东西，lookup相当于是一个接口，可以用来输出更多内容，lookup，顾名思义就是查找、搜索的意思，那在log4j2中，就是允许在输出日志的时候，通过某种方式去查找要输出的内容。\n假如某一个Java程序中，将浏览器的类型记录到了日志中：\nlogger.info(userAgent); User-Agent就属于外界输入的信息，而不是自己程序里定义出来的。只要是外界输入的，就有可能存在恶意的内容，假如有人发来了一个HTTP请求，他的User-Agent是这样一个字符串：\n${jndi:ldap://127.0.0.1/exploit}\n接下来，log4j2将会对这行要输出的字符串进行解析，它发现了字符串中有 ${，要单独处理，发现是JNDI扩展内容_（什么是JNDI？简单粗暴的理解下，它的作用类似于JDBC，JDBC（Java Data Base Connectivity,java数据库连接）是一种用于执行SQL语句的Java API，可以为多种关系数据库提供统一访问，JDBC为工具/数据库开发人员提供了一个标准的API，据此可以构建更高级的工具和接口，使数据库开发人员能够用纯 Java API 编写数据库应用程序。JNDI(Java Naming and Directory Interface)是一个应用程序设计的API，为开发人员提供了查找和访问各种命名和目录服务的通用、统一的接口，类似JDBC都是构建在抽象层上。）如图：_\n再对JNDI进一步解析，发现了是LDAP协议_（LDAP即Lightweight Directory Access Protocol（轻量级目录访问协议），目录是一个为查询、浏览和搜索而优化的专业分布式数据库，这个东西用在统一身份认证领域比较多，**简单理解就是：**一个类似于字典的数据源，你可以通过LDAP协议，传一个name进去，就能获取到数据。）_LDAP服务器在127.0.0.1，要查找的key是exploit，然后调用具体负责LDAP的模块去请求对应的数据。问题来了！JNDI支持一个叫命名引用的方式，也就是JNDI可以远程下载class文件来构建对象！！！下载后加载起来构建对象，咱就是一整个震惊住的那么一个大动作啊，如果远程下载的URL指向的是一个黑客的服务器，并且下载的class文件里面藏有恶意代码，那歇逼了，什么样的后果都可能出现，这是JNDI注入。\n这次“核弹”漏洞造成的影响 log4j2的使用面很广泛，现在Java技术栈在Web、后端开发、大数据等领域应用非常广泛，国内除了阿里巴巴、京东、美团等一大片以Java为主要技术栈的公司外，还有多如牛毛的中小企业选择Java。除此之外还有像kafka、elasticsearch、flink这样的大量中间件都是用Java语言开发的。它们大量使用了log4j2作为日志输出。如果输出的日志有外部输入混进来，那直接就是远程代码执行RCE，灭顶之灾！好吧这些是大佬们的遭遇和分析，至少目前为止对很多人，至少我这种菜鸟没有产生什么大的影响…\n有关解决和修复 方式一：禁用lookup或JNDI服务\n罪魁祸首就是lookup和JNDI，那么直接修改配置文件log4j2.formatMsgNoLookups=True或禁用JNDI服务，不过一般产生问题的服务都是线上已经在跑的服务，禁用的时候要注意评估一下是否允许。\n方式二：升级新版本\n新版的log4j2已经修复了这个问题，升级即可解决。修复后的log4j2在JNDI lookup中增加了很多的限制：\n1.默认不再支持二次跳转（也就是命名引用）的方式获取对象\n2.只有在log4j2.allowedLdapClasses列表中指定的class才能获取。\n3.只有远程地址是本地地址或者在log4j2.allowedLdapHosts列表中指定的地址才能获取\n这样处理等于是去掉了通过打印日志去远程加载class的方式。\n",
    "description": "",
    "tags": null,
    "title": "log4j漏洞",
    "uri": "/%E6%9D%82%E9%A1%B9/log4j%E6%BC%8F%E6%B4%9E/"
  },
  {
    "content": "简介 mapStruct 是一个类型安全的bean转换工具，基于 JSR 269 ，也同样可以使用命令行构建。\n详细文档：https://mapstruct.org/documentation/stable/reference/html/#customizing-mappings-with-before-and-after\n依赖引入 \u003cproperties\u003e \u003corg.mapstruct.version\u003e1.5.2.Final\u003c/org.mapstruct.version\u003e \u003c/properties\u003e ... \u003cdependencies\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.mapstruct\u003c/groupId\u003e \u003cartifactId\u003emapstruct\u003c/artifactId\u003e \u003cversion\u003e${org.mapstruct.version}\u003c/version\u003e \u003c/dependency\u003e \u003c/dependencies\u003e \u003cbuild\u003e \u003cplugins\u003e \u003cplugin\u003e \u003cgroupId\u003eorg.apache.maven.plugins\u003c/groupId\u003e \u003cartifactId\u003emaven-compiler-plugin\u003c/artifactId\u003e \u003cversion\u003e3.8.1\u003c/version\u003e \u003cconfiguration\u003e \u003csource\u003e1.8\u003c/source\u003e \u003ctarget\u003e1.8\u003c/target\u003e \u003cannotationProcessorPaths\u003e \u003c!-- 如果和lombok 结合可能有编译冲突，需要配置如下 --\u003e \u003cpath\u003e \u003cgroupId\u003eorg.projectlombok\u003c/groupId\u003e \u003cartifactId\u003elombok\u003c/artifactId\u003e \u003cversion\u003e${lombok.version}\u003c/version\u003e \u003c/path\u003e \u003cpath\u003e \u003cgroupId\u003eorg.mapstruct\u003c/groupId\u003e \u003cartifactId\u003emapstruct-processor\u003c/artifactId\u003e \u003cversion\u003e${org.mapstruct.version}\u003c/version\u003e \u003c/path\u003e \u003c/annotationProcessorPaths\u003e \u003c/configuration\u003e \u003c/plugin\u003e \u003c/plugins\u003e \u003c/build\u003e 使用 基础 定义一个基础mapping @Mapper public interface CarMapper { @Mapping(target = \"manufacturer\", source = \"make\") @Mapping(target = \"seatCount\", source = \"numberOfSeats\") CarDto carToCarDto(Car car); @Mapping(target = \"fullName\", source = \"name\") PersonDto personToPersonDto(Person person); } mapStruct会再在编译期生成对应的映射方法，依赖于get set方法，所以需要提前写好get\u0026set方法。\n映射编排 Mapping Composition 可以定义一个注解，组合编排mapping\n@Retention(RetentionPolicy.CLASS) //忽略字段 @Mapping(target = \"id\", ignore = true) @Mapping(target = \"creationDate\", expression = \"java(new java.util.Date())\") @Mapping(target = \"name\", source = \"groupName\") public @interface ToEntity { } 自定义方法 如果有一些需要手写的方法，可以自定义一个方法，再Mapping方法中如果用到了类型转转，会自动使用我们自定义的方法。\n@Mapper public interface CarMapper { @Mapping(...) ... CarDto carToCarDto(Car car); default PersonDto personToPersonDto(Person person) { //hand-written mapping logic } } 使用source\u0026target参数 如果source和target不能通过变量名自动转化，那么可以使用注解手动映射。\n@Mapper public interface AddressMapper { @Mapping(target = \"description\", source = \"person.description\") @Mapping(target = \"houseNumber\", source = \"address.houseNo\") DeliveryAddressDto personAndAddressToDeliveryAddressDto(Person person, Address address); } 嵌套（nested）bean映射 @Mapper public interface CustomerMapper { @Mapping( target = \"name\", source = \"record.name\" ) @Mapping( target = \".\", source = \"record\" ) @Mapping( target = \".\", source = \"account\" ) Customer customerDtoToCustomer(CustomerDto customerDto); } 其中 \".\" 代表this对象\n更新已经创建的bean @Mapper public interface CarMapper { void updateCarFromDto(CarDto carDto, @MappingTarget Car car); } 没有get/set 但是是public修饰时 public class Customer { private Long id; private String name; //getters and setter omitted for brevity } public class CustomerDto { public Long id; public String customerName; } @Mapper public interface CustomerMapper { CustomerMapper INSTANCE = Mappers.getMapper( CustomerMapper.class ); @Mapping(target = \"name\", source = \"customerName\") Customer toCustomer(CustomerDto customerDto); @InheritInverseConfiguration CustomerDto fromCustomer(Customer customer); } 支持builder\u0026constructor创建影射对象 支持map结构映射 public class Customer { private Long id; private String name; //getters and setter omitted for brevity } @Mapper public interface CustomerMapper { @Mapping(target = \"name\", source = \"customerName\") Customer toCustomer(Map\u003cString, String\u003e map); } @AfterMapping @BeforeMapping 映射前后执行代码 ",
    "description": "",
    "tags": null,
    "title": "MapStruct-类型安全的bean转换工具",
    "uri": "/java/lib/mapstruct-%E7%B1%BB%E5%9E%8B%E5%AE%89%E5%85%A8%E7%9A%84bean%E8%BD%AC%E6%8D%A2%E5%B7%A5%E5%85%B7/"
  },
  {
    "content": "绘图mermaid 时序图 sequenceDiagram participant mobile participant ucenter participant mysql loop mobile -\u003e\u003e+ ucenter:userCardRemote.queryCardByNo end",
    "description": "",
    "tags": null,
    "title": "markdown",
    "uri": "/%E5%B7%A5%E5%85%B7/markdown/"
  },
  {
    "content": "资料 官网 ：https://maven.apache.org/ 官方仓库浏览：https://mvnrepository.com/、https://search.maven.org/\n功能 编译、打包、测试、依赖管理等\n仓库 通常情况下企业内仓储依赖是\ngraph LR 本地仓库A \u0026 本地仓库B \u0026 本地仓库C --\u003e 企业私服Nexus--\u003e阿里云Nexus--\u003e中央仓库 其中repository Manager 企业内会用nexus等\n文件规范 java 源文件：src/main/java\n测试用例目录：src/test/java\n输出文件： target/\n配置文件： src/main/resources/\nweb：src/main/webapp\n包含/WEB-INF/web.xml\npom 增加\n\u003cpackaging\u003ewar\u003c/packaging\u003e settings文件 settings文件有两处配置，总配置和用户\nThe Maven install: ${maven.home}/conf/settings.xml A user’s install: ${user.home}/.m2/settings.xml Servers 配置账号密码 sshkey等\n1. `\u003cservers\u003e` 2. `\u003cserver\u003e` 3. `\u003cid\u003eserver001\u003c/id\u003e` 4. `\u003cusername\u003emy_login\u003c/username\u003e` 5. `\u003cpassword\u003emy_password\u003c/password\u003e` 6. `\u003cprivateKey\u003e${user.home}/.ssh/id_dsa\u003c/privateKey\u003e` 7. `\u003cpassphrase\u003esome_passphrase\u003c/passphrase\u003e` 8. `\u003cfilePermissions\u003e664\u003c/filePermissions\u003e` 9. `\u003cdirectoryPermissions\u003e775\u003c/directoryPermissions\u003e` 10. `\u003cconfiguration\u003e\u003c/configuration\u003e` 11. `\u003c/server\u003e` 12. `\u003c/servers\u003e` Mirrors 镜像：对repository的代理，默认的repository的id:central，所以一般mirrorOf会配置central,也可以是*，会对所有的repository替换。\n虽然 mirrors 可以配置多个子节点，但是它只会使用其中的一个节点，即 默认情况下配置多个 mirror 的情况下，只有第一个生效，只有当前一个 mirror 无法连接的时候，才会去找后一个；而我们想要的效果是：当a.jar在第一个 mirror 中不存在的时候，maven会去第二个 mirror 中查询下载，但是maven不会这样做！\n1. `\u003cmirrors\u003e` 2. `\u003cmirror\u003e` 3. `\u003cid\u003eplanetmirror.com\u003c/id\u003e` 4. `\u003cname\u003ePlanetMirror Australia\u003c/name\u003e` 5. `\u003curl\u003ehttp://downloads.planetmirror.com/pub/maven2\u003c/url\u003e` 6. `\u003cmirrorOf\u003ecentral\u003c/mirrorOf\u003e` 7. `\u003c/mirror\u003e` 8. `\u003c/mirrors\u003e` POM文件 POM介绍 pom project object model 完整官方文档：https://maven.apache.org/pom.html\n基础例子 \u003cproject xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\"\u003e \u003c!-- maven 模型版本--\u003e \u003cmodelVersion\u003e4.0.0\u003c/modelVersion\u003e \u003c!-- 分组编号一般是公司域名--\u003e \u003cgroupId\u003eorg.codehaus.mojo\u003c/groupId\u003e \u003c!-- 工件编号一般是项目模块--\u003e \u003cartifactId\u003emy-project.xxx\u003c/artifactId\u003e \u003cversion\u003e1.0\u003c/version\u003e \u003c/project\u003e maven 约定大于配置 好处：\n省去配置 规范开发规范 package: package同时会执行compile\ntest Test开头的类名和test开头的方法名才会被执行\n如果引入junit 包，上一条就失效\n项目依赖 项目依赖是指maven通过以来传播、依赖优先、可选依赖、排除依赖、依赖范围等特性来管理项目ClassPath。 依赖传播 我们的项目通常会依赖第三方组件，第三方组建又会依赖其他组件遇到这种情况Maven会将依赖网络中的所有节点都会加入ClassPath。\n依赖优先 就近原则,链路短的优先 相同路径下配置在前的优先\n但是一个pom文件下，后面的优先（并不规范，一个pom文件里不应该写两个一样的依赖） 可选依赖 如果不希望依赖的包传递引用包，可以打断依赖传递\n\u003coptional\u003etrue\u003c/optional\u003e 排除依赖 \u003cexclusions\u003e \u003cexclusion\u003e \u003c!-- 排除依赖 --\u003e \u003c/exclusion\u003e \u003c/exclustions\u003e 依赖范围 \u003cscope\u003e\u003c/scope\u003e 可选的范围\ncomplie（默认），编译和打包都会依赖 provided：编译时依赖，打包不会依赖。ex: servlet-api.jar(tomcat 存在),lombok runtime:运行时范围，打包时依赖，编译时不依赖。mysql-connector-java.jar\n官方解释：this scope indicates that the dependency is not required for compilation, but is for execution. It is in the runtime and test classpaths, but not the compile classpath. test:测试类依赖 system:类似provided，可指定本地位置 ",
    "description": "",
    "tags": null,
    "title": "maven",
    "uri": "/%E5%B7%A5%E5%85%B7/maven/"
  },
  {
    "content": "META-INF The META-INF directory The following files/directories in the META-INF directory are recognized and interpreted by the Java 2 Platform to configure applications, extensions, class loaders and services:\nMANIFEST.MF The manifest file that is used to define extension and package related data. 主要的清单文件，包括版本等信息 比如下面这个asm的MF文件\nManifest-Version: 1.0 Ant-Version: Apache Ant 1.6.5 Created-By: 1.6.0_02-b05 (Sun Microsystems Inc.) Implementation-Title: ASM Implementation-Version: 3.1 Implementation-Vendor: France Telecom R\u0026D INDEX.LIST This file is generated by the new “-i” option of the jar tool, which contains location information for packages defined in an application or extension. It is part of the JarIndex implementation and used by class loaders to speed up their class loading process.\nx.SF The signature file for the JAR file. ‘x’ stands for the base file name.\nx.DSA The signature block file associated with the signature file with the same base file name. This file stores the digital signature of the corresponding signature file.\nservices/ This directory stores all the service provider configuration files.\nSPI和springAutoConfig等都会使用这个路径\nWEB-INF servlet技术使用文件夹，经常会放置一些网页和web.xml等配置\n",
    "description": "",
    "tags": null,
    "title": "META-INF和WEB-INFO",
    "uri": "/java/meta-inf%E5%92%8Cweb-info/"
  },
  {
    "content": "MyBatis是一个持久层的ORM框架，使用简单，学习成本较低。可以执行自己手 写的SQL语句，比较灵活。但是MyBatis的自动化程度不高，移植性也不高，有 时从一个数据库迁移到另外一个数据库的时候需要自己修改配置，所以称只为半 自动ORM框架\njdbc方式 @Test public void test() throws SQLException { Connection conn=null; PreparedStatement pstmt=null; try { // 1.加载驱动 //Class.forName(\"com.mysql.jdbc.Driver\"); // 2.创建连接 conn= DriverManager. // SPI ,mysql Driver Connector，的META-INF.services下会有 java.sql.Driver 的实现类 getConnection(\"jdbc:mysql://localhost:3306/mybatis_example\", \"root\", \"123456\"); // 开启事务 conn.setAutoCommit(false); // SQL语句 参数#{} ${} \u003cif\u003e String sql=\" select id,user_name,create_time from t_user where id=?;\"; // 获得sql执行者 ： // 1. 执行预处理 pstmt=conn.prepareStatement(sql); pstmt.setInt(1,1); // 执行查询 pstmt.execute(); ResultSet rs= pstmt.getResultSet(); //ResultSet rs= pstmt.executeQuery(); rs.next(); User user =new User(); user.setId(rs.getLong(\"id\")); user.setUserName(rs.getString(\"user_name\")); user.setCreateTime(rs.getDate(\"create_time\")); System.out.println(user.toString()); pstmt=conn.prepareStatement(sql); pstmt.setInt(1,1); // 提交事务 conn.commit(); } catch (Exception e) { e.printStackTrace(); // 回滚事务 conn.rollback(); } finally{ // 关闭资源 try { if(conn!=null){ conn.close(); } if(pstmt!=null){ pstmt.close(); } } catch (SQLException e) { e.printStackTrace(); } } } 存在的问题 数据库连接创建，释放频繁造成西戎资源的浪费，从而影响系统性能，使 用数据库连接池可以解决问题。 sql语句在代码中硬编码，造成代码的不已维护，实际应用中sql的变化可 能较大，sql代码和java代码没有分离开来维护不方便。 使用preparedStatement向有占位符传递参数存在硬编码问题因为sql中 的where子句的条件不确定，同样是修改不方便 对结果集中解析存在硬编码问题，sql的变化导致解析代码的变化，系统维 护不方便。 个人认为mybatis主要的功能就2点： 1、动态sql生成 2、ORM\nMybaits整体体系图 使用 public class App { public static void main(String[] args) { String resource = \"mybatis‐config.xml\"; Reader reader; try{ //将XML配置文件构建为Configuration配置类 reader = Resources.getResourceAsReader(resource); // 通过加载配置文件流构建一个SqlSessionFactory DefaultSqlSessionFactor SqlSessionFactory sqlMapper = new SqlSessionFactoryBuilder().build( eader); // 数据源 执行器 DefaultSqlSession SqlSession session = sqlMapper.openSession(); try{ // 执行查询 底层执行jdbc //User user = (User)session.selectOne(\"com.tuling.mapper.selectById\", 1); UserMapper mapper = session.getMapper(UserMapper.class); System.out.println(mapper.getClass()); User user = mapper.selectById(1L); System.out.println(user.getUserName()); } catch (Exception e) { e.printStackTrace(); }finally { session.close(); } } catch (IOException e) { e.printStackTrace(); } } } 总结分为4步：\n从配置文件(通常是XML文件)得到SessionFactory; 从SessionFactory得到SqlSession; 通过SqlSession进行CRUD和事务的操作; 执行完相关操作之后关闭Session。 spring集成mybatis 官方文档 https://mybatis.org/spring/zh/index.html\n方式 1: MapperScannerConfigurer 是mapper注入核心类，其实现了BeanDefinitionRegistryPostProcessor。 获取到配置以后，扫描mapper，通过MybatisMapperProxy生成代理对象，然后依靠MapperFactoryBean，把生成代理对象和mapper的name关联起来，然后注册beanDefination。\n方式2:@MapperScan MapperScannerRegistrar，重写了spring 扫描bean的方法，配合MapperFactoryBean将代理后的mapper注入spring。\nmapper生成 ",
    "description": "",
    "tags": null,
    "title": "mybatis",
    "uri": "/%E7%B1%BB%E5%BA%93%E6%A1%86%E6%9E%B6/mybatis/"
  },
  {
    "content": "mysql 逻辑框架图 ",
    "description": "",
    "tags": null,
    "title": "mysql",
    "uri": "/%E4%B8%AD%E9%97%B4%E4%BB%B6/mysql/"
  },
  {
    "content": "类型 标准数据类型 Python3 中有六个标准的数据类型：\n**不可变数据（3 个）\nNumber（数字） int、float、bool、complex。其中bool是int的子类。False == 0 String（字符串） Tuple（元组） **可变数据（3 个）\nList（列表） Set（集合） Dictionary（字典） Python3 的六个标准数据类型中： 列表 # 简单浅拷贝 squares[:] # 合并 squares1+squares2 列表推导 \u003e\u003e\u003e char_list=[ x.upper() for x in 'ABC'] ['A', 'B', 'C'] 生成器表达式 虽然也可以用列表推导来初始化元组、数组或其他序列类型，但是生成器表达式是更好的选择。这是因为生成器表达式背后遵守了迭代器协议，可以逐个地产出元素，而不是先建立一个完整的列表，然后再把这个列表传递到某个构造函数里。\n\u003e\u003e\u003e colors = ['black', 'white'] \u003e\u003e\u003e sizes = ['S', 'M', 'L'] \u003e\u003e\u003e for tshirt in ('%s%s'%(c, s) for c in colors for s in sizes): ... print(tshirt) ... black S black M black L white S white M white L 元组 元组和记录元组其实是对数据的记录：元组中的每个元素都存放了记录中一个字段的数据，外加这个字段的位置。正是这个位置信息给数据赋予了意义。\ncity, year, pop, chg, area = ('Tokyo', 2003, 32450, 0.66, 8014) 对象 python对象三要素 id（对象地址）、type、value\nl1=[1,2,3] l2=[1,2,3] # 调用对象__eq__() \u003e\u003e\u003el1==l2 true # 对比内存地址 \u003e\u003e\u003el1 is l2 false 赋值(=)、浅拷贝(copy())、深拷贝(deepcopy() #赋值 a=[1,2,[4,5]] #浅拷贝 b=copy(a) #深拷贝 c=deepcopy(b) 运算 #除法运算 \u003e\u003e\u003e5/2 2.5 #除法\u0026向上取整 \u003e\u003e\u003e5//2 2 # 从左到右连续运算 \u003e\u003e\u003e 2\u003c3\u003c=3!=False True 向上取整: 5//2= 2\n集合框架 collections 这个模块实现了特定目标的容器，以提供Python标准内建容器 dict , list , set , 和 tuple 的替代选择。\n- - namedtuple() 创建命名元组子类的工厂函数 deque 类似列表(list)的容器，实现了在两端快速添加(append)和弹出(pop) chainMap 类似字典(dict)的容器类，将多个映射集合到一个视图里面 Counter 字典的子类，提供了可哈希对象的计数功能 deque\n类似列表(list)的容器，实现了在两端快速添加(append)和弹出(pop)\nChainMap\n类似字典(dict)的容器类，将多个映射集合到一个视图里面\nCounter\n字典的子类，提供了可哈希对象的计数功能\nOrderedDict\n字典的子类，保存了他们被添加的顺序\ndefaultdict\n字典的子类，提供了一个工厂函数，为字典查询提供一个默认值\nUserDict\n封装了字典对象，简化了字典子类化\nUserList\n封装了列表对象，简化了列表子类化\nUserString\n封装了字符串对象，简化了字符串子类化\n循环 python的for循环只能使用迭代模式 for w in words: pass\nrange 如果需要index需要配合range()函数\n\u003e\u003e\u003e a = ['Mary', 'had', 'a', 'little', 'lamb'] \u003e\u003e\u003e for i in range(len(a)): ... print(i, a[i]) enumerate 但是多数情况下enumerate更加方便\n\u003e\u003e\u003e for i, v in enumerate(['tic', 'tac', 'toe']): \u003e\u003e\u003e zip 如果需要同时遍历多个数组可以使用zip\n\u003e\u003e\u003e questions = ['name', 'quest', 'favorite color'] \u003e\u003e\u003e answers = ['lancelot', 'the holy grail', 'blue'] \u003e\u003e\u003e for q, a in zip(questions, answers): ... print('What is your {0}? It is {1}.'.format(q, a)) ... What is your name? It is lancelot. 小技巧 提前给数组分配内容 a=[0]* 10 ",
    "description": "",
    "tags": null,
    "title": "python语法知识",
    "uri": "/python/python%E8%AF%AD%E6%B3%95%E7%9F%A5%E8%AF%86/"
  },
  {
    "content": "基本介绍 elasticSearch 提供了一种用于查询的基于json的全查询领域特定语言 Query DSL（Domain specific ）。\n可以把Query DSL看作是查询的抽象语法树，由两种从句组成。\nleaf query clauses 叶子查询从句，就像字段的一部分一样，比如match、term、range。\ncompound query causes 复合查询子句，包装了叶子查询和复合查询，用于以逻辑的方式组合多个查询（比如bool or dis_max）\n昂贵查询 昂贵查询执行缓慢，会影响集群稳定性。分为以下几种\n需要连续扫描来匹配内容的 script 需要很高的预先准备成本 fuzzy regexp prefix wildcard range joining queries query and filter context 相关性分数 默认情况下，es排序按照相关性分数进行排序，它代表这文档与查询的匹配程度。 相关性分数是一个正浮点数，对应_score 字段。\n查询上下文 在查询上下文里，查询子句的回答是“此文档与此查询子句的匹配程度”，除了决定文档是否匹配，这个查询子句也计算匹配程度对应_score字段。\n过滤上线文 在filter context内，查询子句的回答是“此文档与查询子句是否匹配”，答案只有是否。\n经常使用的过滤器将被es缓存，以提高性能。\n过滤上下文并不影响score计算结果。\n举个例子 { \"query\": { //query查询 \"bool\": { //bool内的两个查询子句使用query context \"must\": [ { \"match\": { \"title\": \"Search\" }}, { \"match\": { \"content\": \"Elasticsearch\" }} ], \"filter\": [//filter 过滤掉不匹配的文档 { \"term\": { \"status\": \"published\" }}, { \"range\": { \"publish_date\": { \"gte\": \"2015-01-01\" }}} ] } } } ==官方建议== 在query 子句内写影响分数的条件（也就是文档匹配程度），其他子句都应该在filter内写\n复合查询 复合查询可以包含复合查询和叶子查询，互相结合影响查询分数或者切换filter Context\nbool 用于组合多个叶子或复合查询子句的默认查询，如must、should、must_not或筛选子句。\nmust filter should must_not boosting 对分数进行正向或者负向调整\nconstant_score 查询指定分数的文档\ndis_max 返回一个最匹配的文档，同时用于单条查询\nfunction_score 分数修改\n全文查询 Full text queries intervals 间隙搜索 查询间隔控制。 下面的例子就是，会匹配到my favorite food is cold porridge，但是不会匹配到when it's cold my favorite food is porridge. 因为设置了max_gaps 为0.\n{ \"query\": { \"intervals\" : { \"my_text\" : { \"all_of\" : { \"ordered\" : true, \"intervals\" : [ { \"match\" : { \"query\" : \"my favorite food\", \"max_gaps\" : 0, \"ordered\" : true } }, { \"any_of\" : { \"intervals\" : [ { \"match\" : { \"query\" : \"hot water\" } }, { \"match\" : { \"query\" : \"cold porridge\" } } ] } } ] } } } } } match match是full text query的标准查询语句。\n顶级参数 解释 query operator 分词之后的逻辑的查询逻辑，可以是and或者or ",
    "description": "",
    "tags": null,
    "title": "Query DSL",
    "uri": "/%E4%B8%AD%E9%97%B4%E4%BB%B6/elasticsearch/query-dsl/"
  },
  {
    "content": "官网命令介绍 https://redis.io/commands/ https://pdai.tech/md/db/nosql-redis/db-redis-x-redis-ds.html\n数据结构 字符串 常用命令： SET GET MSET（json的key） MGET SETNX（分布式锁） INCR（原子操作） INCRYBY （批量） GET\nhash结构 Hash常用操作 HSET key field value //存储一个哈希表key的键值 HSETNX key field value //存储一个不存在的哈希表key的键值 HMSET key field value [field value …] //在一个哈希表key中存储多个键值对 HGET key field //获取哈希表key对应的field键值 HMGET key field [field …] //批量获取哈希表key中多个field键值 HDEL key field [field …] //删除哈希表key中的field键值 HLEN key //返回哈希表key中field的数量 HGETALL key //返回哈希表key中所有的键值 HINCRBY key field increment //为哈希表key中field键的值加上增量increment\n相比较String 优点 同类数据归类整合储存，方便数据管理 相比string操作消耗内存与cpu更小 相比string储存更节省空间 缺点 过期功能不能使用在field上，只能用在key上 Redis集群架构下不适合大规模使用。大key容易造成数据分布不均匀 List结构 队列结构，最大2^32-1个元素，主要用于头尾添加访问元素。 LPUSH RPUSH LPOP RPOP LRANGE 返回获取 BLPOP Block LPOP，会阻塞 BRPOP\n应用 stack=LPUSH+LPOP queue=LPUSH+RPOP blocking queue=LPUSH+BRPOP\nSET结构 基础命令 SADD SREM 删除元素 SMEMBERS 查看全部元素 SRANDMEMBER key count 随机从key中抽取count个元素 SPOP 随机从key中抽取count个元素，并排除 pop·· SISMEMBER 是否包含 SCARD获取总数\n集合命令 SINTER 求交集 SUNION 并集 SDIFF 查集（第一个集合，在后续集合中不存在的元素）\n应用 抽奖 关注模型\n共同关注的人 SINTER 我关注的人也关注了他 SISMEMBER 可能喜欢 SDIFF ZSET 有序集合 常用操作： ZADD key score ZRANGE key start stop 排序 ZREVRANGE 倒序 ZUNIONSTORE 并集并放入一个key\n应用： 排行榜\nredis注意事项 redis最应该避免大key，不要一个key里面存太多数据。\n常见面试问题 Redis的单线程和高性能 Redis是单线程吗? Redis 的单线程主要是指 Redis 的网络 IO 和键值对读写是由一个线程来完成的，这也是 Redis 对外 提供键值存储服务的主要流程。但 Redis 的其他功能，比如持久化、异步删除、集群数据同步等，其实是由额外的线程执行的。\nRedis 单线程为什么还能这么快? 因为它所有的数据都在内存中，所有的运算都是内存级别的运算，而且单线程避免了多线程的切换性 能损耗问题。正因为 Redis 是单线程，所以要小心使用 Redis 指令，对于那些耗时的指令(比如 keys)，一定要谨慎使用，一不小心就可能会导致 Redis 卡顿。\nRedis 单线程如何处理那么多的并发客户端连接? Redis的IO多路复用:redis利用epoll来实现IO多路复用，将连接信息和事件放到队列中，依次放到 文件事件分派器，事件分派器将事件分发给事件处理器。 redis 一个命令过来大体分四步 1、建立连接 2、读取数据 3、执行命令 4、应答 连接建立优化先入队列，数据接收完成以后，传给事件处理器，不过需要注意命令的执行仍然会按照入队的顺序执行，只不过优化减少了IO时间。\n",
    "description": "",
    "tags": null,
    "title": "redis基础知识",
    "uri": "/%E4%B8%AD%E9%97%B4%E4%BB%B6/redis/redis%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"
  },
  {
    "content": "参考资料 RocketMQ 消息积压了，增 加消费者有用吗？：https://www.pudn.com/news/62f766f45425817ffc3eae52.html\n",
    "description": "",
    "tags": null,
    "title": "RocketMQ",
    "uri": "/%E4%B8%AD%E9%97%B4%E4%BB%B6/rocketmq/"
  },
  {
    "content": "https://www.cnblogs.com/ciel717/p/16180055.html\nproduceGroup: 用于事物消息，在一个producerGroup内的节点中，如果某个producer down了，那么会找另一个producer重新发送。\n面试常问的问题： 使用RocketMQ如何保证消息不丢失？ 这个是在面试时，关于MQ，面试官最喜欢问的问题。这个问题是所有MQ都需要面 对的一个共性问题。大致的解决思路都是一致的，但是针对不同的MQ产品又有不同 的解决方案。分析这个问题要从以下几个角度入手：\n1、哪些环节会有丢消息的可能？ 我们考虑一个通用的MQ场景： 其中，1，2，4三个场景都是跨网络的，而跨网络就肯定会有丢消息的可能。 然后关于3这个环节，通常MQ存盘时都会先写入操作系统的缓存page cache中，然 后再由操作系统异步的将消息写入硬盘。这个中间有个时间差，就可能会造成消息 丢失。如果服务挂了，缓存中还没有来得及写入硬盘的消息就会丢失。 这个是MQ场景都会面对的通用的丢消息问题。那我们看看用RocketMQ时要如何 解决这个问题\ntopicQueue 数量过多会有性能问题\n集群消费由brocker管理 广播消费由consumer管理\n",
    "description": "",
    "tags": null,
    "title": "rocketmq基本概念",
    "uri": "/%E4%B8%AD%E9%97%B4%E4%BB%B6/rocketmq/rocketmq%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/"
  },
  {
    "content": "search API 用于搜索\u0026聚合es上的数据和数据流。\n大多数的searchAPI 都支持 multi-target syntax（简单理解为可以跨索引搜索），可以通过呢explain API 来查询执行计划。\nCoreSearch 请求方式 GET /\u003ctarget\u003e/_search POST /\u003ctarget\u003e/_search { } 路径变量\u003ctarget\u003e为索引名称，支持模糊匹配，可以使用get参数q or POST 的reuestBody传入查询参数,大多数命令q和requestBody都痛哟功能。\n查询参数 query exlain 执行计划 使用Query DSL 定义查询对象。\ndocvalue_fields 在fields（响应体会讲）里控制展示的_doc下的字段（注意与fields字段区分），同时可以对字段进行format\nfields 与docvalue_fields类似，只不过范围是_source内的字段，范围更小。\nfrom default 0\nsize 默认10，在默认设置下，你不可能通过from\u0026size参数对超过10000个命中数据进行分页。如果要用得是search_after参数。\nsort pit 限制搜索内容在一个时间点内（point in time）。如果提供了pit则查询时不需要填写index\nmin_score 指定最小的分数\nruntime_mappings 定义一些runtime fields 用于搜索，这些字段将优先覆盖相同名字的字段，注意只能用于查询，response不会展示。\n响应体 took es 执行请求花费的时间，这个时间就是协调节点接受到请求和返回响应的时间差。\n_shards total:需要执行的shards successful： skipped: 轻量级检查意识到分片没有数据，就跳过 failed hits { \"total\" : { //文档的元数据 \"value\" : 10000,//返回的文档数量 \"relation\" : \"gte\"//如果是eq那么，就是文档总数。如果是gte那么value就是下限 }, \"max_score\" : 1.0,//文档的最高分，如果为null表明文档不是以score排序的 \"hits\" : [ { \"_index\" : \"kibana_sample_data_logs\",// \"_type\" : \"_doc\",//Mapping type of the returned document. \"_id\" : \"DexbbYUBknarlexk7QjU\",//文档id \"_score\" : 1.0,//分数 \"_source\" : {//原始的json文档 }, \"fields\":{//展示来自 docvalue_fields、script_fields、stored_fields的字段 } } ",
    "description": "",
    "tags": null,
    "title": "Search API",
    "uri": "/%E4%B8%AD%E9%97%B4%E4%BB%B6/elasticsearch/search-api/"
  },
  {
    "content": "简介 Sentinel 是面向分布式、多语言异构化服务架构的流量治理组件，主要以流量为切入点，从流量路由、流量控制、流量整形、熔断降级、系统自适应过载保护、热点流量防护等多个维度来帮助开发者保障微服务的稳定性。\nSentinel 基本概念 资源 资源是 Sentinel 的关键概念。它可以是 Java 应用程序中的任何内容，例如，由应用程序提供的服务，或由应用程序调用的其它应用提供的服务，甚至可以是一段代码。在接下来的文档中，我们都会用资源来描述代码块。\n只要通过 Sentinel API 定义的代码，就是资源，能够被 Sentinel 保护起来。大部分情况下，可以使用方法签名，URL，甚至服务名称作为资源名来标示资源。\n规则 围绕资源的实时状态设定的规则，可以包括流量控制规则、熔断降级规则以及系统保护规则。所有规则可以动态实时调整。\nSentinel 功能和设计理念 流量控制 流量控制有以下几个角度:\n资源的调用关系，例如资源的调用链路，资源和资源之间的关系； 运行指标，例如 QPS、线程池、系统负载等； 控制的效果，例如直接限流、冷启动、排队等。 Sentinel 的设计理念是让您自由选择控制的角度，并进行灵活组合，从而达到想要的效果。\n熔断降级 什么是熔断降级 除了流量控制以外，降低调用链路中的不稳定资源也是 Sentinel 的使命之一。由于调用关系的复杂性，如果调用链路中的某个资源出现了不稳定，最终会导致请求发生堆积。\nSentinel 和 Hystrix 的原则是一致的: 当调用链路中某个资源出现不稳定，例如，表现为 timeout，异常比例升高的时候，则对这个资源的调用进行限制，并让请求快速失败，避免影响到其它的资源，最终产生雪崩的效果。\n熔断降级设计理念 Sentinel 对这个问题采取了两种手段:\n通过并发线程数进行限制 和资源池隔离的方法不同，Sentinel 通过限制资源并发线程的数量，来减少不稳定资源对其它资源的影响。这样不但没有线程切换的损耗，也不需要您预先分配线程池的大小。当某个资源出现不稳定的情况下，例如响应时间变长，对资源的直接影响就是会造成线程数的逐步堆积。当线程数在特定资源上堆积到一定的数量之后，对该资源的新请求就会被拒绝。堆积的线程完成任务后才开始继续接收请求。\n通过响应时间对资源进行降级 除了对并发线程数进行控制以外，Sentinel 还可以通过响应时间来快速降级不稳定的资源。当依赖的资源出现响应时间过长后，所有对该资源的访问都会被直接拒绝，直到过了指定的时间窗口之后才重新恢复。\n系统负载保护 Sentinel 同时提供系统维度的自适应保护能力。防止雪崩，是系统防护中重要的一环。当系统负载较高的时候，如果还持续让请求进入，可能会导致系统崩溃，无法响应。在集群环境下，网络负载均衡会把本应这台机器承载的流量转发到其它的机器上去。如果这个时候其它的机器也处在一个边缘状态的时候，这个增加的流量就会导致这台机器也崩溃，最后导致整个集群不可用。\n针对这个情况，Sentinel 提供了对应的保护机制，让系统的入口流量和系统的负载达到一个平衡，保证系统在能力范围之内处理最多的请求。\n开源框架适配 web servlet: CommonFilter dubbo http client 等等 https://sentinelguard.io/zh-cn/docs/open-source-framework-integrations.html 控制台 Sentinel 提供一个轻量级的开源控制台，它提供机器发现以及健康情况管理、监控（单机和集群），规则管理和推送的功能。这里，我们将会详细讲述如何通过简单的步骤就可以使用这些功能。 引入JAR包 客户端需要引入 Transport 模块来与 Sentinel 控制台进行通信。您可以通过 pom.xml 引入 JAR 包:\n\u003cdependency\u003e \u003cgroupId\u003ecom.alibaba.csp\u003c/groupId\u003e \u003cartifactId\u003esentinel-transport-simple-http\u003c/artifactId\u003e \u003cversion\u003ex.y.z\u003c/version\u003e \u003c/dependency\u003e 配置启动参数 启动时加入 JVM 参数 -Dcsp.sentinel.dashboard.server=consoleIp:port 指定控制台地址和端口。若启动多个应用，则需要通过 -Dcsp.sentinel.api.port=xxxx 指定客户端监控 API 的端口（默认是 8719）。\n除了修改 JVM 参数，也可以通过配置文件取得同样的效果。更详细的信息可以参考 启动配置项。\n触发客户端初始化 确保客户端有访问量，Sentinel 会在客户端首次调用的时候进行初始化，开始向控制台发送心跳包。\n简单的demo public class SentinelDemoTest { // 配置规则. private static void initFlowRules() { List\u003cFlowRule\u003e rules = new ArrayList\u003c\u003e(); FlowRule rule = new FlowRule(); rule.setResource(\"HelloWorld\"); rule.setGrade(RuleConstant.FLOW_GRADE_QPS); rule.setCount(8); rules.add(rule); FlowRuleManager.loadRules(rules); } private static void initDegradeRules() { List\u003cDegradeRule\u003e rules = new ArrayList\u003c\u003e(); DegradeRule rule = new DegradeRule(); rule.setResource(\"HelloWorld\"); rule.setGrade(RuleConstant.DEGRADE_GRADE_EXCEPTION_COUNT); rule.setCount(2); rule.setTimeWindow(1); rules.add(rule); DegradeRuleManager.loadRules(rules); } /** * 异常捕获式限流 * try-with-resources 语句 */ @Test public void t1() throws InterruptedException { initFlowRules(); while (true) { Thread.sleep(100); try (Entry entry = SphU.entry(\"HelloWorld\")) { // 被保护的逻辑 System.out.println(\"hello world\"); } catch (BlockException ex) { // 处理被流控的逻辑 System.out.println(\"blocked!\"); } } } /** * 异常捕获式限流 * try finally 语句 */ @Test public void t1_1() throws InterruptedException { initFlowRules(); // 配置规则. while (true) { Thread.sleep(100); Entry entry = null; try { entry = SphU.entry(\"HelloWorld\"); // 被保护的逻辑 System.out.println(\"hello world\"); // 处理被流控的逻辑 System.out.println(\"blocked!\"); } catch (BlockException e) { e.printStackTrace(); } finally { if (entry != null) { entry.exit(); } } } } /** * 条件判断式限流 */ @Test public void t2() throws InterruptedException { // 配置规则. initFlowRules(); while (true) { Thread.sleep(100); boolean entryOk = SphO.entry(\"HelloWorld\"); if (entryOk) { // 被保护的逻辑 System.out.println(\"hello world\"); } else { // 处理被流控的逻辑 System.out.println(\"blocked!\"); } SphO.exit(); } } /** * 降级 */ @Test public void t4() { initDegradeRules(); while (true) { Entry entry = null; try { Thread.sleep(100); entry = SphU.entry(\"HelloWorld\"); throw new RuntimeException(\"exception\"); } catch (BlockException e) { System.out.println(\"degrade\"); } catch (Exception e) { System.out.println(\"pass\"); Tracer.trace(e); } finally { if (entry != null) { entry.exit(); } } } } } 核心源码 在 Sentinel 里面，所有的资源都对应一个资源名称以及一个 Entry。Entry 可以通过对主流框架的适配自动创建，也可以通过注解的方式或调用 API 显式创建；每一个 Entry 创建的时候，同时也会创建一系列功能插槽（slot chain）。这些插槽有不同的职责，例如:\nNodeSelectorSlot 1.负责收集资源的路径，并将这些资源的调用路径，以树状结构存储起来，用于根据调用路径来限流降级2.构造一个Node用于存储当前请求的统计数据； ClusterBuilderSlot 为了获得同一资源在不同上下文中的总统计信息，同一资源全局共享同一个ClusterNode。ClusterBuilderSlot主要负责构建这个ClusterNode； StatisticSlot 则用于记录、统计不同纬度的 runtime 指标监控信息； FlowSlot 则用于根据预设的限流规则以及前面 slot 统计的状态，来进行流量控制； AuthoritySlot 则根据配置的黑白名单和调用来源信息，来做黑白名单控制； DegradeSlot 则通过统计信息以及预设的规则，来做熔断降级； SystemSlot 则通过系统的状态，例如 load1 等，来控制总的入口流量； ",
    "description": "",
    "tags": null,
    "title": "sentinel",
    "uri": "/%E7%B1%BB%E5%BA%93%E6%A1%86%E6%9E%B6/sentinel/"
  },
  {
    "content": "-c 表示后面的参数将会作为字符串读入作为执行的命令。 ex：\n/bin/bash -c ls /bin/bash ls ",
    "description": "",
    "tags": null,
    "title": "shell",
    "uri": "/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/shell/"
  },
  {
    "content": "bash有几种不同的运行模式，login shell与non-login shell,.interactive shell.与non-interactive shell(比如执行shel脚本)。这两种 分类方法是交叉的，也就是说一个login shell7可能是一个interactive shell,也可能是个non-interactive shell。. 在下列情况下，我们可以获得一个login shell: 1.登录系统时获得的J顶层shell,无论是通过本地终端登录，还是通过网络ssh登录。这种情况下获得的login shell是一个交互式shell。. 2.在终端下使用-login选项调用bash,可以获得一个交互式login shell。. 3.在脚本中使用-login选项调用bash(比如在shell脚本第一行做如下指定：#！/bin/bash–login),此时得到一个非交互式的login shell。 4.使用\"su-“切换到指定用户时，获得此用户的login shell。如果不使用”.\"，则获得non-login shell。 login shell与non-login shell的主要区别在于它们启动时会读取不同的配置文件，从而导致环境不一样。 login shell的行为： login shell,启动时首先读取/etc/profile:全局配置，然后依次查找~/.bash_profile、~/.bash_login、~/.profile三个配置文件，并且 读取第一个找到的并且可读的文件。login shell退出时读取并执行~/.bash_logout中的命令。 non-login shell的行为： 交互式的non-login shell)启动时读取~.bashrc资源文件。非交互式的non–login shell不读取上述所有配置文件，而是查找环境变量 BASH ENV,读取并执行BASH ENV指向的文件中的命令。 如果使用命令\"sh\"调用bash,bash会尽可能保持向后兼容。作为login shellF启动时，bash依次读取/etc/profile和~l.profile配置文件。作为 non-login shell/启动时，bash读取环境变量ENV指向的文件。 通常我们要定制一些配置时，将配置写在.bashrc中，然后在/.bash_profile中读取~/.bashrc,这样可以保证login shell和交互式non-login shell得到相同的配置。至于/etc/profile就不要轻易去改啦，毕竟会影响系统全局的配置。\n",
    "description": "",
    "tags": null,
    "title": "shell 的login shell与non-login shell",
    "uri": "/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/shell-%E7%9A%84login-shell%E4%B8%8Enon-login-shell/"
  },
  {
    "content": "几篇还不错的文章： SLF4J和Logback和Log4j和Logging的区别与联系\njava日志体系\n",
    "description": "",
    "tags": null,
    "title": "slf4j",
    "uri": "/%E6%9D%82%E9%A1%B9/slf4j/"
  },
  {
    "content": "生命周期 补充： @PostConstruct 代表bean构建完成后置处理，在属性注入之后，基于初始化前实现 beanPostProcessor .beforeInitlazation。\n循环依赖 三级缓存 singletonFactories 对象工厂，表示用来创建早期bean对象的工厂,存放的就是个Function.\naddSingletonFactory(beanName, () -\u003e getEarlyBeanReference(beanName, mbd, bean)); getEarlyBeanReference 默认不会做任何处理，如果需要aop会生成代理类。\nearlySingletonObjects 早期bean，未完成依赖注入，但是已经经过AOP。\nsingletonObjects 依赖注入完成的bean\n存放顺序 singletonFactories–\u003eearlySingletionObjects–\u003esingletonObjects\n读取顺序 singletonObjects–\u003eearlySingletionObjects–\u003esingletonFactories\n",
    "description": "",
    "tags": null,
    "title": "spring bean",
    "uri": "/spring/spring-bean/"
  },
  {
    "content": "spring cache是spring对各种cache的一种抽象管理，可以使用redis、caffeine等。\n\u003c-- 必要 --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-cache\u003c/artifactId\u003e \u003cversion\u003e2.2.5.RELEASE\u003c/version\u003e \u003c/dependency\u003e \u003c-- 缓存中一种 --\u003e \u003cdependency\u003e \u003cgroupId\u003ecom.github.ben-manes.caffeine\u003c/groupId\u003e \u003cartifactId\u003ecaffeine\u003c/artifactId\u003e \u003cversion\u003e2.9.2\u003c/version\u003e \u003c/dependency\u003e 在使用缓存之前，需要创建一个CacheManager\n@Bean public CacheManager cacheManager() { CaffeineCacheManager caffeineCacheManager = new CaffeineCacheManager(); caffeineCacheManager.setCaffeine( Caffeine.newBuilder() .expireAfterWrite(10, TimeUnit.MINUTES) .maximumSize(10_000)); return caffeineCacheManager; } http://t.zoukankan.com/hager-p-13197673.html\nhttps://www.freesion.com/article/401730391/\n",
    "description": "",
    "tags": null,
    "title": "Spring cache",
    "uri": "/spring/spring-cache/"
  },
  {
    "content": "BeanFactory ApplicationContext ApplicationContext 也实现了beanFactory，实际上具体实现依靠获取Context内的BeanFacoty实例DefaultListableBeanFactory 来实现功能的。\ngraph TD 10[ContextLoaderListener.contextInitialized] --创建WebApplicationContext--\u003e15[ContextLoader.initWebApplicationContext] --\u003e 18[configureAndRefreshWebApplicationContext] --初始化context--\u003e20 subgraph refresh 20[ConfigurableApplicationContext.refresh] --prepareRefresh--\u003e21[准备刷新:包括spring环境等] -- obtainFreshBeanFactory--\u003e22[创建bean工厂] -- prepareBeanFactory--\u003e23[bean工厂初始化配置] -- postProcessBeanFactory --\u003e24[添加beanFactory的后置护理器] -- invokeBeanFactoryPostProcessors --\u003e25[调用beanFactory后置处理器.bean扫描是在这一步操作的] -- registerBeanPostProcessors --\u003e26[注册bean后置处理器,这里添加autowired等后置处理器] -- initMessageSource --\u003e27[国际化等] -- initApplicationEventMulticaster--\u003e28[创基一个事件广播器来处理事件] -- onRefresh --\u003e29[初始化前添加特殊bean 默认啥都不干] -- registerListeners --\u003e 30[注册event listener] -- finishBeanFactoryInitialization --\u003e31[初始化剩余的bean,普通的bean会在这一部进行createBean操作] -- finishRefresh--\u003e32[主要是发送ContextRefreshedEvent 通知完成refresh] end",
    "description": "",
    "tags": null,
    "title": "spring Context",
    "uri": "/spring/spring-context/"
  },
  {
    "content": "Spring Web MVC是基于Servlet API构建的原始Web框架，从一开始就已包含在Spring框架中。正式名 称“ Spring Web MVC”来自其源模块的名称(spring-webmvc)，但它通常被称为“ Spring MVC”。 xml下配置servlet的映射非常麻烦 开发效率低 必须要继承父类、重写方法 侵入性强 如果想在一个Servlet中处理同一业务模块的的功能分发给不同方法进行处理非常麻烦 参数解析麻烦:单个参数（转换类型）—\u003epojo对象 Json文本—\u003epojo对象 数据响应麻烦:pojo对象—\u003ejson … Content-type 跳转页面麻烦, 对path的控制、 如果使用其他模板也很麻烦 、设置编码麻烦…等等… 所以SpringMVC 就是在Servlet的基础上进行了封装，帮我把这些麻烦事都给我们做了。\n核心方法在 DispatcherServlet::doDispatch\n需要了解的类和方法 RequestMappingHandler 请求映射处理器，用于将一个request和一个handler给映射起来。有好多种形式进行映射，常见的是BeanNameUrlHandlerMapping（bean name和url映射）和DefaultAnnotationHandlerMapping（RequestMapping等注解映射），一般都用DefaultAnnotationHandlerMapping,mvc使用mvc:annotation-driven开启。\nRequestMappingHandlerMapping ,\ndispatcherServlet是核心分分发器，其核心方法时doDispatch()。 根据请求路径\nHandler（具体的Controller 方法） HandlerMapping（根据request定为到对应的HandlerExecutionChain） HandlerExecutionChain（handler的执行链，包含了拦截器和HandlerMethod） HandlerMethod(包装了Handler) HandlerAdapter()\nHandlerMethodReturnValueHandlerComposite HandlerMethodReturnValueHandler\nHandlerMethodArgumentResolverComposite HandlerMethodArgumentResolver\nmessageConverter （依赖 HandlerMethodReturnValueHandler和HandlerMethodArgumentResolver 处理请求前后 ）\n",
    "description": "",
    "tags": null,
    "title": "spring mvc",
    "uri": "/spring/spring-mvc/"
  },
  {
    "content": "不同host指定使用不同密钥 在.ssh/下创建一个config文件\nHost hostA HostName www.abc.com Port 1234 User test IdentityFile ~\\.ssh\\id_rsa Host hostB HostName 123.456.789.000 Port 5678 User root IdentityFile ~\\.ssh\\id_rsa 给linux实例添加新增SSH公钥 #!/bin/bash # ssh public key to be added. sshPublicKey=\"{{sshPublicKey}}\" mkdir -p ~/.ssh \u0026\u0026 chmod 700 ~/.ssh touch ~/.ssh/authorized_keys chmod 600 ~/.ssh/authorized_keys echo $sshPublicKey \u003e\u003e ~/.ssh/authorized_keys echo \"operation success!\" ",
    "description": "",
    "tags": null,
    "title": "SSH",
    "uri": "/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/ssh/"
  },
  {
    "content": "为啥是去中心化的： 阿帕网当初设计的时候为了防止苏联人攻击损坏一个节点，其他节点不可用，所以做成了去中心化的。 IEEE和ISO\nOSI 七层模型是ISO提供的，都是学者相对学术 IEEE是 五工程师协会提出的，更加实际可实现\nIP地址和MAC地址的区别\nIP地址可以变动、mac地址是不变的，相同子网内寻址使用MAC地址，不同网络使用IP地址\nSYN(synchronous建立联机) ACK(acknowledgement 确认) PSH(push传送) FIN(finish结束) RST(reset重置) URG(urgent紧急)\nSequence number(顺序号码)\n",
    "description": "",
    "tags": null,
    "title": "TCP IP协议",
    "uri": "/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/tcp-ip%E5%8D%8F%E8%AE%AE/"
  },
  {
    "content": "栈上分配 为什么需要栈上分配\n在我们的应用程序中，其实有很多的对象的作用域都不会逃逸出方法外，也就是说该对象的生命周期会随着方法的调用开始而开始，方法的调用结束而结束，对于这种对象，是不是该考虑将对象不在分配在堆空间中呢？ 我们通过JVM内存分配可以知道JAVA中的对象都是在堆上进行分配，当对象没有被引用的时候，需要依靠GC进行回收内存，如果对象数量较多的时候，会给GC带来较大压力，也间接影响了应用的性能。\n什么是栈上分配\n所以,栈上分配是JVM提出的一种调优方案,JVM通过逃逸分析确定该对象不会被外部访问,如果不会逃逸可以将该对象在栈上分配内存，每个方法或者说每个线程都有属于自己独立的栈帧,随着方法的调用结束,这样该对象所占用的内存空间就可以随栈帧出栈而销毁，就减轻了垃圾回收的压力。\n对象逃逸分析：就是分析对象动态作用域，当一个对象在方法中被定义后，它可能被外部方法所引用，例如作为调用参数传递到其他地方中。\n分析如下案例:\npublic User test1(){ User user = new User(); user.setId(1); user.setName(“1”); return user; }\npublic void test2(){ User user = new User(); user.setId(1); user.setName(“1”);\n//保存数据库 //userMapper.save(user); } 很显然test1方法中的user对象被返回了，这个对象的作用域范围不确定，test2方法中的user对象我们可以确定当方法结束这个对象就可以认为是无效对象了，对于这样的对象我们其实可以将其分配在栈内存里，让其在方法结束时跟随栈内存一起被回收掉。\nJVM对于这种情况可以通过开启逃逸分析参数(-XX:+DoEscapeAnalysis)来优化对象内存分配位置，使其通过标量替换优先分配在栈上(栈上分配)，JDK7之后默认开启逃逸分析，如果要关闭使用参数(-XX:-DoEscapeAnalysis)\n标量替换：通过逃逸分析确定该对象不会被外部访问，并且对象可以被进一步分解时，JVM不会创建该对象，而是将该对象成员变量分解若干个被这个方法使用的成员变量所代替，这些代替的成员变量在栈帧或寄存器上分配空间，这样就不会因为没有一大块连续空间导致对象内存不够分配。开启标量替换参数(-XX:+EliminateAllocations)，JDK7之后默认开启。\n栈上分配的优点:\n1.可以在方法调用结束后自行销毁对象,无需垃圾回收器的介入,有效减小JVM的GC压力 2.栈上分配速度很快,有效提高程序性能\n栈上分配的缺点:\n1.栈的空间是有限的,栈空间存放不了大对象,遇到大对象的创建则还是会存放在堆空间中\nTLAB 可能很多人会有疑惑，已经提供了栈上分配，为什么还要有什么TLAB，甚至混淆了两者之间的差别，包括我自己，之前也存在很多疑惑，下面为大家揭开原因 全名: 本地线程分配缓冲(Thread Local Allocation Buffer,TLAB)，这是一个线程专用的内存分配区域。\n为什么需要TLAB\n在线程初始化时，同时也会申请一块指定大小的内存，只给当前线程使用，这样每个线程都单独拥有一个空间，如果需要分配内存，就在自己的空间上分配，这样就不存在竞争的情况，可以大大提升分配效率。\n如何开启TLAB\nJVM默认开启了TLAB功能，也可以使用-XX: +UseTLAB 显示开启\n如何观察TLAB使用情况\nJVM提供了-XX:+PrintTLAB 参数打开跟踪TLAB的使用情况\n如何调整TLAB默认大小 -XX:TLABSize 通过该参数指定分配给每一个线程的TLAB空间的大小\n简单理解\n为了避免多线程情况下抢占空间,每个线程会提前在EDEN区中,额外划分一块内存区域,指定对象直接进入区域使用, jdk8默认开启\nTLAB的缺点:\n1.TLAB空间一般不会很大(占用了Eden区),所以大对象也无法在TLAB上进行分配,遇到大对象最终也只能分配到堆空间中\n如下图:对象分配流程图\n最后栈上分配和TLAB的对比\n名称\t针对点\t处于对象分配流程的位置 栈上分配\t减少GC的负担\t1 TLAB\t加速堆上对象分配速度\t2\n",
    "description": "",
    "tags": null,
    "title": "TLAB\u0026栈上分配",
    "uri": "/java/jvm/tlab%E6%A0%88%E4%B8%8A%E5%88%86%E9%85%8D/"
  },
  {
    "content": "@Transactional 注解属性 rollbackFor 设置错误 rollbackFor 可以指定能够触发事务回滚的异常类型。Spring默认抛出了未检查unchecked异常（继承自 RuntimeException 的异常）或者 Error才回滚事务；其他异常不会触发回滚事务。如果在事务中抛出其他类型的异常，但却期望 Spring 能够回滚事务，就需要指定rollbackFor属性。\n",
    "description": "",
    "tags": null,
    "title": "transcational",
    "uri": "/spring/transcational/"
  },
  {
    "content": "简介 统一资源标志符URI就是在某一规则下能把一个资源独一无二地标识出来。 拿人做例子，假设这个世界上所有人的名字都不能重复，那么名字就是URI的一个实例，通过名字这个字符串就可以标识出唯一的一个人。 现实当中名字当然是会重复的，所以身份证号才是URI，通过身份证号能让我们能且仅能确定一个人。 那统一资源定位符URL是什么呢。也拿人做例子然后跟HTTP的URL做类比，就可以有：\n动物住址协议://地球/中国/浙江省/杭州市/西湖区/某大学/14号宿舍楼/525号寝/张三.人\n可以看到，这个字符串同样标识出了唯一的一个人，起到了URI的作用，所以URL是URI的子集。URL是以描述人的位置来唯一确定一个人的。 在上文我们用身份证号也可以唯一确定一个人。对于这个在杭州的张三，我们也可以用：\n身份证号：123456789\n来标识他。 所以不论是用定位的方式还是用编号的方式，我们都可以唯一确定一个人，都是URl的一种实现，而URL就是用定位的方式实现的URI。\nURL URL：（全称：Uniform Resource Locator） 统一资源定位符。\n它是对可以从互联网上得到的资源的位置和访问方法的一种简洁的表示，是互联网上标准资源的地址\nURL 的常见定义格式为\nscheme://host[:port#]/path/…/[;url-params][?query-string][#anchor]\nscheme //有我们很熟悉的http、https、ftp以及著名的ed2k，迅雷的thunder等。 host //HTTP服务器的IP地址或者域名 port# //HTTP服务器的默认端口是80，这种情况下端口号可以省略。如果使用了别的端口，必须指明， 例如tomcat的默认端口是8080 http://localhost:8080/ path //访问资源的路径 url-params //所带参数 query-string //发送给http服务器的数据 anchor //锚点定位 URL的格式一般由下列三部分组成:\n协议(或称为服务方式); 存有该资源所在的服务器的名称或IP地址(包括端口号); 主机资源的具体地址。 一个简单的url 1 — 协议 常见的协议 http 超文本传输协议资源 https 用安全套接字层传送的超文本传输协议 ftp 文件传输协议 mailto 电子邮件地址 2 —服务器名称或IP 端口:相当于一种数据的传输通道。用于接受某些数据，然后传输给相应的服务，而电脑将这些数据处理后，再将相应的回复通过开启的端口传给对方。\n端口的作用：因为 IP 地址与网络服务的关系是一对多的关系。所以实际上因特网上是通过 IP 地址加上端口号来区分不同的服务的。\n端口是通过端口号来标记的，端口号只有整数，范围是从0 到65535。\n3 — 主机资源具体地址 例如： /webProject/index.html 一般的URL为：\nURL: http://127.0.0.1:8080/webProject/index.html URI URI：（全称：Uniform Resource Identifier） 统一资源标识符，它是一个字符串用来标示抽象或物理资源\nWeb上可用的每种资源（ HTML文档、图像、音频、视频片段、程序等）都由一个通用资源标识符（Uniform Resource Identifier, 简称”URI”）进行定位。\nURI的格式也由三部分组成:\n访问资源的命名机制。 存放资源的主机名。 资源自身的名称，由路径表示。 联系与区别 URI ：Uniform Resource Identifier，统一资源标识符； URL：Uniform Resource Locator，统一资源定位符； URN：Uniform Resource Name，统一资源名称。\nURI 属于 URL 更高层次的抽象，一种字符串文本标准。\n就是说，URI 属于父类，而 URL 属于 URI 的子类。URL 是 URI 的一个子集\nURI 表示请求服务器的路径，定义这么一个资源。而 URL 同时说明要如何访问这个资源（http://）。./)\nURI可以分为URL,URN，或同时具备locators 和names特性的一个东西。URN作用就好像一个人的名字，URL就像一个人的地址。换句话说：URN确定了东西的身份，URL提供了找到它的方式。”\n总结 URL是一种具体的URI，它不仅唯一标识资源，而且还提供了定位该资源的信息。\nURI是一种语义上的抽象概念，可以是绝对的，也可以是相对的，而URL则必须提供足够的信息来定位。\nURI：统一资源标识 URL：统一资源定位 URN：统一资源名称\n例如： www.baidu.com是URL. www.baidu.com/index.html 是URL 同时也是URI。 所以，URL 就是 URI 的 定位。\n但 URI 不一定是 URL。 因为 URI有一类子集是 URN，它是命名资源 但不指定如何定位资源。 如： mailto 需要 加上 相应的结构参数，才能进行 统一资源定位。 如： mailto: xxxxx@qq.com\n因此，三者之间的关系是： URI 一定是 URL URN + URL 就是 URI。\n",
    "description": "",
    "tags": null,
    "title": "URL和URI",
    "uri": "/%E6%9D%82%E9%A1%B9/url%E5%92%8Curi/"
  },
  {
    "content": " vim是一款无处不在、高可配置、编辑十分高效的文本编辑器。\n虽然vim学习曲线很陡峭，但是学会了真的会带来快乐，这种感觉就像你可以从找人装修你的家，也可以自己搞，买材料、买装备、学习如何装修。\n如果你并非整天与命令行打交道，那么学习vim给你带来的方便并不会太多，而且耗费的时间肯定是划不来的，但是学习的过程是快乐的！快乐就好。\nvim 键位图 基础命令 移动动图 类型 按键 描述 保存\u0026退出 ctrl+z|:q! 强制退出 :wq|:x|ZZ 保存退出 :w !sudo tee % 打开只读文件时保存 折叠 zo 打开 zc 关闭 zM 关闭所有 zR 打开所有 动作 \u003cC-u\u003e/ \u003cC-u\u003e 上/下一页 运算符 = 格式化代码 gU upper gu lower \u003c / \u003e 缩紧调整indent 视图模式 \u003cC-v\u003e 列选择 V 行选择 \u003cC-v\u003e+I/\u003cC-v\u003e$A 在行首/行尾添加内容 文本对象 存储个性化配置的vimrc 在～/.vimrc\n插件 vim-camelsnek 驼峰和长蛇风格转换\n",
    "description": "",
    "tags": null,
    "title": "vim",
    "uri": "/%E5%B7%A5%E5%85%B7/vim/"
  },
  {
    "content": "因为我们完全信任了用户输入，但有些别有用心的用户会像这样的输入\n这样无论是谁访问这个页面的时候控制台都会输出“Hey you are a fool fish!”，如果这只是个恶意的小玩笑，有些人做的事情就不可爱了，有些用户会利用这个漏洞窃取用户信息、诱骗人打开恶意网站或者下载恶意程序等，看个最简单的例子\n作者：乔治大叔\n链接：https://www.jianshu.com/p/033cb2fa5098\n来源：简书\n著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。\n",
    "description": "",
    "tags": null,
    "title": "XSS跨站脚本攻击",
    "uri": "/%E6%9D%82%E9%A1%B9/xss%E8%B7%A8%E7%AB%99%E8%84%9A%E6%9C%AC%E6%94%BB%E5%87%BB/"
  },
  {
    "content": "YAML 是什么？ YAML 是一种可读性高，以数据为中心的数据序列化格式。可以表达 对象（键值对），数组，标量 这几种数据形式 能够被多种编程语言和脚本语言解析。\n什么是序列化？\n序列化指的是将自定义的对象或者其他数据进行持久化，从而方便进行传输和存储。一般情况下，能够序列化的数据一定能够通过反序列化恢复。\nYAML 语法与格式 基本语法 以 k: v 的形式来表示键值对的关系，冒号后面必须有一个空格 # 表示注释 对大小写敏感 通过缩进来表示层级关系，缩排中空格的数目不重要，只要相同阶层的元素左侧对齐就可以了 缩进只能使用空格，不能使用 tab 缩进键 字符串可以不用双引号 格式 对象和键值对\n通过 k: v 的方式表示对象或者键值对，冒号后必须要加一个空格：\nName: Astron Sex: female School: TJU 通过缩进来表示对象的多个属性：\nPeople: Name: Astron Sex: female School: TJU 也可以写成\npeople: {name: Astron, sex: female} 数组\n数组（或者列表）中的元素采用 - 表示，以 - 开头的行表示构成一个数组\neg1：\n- A - B - C eg2:\npeople: - yyy - zzz - www 行内表示：\npeople: [yyy, zzz, www] eg3: 对象数组\npeople: - name: yyy age: 18 - name: zzz age: 19 使用流式表示：\npeople: [{name: yyy, age: 18},{name: zzz, age: 19}] 标量\n标量是最基本的不可再分的值，包括：\n整数 浮点数 字符串 布尔值 Null 时间 日期 eg:\nboolean: - true # 大小写都可以 - false float: - 3.14 - 3.25e+5 # 科学计数法 int: 12 null: nodeName: name string: 123 date: 2020-01-01 # 格式为 yyyy-MM-dd datetime: 2020-01-10T15:02:08+08:00 # 日期和时间使用T连接，+表示时区 引用\n\u0026 用于建立锚点，* 用于引用锚点，\u003c\u003c 表示合并到当前数据\neg1:\ndefaults: \u0026defaults adapter: ppp host: qqq development: database: mq \u003c\u003c: *defaults 相当于：\ndefaults: adapter: ppp host: qqq development: database: mq adapter: ppp host: qqq eg2:\n- \u0026showell steve - clark - eve - *showell 相当于:\n- steve - clark - eve - steve ",
    "description": "",
    "tags": null,
    "title": "yaml",
    "uri": "/%E6%9D%82%E9%A1%B9/yaml/"
  },
  {
    "content": "什么是zookeeper 它是一个分布式协调框架，是Apache Hadoop 的一个子项目，它主要是用来解决分布式应用中经常遇到的一些数据管理问题，如:统一命名服务、状态同 步服务、集群管理、分布式应用配置项的管理等。\n核心概念 简单的理解Zookeeper 是一个用于存储少量数据的基于内存 的数据库，主要有如下两个核心的概念:\n文件系统数据结构 监听通知机制。 文件系统数据结构 Zookeeper维护一个类似文件系统的数据结构: 每个子目录项都被称作为 znode(目录节点)，和文件系统类似，我们能够自由的增加、删除 znode，在一个znode下增加、删除子znode。\n有四种类型的znode:\nPERSISTENT­持久化目录节点 客户端与zookeeper断开连接后，该节点依旧存在，只要不手动删除该节点，他将永远存在\nPERSISTENT_SEQUENTIAL­持久化顺序编号目录节点 客户端与zookeeper断开连接后，该节点依旧存在，只是Zookeeper给该节点名称进行顺序编号\nEPHEMERAL­临时目录节点 客户端与zookeeper断开连接后，该节点被删除(和sessionId绑定的，session断开或者超时会被删除)\nEPHEMERAL_SEQUENTIAL­临时顺序编号目录节点 客户端与zookeeper断开连接后，该节点被删除，只是Zookeeper给该节点名称进行顺序编号\nContainer 节点(3.5.3 版本新增，如果Container节点下面没有子节点，则Container节点 在未来会被Zookeeper自动清除,定时任务默认60s 检查一次)\nTTL 节点( Time To Live 默认禁用，只能通过系统配置 zookeeper.extendedTypesEnabled=true 开启，不稳定)\n监听通知机制 客户端注册监听它关心的任意节点，或者目录节点及递归子目录节点\n如果注册的是对某个节点的监听，则当这个节点被删除，或者被修改时，对应的客户端将被通知 如果注册的是对某个目录的监听，则当这个目录有子节点被创建，或者有子节点被删除，对应的客户端将被通知 如果注册的是对某个目录的递归子节点进行监听，则当这个目录下面的任意子节点有目录结构 的变化(有子节点被创建，或被删除)或者根节点有数据变化时，对应的客户端将被通知。 get -w /xxx 监听只会监听当前节点，子节点修改不会被监听 注意:所有的通知都是一次性的，及无论是对节点还是对目录进行的监听，一旦触发，对应的监 听即被移除。递归子节点，监听是对所有子节点的，所以，每个子节点下面的事件同样只会被触发一次。\n应用场景 分布式配置中心 分布式注册中心 分布式锁 分布式队列 集群选举 分布式屏障 发布/订阅 节点元数据 可以通过stat命令，或者get -s cZxid:创建znode的事务ID(Zxid的值)。 mZxid:最后修改znode的事务ID。 pZxid:最后添加或删除子节点的事务ID(子节点列表发生变化才会发生改变)。 ctime:znode创建时间。 mtime:znode最近修改时间。\ndataVersion:znode的当前数据版本。 cversion:znode的子节点结果集版本(一个节点的子节点增加、删除都会影响这个版本）。 aclVersion：znode的acl版本 ephemeralOwner:znode是临时znode时，表示znode所有者的 session ID。 如果 znode不是临时znode，则该字段设置为零。 dataLength:znode数据字段的长度。 numChildren:znode的子znode的数量。\nACL 权限控制( Access Control List ) Zookeeper 的ACL 权限控制,可以控制节点的读写操作,保证数据的安全性，Zookeeper ACL 权 限设置分为 3 部分组成，分别是:权限模式(Scheme)、授权对象(ID)、权限信息 (Permission)。最终组成一条例如“scheme:id:permission”格式的 ACL 请求信息。\nScheme(权限模式):用来设置 ZooKeeper 服务器进行权限验证的方式。ZooKeeper 的权限 验证方式大体分为两种类型:\n一种是范围验证。所谓的范围验证就是说 ZooKeeper 可以针对一个 IP 或者一段 IP 地址授予某 种权限。比如我们可以让一个 IP 地址为“ip:192.168.0.110”的机器对服务器上的某个数据节 点具有写入的权限。或者也可以通过“ip:192.168.0.1/24”给一段 IP 地址的机器赋权。\n另一种权限模式就是口令验证，也可以理解为用户名密码的方式。在 ZooKeeper 中这种验证方 式是 Digest 认证，而 Digest 这种认证方式首先在客户端传送“username:password”这种形 式的权限表示符后，ZooKeeper 服务端会对密码 部分使用 SHA-1 和 BASE64 算法进行加密， 以保证安全性。\n还有一种Super权限模式, Super可以认为是一种特殊的 Digest 认证。具有 Super 权限的客户端 可以对 ZooKeeper 上的任意数据节点进行任意操作。\n授权对象(ID)\n授权对象就是说我们要把权限赋予谁，而对应于 4 种不同的权限模式来说，如果我们选择采用 IP 方式，使用的授权对象可以是一个 IP 地址或 IP 地址段;而如果使用 Digest 或 Super 方式，则 对应于一个用户名。如果是 World 模式，是授权系统中所有的用户。\n权限信息(Permission)\n权限就是指我们可以在数据节点上执行的操作种类，如下所示:在 ZooKeeper 中已经定义好的 权限有 5 种:\n数据节点(c: create)创建权限，授予权限的对象可以在数据节点下创建子节点; 数据节点(w: wirte)更新权限，授予权限的对象可以更新该数据节点;\n数据节点(r: read)读取权限，授予权限的对象可以读取该节点的内容以及子节点的列表信息; 数据节点(d: delete)删除权限，授予权限的对象可以删除该数据节点的子节点; 数据节点(a: admin)管理者权限，授予权限的对象可以对该数据节点体进行 ACL 权限设置。\n命令:\ngetAcl:获取某个节点的acl权限信息\nsetAcl:设置某个节点的acl权限信息\naddauth: 输入认证授权信息，相当于注册用户信息，注册时输入明文密码，zk将以密文的形式存 储\n可以通过系统参数zookeeper.skipACL=yes进行配置，默认是no,可以配置为true, 则配置过的 ACL将不再进行权限检测 ex： setAcl /test auth:yuvenhol:pwd:rwcd create /test xxdataxx ip:192.168.109.130:rw\n数据结构 //DataNode 是Zookeeper存储节点数据的最小单位 public class DataNode implements Record{ byte data[]; Long acl; public StatPersisted stat; private Set\u003cString\u003e children = null; } // public class DataTree{ private final ConcurrentHashMap\u003cString, DataNode\u003e nodes = new ConcurrentHashMap\u003cString, DataNode\u003e(); private final WatchManager dataWatches = new WatchManager(); private final WatchManager childWatches = new WatchManager(); } 事务日志\u0026数据快照 格式化后效果 事务日志： 针对每一次客户端的事务操作，Zookeeper都会将他们记录到事务日志中，当然，Zookeeper也 会将数据变更应用到内存数据库中。我们可以在zookeeper的主配置文件zoo.cfg 中配置内存中 的数据持久化目录，也就是事务日志的存储路径 dataLogDir. 如果没有配置dataLogDir(非必 填), 事务日志将存储到dataDir (必填项)目录 数据快照： 用于记录Zookeeper服务器上某一时刻的全量数据，并将其写入到指定的磁盘文件中。 可以通过配置snapCount配置每间隔事务请求个数，生成快照，数据存储在dataDir 指定的目录中\n事务日志文件名为: log.\u003c当时最大事务ID\u003e，应为日志文件时顺序写入的，所以这个最大事务 ID也将是整个事务日志文件中，最小的事务ID，日志满了即进行下一次事务日志文件的创建\n快照事务日志文件名为: snapshot.\u003c当时最大事务ID\u003e，日志满了即进行下一次事务日志文件的 创建\n",
    "description": "",
    "tags": null,
    "title": "zookeeper",
    "uri": "/%E5%88%86%E5%B8%83%E5%BC%8F/zookeeper/"
  },
  {
    "content": "1、字段意义不可分割，不能是数组等集合或者表达多个意义。 2、每个字段都依赖主键 3、依赖不可传递，比如 A-\u003eB-\u003eC 不行的，必须A-\u003eC,B-\u003eC。\n",
    "description": "",
    "tags": null,
    "title": "三大范式",
    "uri": "/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql/%E4%B8%89%E5%A4%A7%E8%8C%83%E5%BC%8F/"
  },
  {
    "content": "中间件是为应用提供通用服务和功能的软件。数据管理、应用服务、消息传递、身份验证和 API 管理通常都要通过中间件。\n中间件可以帮助开发人员更有效地构建应用。它就如同是应用、数据与用户之间的纽带。\n对于具有多云和容器化环境的企业而言，中间件可以助您大规模、经济高效地开发和运行应用。 一般而言中间件和框架的区别是，中间件是独立运行的用于处理某项专门业务的CS程序，会有配套的客户端和服务端，框架虽然也是处理某个专门业务的但是它不是独立程序，是寄宿在宿主程序进程内的一套类库。 作者：阿里巴巴淘系技术\n链接：https://www.zhihu.com/question/19730582/answer/1663627873\n来源：知乎\n著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。\n常用基础中间件 路由与web服务器：处理和转发其他服务器通信数据的服务器。 如被业界广泛使用的阿里基于 Nginx 研发的 Tengine、阿里内部的集中式路由服务 VipServer\nRPC框架：微服务时代的远程服务调用框架。如grpc, Thrift, 阿里的 HSF, Dubbo, SOFA-RPC\n消息中间件：支持在分布式系统之间发送和接收消息的软件。 如 Apache kafka, Apache RabbitMQ, NSQ, 阿里孵化开源的 Apache RocketMQ\n缓存服务: 分布式的高速数据存储层，一般是内存存储。如 阿里 Tair，业界的 Redis, Memcached, Ehcache\n配置中心：用来统一管理各个项目中所有配置的系统。如 阿里 Nacos、携程 Apollo、百度 Disconf\n分布式事务：事务的参与者、支持事务的服务器、资源服务器以及事务管理器分别位于不同的分布式系统的不同节点之上。 如 阿里 seata、腾讯 DTF\n任务调度：分布式环境下提供定时、任务编排、分布式跑批等功能的系统。如 阿里 SchedulerX、业界 xxl-job、当当 elastic-job、有赞 TSP\n数据库层 用于支持弹性扩容和分库分表的 TDDL，数据库连接池 Driud, Binlog 同步的 Canal 等。\n",
    "description": "",
    "tags": null,
    "title": "中间件的定义",
    "uri": "/%E4%B8%AD%E9%97%B4%E4%BB%B6/%E4%B8%AD%E9%97%B4%E4%BB%B6%E7%9A%84%E5%AE%9A%E4%B9%89/"
  },
  {
    "content": "https://zhuanlan.zhihu.com/p/476222316\n",
    "description": "",
    "tags": null,
    "title": "为什么SpringBoot可以直接运行 jar 包？",
    "uri": "/spring/springboot/%E4%B8%BA%E4%BB%80%E4%B9%88springboot%E5%8F%AF%E4%BB%A5%E7%9B%B4%E6%8E%A5%E8%BF%90%E8%A1%8C-jar-%E5%8C%85/"
  },
  {
    "content": "事务的概念 事务的意义就是为了保证系统中所有数据的都是符合预期的，且相互关联的数据之间不会产生矛盾，即数据状态的一致性。\n经典数据库理论中，要达成这个目标，需要三方面共同努力来保障。\n原子性（Atomic）：在同一项业务处理过程中，事务保证了对多个数据的修改，要么同时成功，要么同时被撤销。 隔离性（Isolation）：在不同的业务处理过程中，事务保证了各自业务正在读、写的数据互相独立，不会彼此影响。 持久性（Durability）：事务应当保证所有成功被提交的数据修改都能够正确地被持久化，不丢失数据。 事务的四大特性ACID，纯属凑数😓 目前事务的概念已经不在局限于数据库方面了，延伸到所有涉及到保证一致性的场景，包括但不限于缓存、消息队列、分布式存储等。\n在使用单一数据源的情况下，使用A.I.D保证事务的做法比较容易，事务由数据源控制，被称作局部事务（也叫本地事务），一致性被称为“内部一致性”。 在使用多数据源的情况下，甚至多个服务多个数据源，这时要保证一致性被称为\"外部一致性\"。\n",
    "description": "",
    "tags": null,
    "title": "事务",
    "uri": "/%E6%95%B0%E6%8D%AE%E5%BA%93/%E4%BA%8B%E5%8A%A1/"
  },
  {
    "content": "据说人生清楚这四个问题，就不再迷茫。\n我喜欢什么 我适合什么 我想成为怎样的人 我想过什么样的生活 ",
    "description": "",
    "tags": null,
    "title": "人生四问",
    "uri": "/%E8%83%A1%E8%AF%8C%E5%85%AB%E6%89%AF%E5%A4%A7%E9%81%93%E7%90%86/%E4%BA%BA%E7%94%9F%E5%9B%9B%E9%97%AE/"
  },
  {
    "content": " 迟来的深情不如狗叫 —— jukie\n断臂求生——jukie\n",
    "description": "",
    "tags": null,
    "title": "人生大道理",
    "uri": "/%E8%83%A1%E8%AF%8C%E5%85%AB%E6%89%AF%E5%A4%A7%E9%81%93%E7%90%86/%E4%BA%BA%E7%94%9F%E5%A4%A7%E9%81%93%E7%90%86/"
  },
  {
    "content": "全局事务（Global Transaction） 全局事务仍然追求ACID的强一致性，适用于在使用多个数据源时。\n2PC 伪代码：\npublic void buyBook(PaymentBill bill) { userTransaction.begin(); warehouseTransaction.begin(); businessTransaction.begin(); try { userAccountService.pay(bill.getMoney()); warehouseService.deliver(bill.getItems()); businessAccountService.receipt(bill.getMoney()); userTransaction.commit(); warehouseTransaction.commit(); businessTransaction.commit(); } catch(Exception e) { userTransaction.rollback(); warehouseTransaction.rollback(); businessTransaction.rollback(); } } 准备阶段：又叫作投票阶段，在这一阶段，协调者询问事务的所有参与者是否准备好提交，参与者如果已经准备好提交则回复 Prepared，否则回复 Non-Prepared。这里所说的准备操作跟人类语言中通常理解的准备并不相同，对于数据库来说，准备操作是在重做日志中记录全部事务提交操作所要做的内容，它与本地事务中真正提交的区别只是暂不写入最后一条 Commit Record 而已，这意味着在做完数据持久化后并不立即释放隔离性，即仍继续持有锁，维持数据对其他非事务内观察者的隔离状态。 提交阶段：又叫作执行阶段，协调者如果在上一阶段收到所有事务参与者回复的 Prepared 消息，则先自己在本地持久化事务状态为 Commit，在此操作完成后向所有参与者发送 Commit 指令，所有参与者立即执行提交操作；否则，任意一个参与者回复了 Non-Prepared 消息，或任意一个参与者超时未回复，协调者将自己的事务状态持久化为 Abort 之后，向所有参与者发送 Abort 指令，参与者立即执行回滚操作。对于数据库来说，这个阶段的提交操作应是很轻量的，仅仅是持久化一条 Commit Record 而已，通常能够快速完成，只有收到 Abort 指令时，才需要根据回滚日志清理已提交的数据，这可能是相对重负载的操作。 以上这两个过程被称为“两段式提交”（2 Phase Commit，2PC）协议，而它能够成功保证一致性还需要一些其他前提条件。\n必须假设网络在提交阶段的短时间内是可靠的，即提交阶段不会丢失消息。同时也假设网络通信在全过程都不会出现误差，即可以丢失消息，但不会传递错误的消息，XA 的设计目标并不是解决诸如拜占庭将军一类的问题。两段式提交中投票阶段失败了可以补救（回滚），而提交阶段失败了无法补救（不再改变提交或回滚的结果，只能等崩溃的节点重新恢复），因而此阶段耗时应尽可能短，这也是为了尽量控制网络风险的考虑。 必须假设因为网络分区、机器崩溃或者其他原因而导致失联的节点最终能够恢复，不会永久性地处于失联状态。由于在准备阶段已经写入了完整的重做日志，所以当失联机器一旦恢复，就能够从日志中找出已准备妥当但并未提交的事务数据，并向协调者查询该事务的状态，确定下一步应该进行提交还是回滚操作。 存在的问题 单点问题：协调者在两段提交中具有举足轻重的作用，协调者等待参与者回复时可以有超时机制，允许参与者宕机，但参与者等待协调者指令时无法做超时处理。一旦宕机的不是其中某个参与者，而是协调者的话，所有参与者都会受到影响。如果协调者一直没有恢复，没有正常发送 Commit 或者 Rollback 的指令，那所有参与者都必须一直等待。 性能问题：两段提交过程中，所有参与者相当于被绑定成为一个统一调度的整体，期间要经过两次远程服务调用，三次数据持久化（准备阶段写重做日志，协调者做状态持久化，提交阶段在日志写入 Commit Record），整个过程将持续到参与者集群中最慢的那一个处理操作结束为止，这决定了两段式提交的性能通常都较差。 一致性风险：前面已经提到，两段式提交的成立是有前提条件的，当网络稳定性和宕机恢复能力的假设不成立时，仍可能出现一致性问题。宕机恢复能力这一点不必多谈，1985 年 Fischer、Lynch、Paterson 提出了“FLP 不可能原理”，证明了如果宕机最后不能恢复，那就不存在任何一种分布式协议可以正确地达成一致性结果。该原理在分布式中是与“CAP 不可兼得原理“齐名的理论。而网络稳定性带来的一致性风险是指：尽管提交阶段时间很短，但这仍是一段明确存在的危险期，如果协调者在发出准备指令后，根据收到各个参与者发回的信息确定事务状态是可以提交的，协调者会先持久化事务状态，并提交自己的事务，如果这时候网络忽然被断开，无法再通过网络向所有参与者发出 Commit 指令的话，就会导致部分数据（协调者的）已提交，但部分数据（参与者的）既未提交，也没有办法回滚，产生了数据不一致的问题。 3PC 3PC是针对2PC的优化，分为 Can、Pre、Do 三个阶段。新增了一个Can（询问阶段），如果数据库状态不能保证可以顺利完成，则不锁定资源。三阶段也解决了单点问题，如果协调者超时默认会提交事务。 ",
    "description": "",
    "tags": null,
    "title": "全局事务",
    "uri": "/%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%85%A8%E5%B1%80%E4%BA%8B%E5%8A%A1/"
  },
  {
    "content": "逻辑划分：\nHot spot 实现\n虚拟机栈：\n每个方法被执行事会生成一个栈桢（Stack Frame）用于存储局部变量表，操作数栈、动态链接、方法出口等\n本地方法栈：\n与虚拟机栈功能相似，服务于native方法。Hot-spot把本地方法栈与虚拟机栈合二为一。\n堆：\n对象存储的地方，有些对象存储在栈上，依靠内存逃逸。\n方法区：\n存放类的信息，常量、静态变量、及时编译后的代码缓存。\n运行时常量池：\nJava程序要运行时，需要编译器先将源代码文件编译成字节码（.class)文件，然后在由JVM解释执行。\nclass文件中除了有类的版本、字段、方法、接口等描述信息外,还有一项信息是常量池(Constant pool table)，用于存放编译期生成的各种字面量和符号引用，这部分内容将在类加载后进入运行时常量池中存放。\n静态常量池就是上面说的class文件中的常量池。class常量池是在编译时每个class文件中都存在。不同的符号信息放置在不同标志的常量表中。\n",
    "description": "",
    "tags": null,
    "title": "内存结构",
    "uri": "/java/%E5%86%85%E5%AD%98%E7%BB%93%E6%9E%84/"
  },
  {
    "content": "rc file 在linux中我们在对命令设置持续保存时，常常会把设置添加到一个rc文件内，比如.zshrc、.vimrc 等等。那么rc是啥意思，时run command的简称，意思是运行命令，就是在一个命令运行时需要指定的配置，所以每次命令运行时会从rc文件获取配置然后作为参数添加到命令里。\n",
    "description": "",
    "tags": null,
    "title": "冷知识",
    "uri": "/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/%E5%86%B7%E7%9F%A5%E8%AF%86/"
  },
  {
    "content": " 事务基本概念[[事务]]\n分布式事务 在分布式服务环境下的事务处理机制。\nCAP理论 分布式计算领域所公认的著名定理。这个定理里描述了一个分布式的系统中，涉及共享数据问题时，以下三个特性最多只能同时满足其中两个：\n一致性（Consistency）：代表数据在任何时刻、任何分布式节点中所看到的都是符合预期的。一致性在分布式研究中是有严肃定义、有多种细分类型的概念，以后讨论分布式共识算法时，我们还会再提到一致性，那种面向副本复制的一致性与这里面向数据库状态的一致性严格来说并不完全等同，具体差别我们将在后续分布式共识算法中再作探讨。 可用性（Availability）：代表系统不间断地提供服务的能力，理解可用性要先理解与其密切相关两个指标：可靠性（Reliability）和可维护性（Serviceability）。可靠性使用平均无故障时间（Mean Time Between Failure，MTBF）来度量；可维护性使用平均可修复时间（Mean Time To Repair，MTTR）来度量。可用性衡量系统可以正常使用的时间与总时间之比，其表征为：A=MTBF/（MTBF+MTTR），即可用性是由可靠性和可维护性计算得出的比例值，譬如 99.9999%可用，即代表平均年故障修复时间为 32 秒。 分区容忍性（Partition Tolerance）：代表分布式环境中部分节点因网络原因而彼此失联后，即与其他节点形成“网络分区”时，系统仍能正确地提供服务的能力。 对C、A、P三者的取舍，会产生不同取向的。\n如果放弃分区容忍性（CA without P），意味着我们将假设节点之间通信永远是可靠的。永远可靠的通信在分布式系统中必定不成立的，这不是你想不想的问题，而是只要用到网络来共享数据，分区现象就会始终存在。在现实中，最容易找到放弃分区容忍性的例子便是传统的关系数据库集群，这样的集群虽然依然采用由网络连接的多个节点来协同工作，但数据却不是通过网络来实现共享的。以 Oracle 的 RAC 集群为例，它的每一个节点均有自己独立的 SGA、重做日志、回滚日志等部件，但各个节点是通过共享存储中的同一份数据文件和控制文件来获取数据的，通过共享磁盘的方式来避免出现网络分区。因而 Oracle RAC 虽然也是由多个实例组成的数据库，但它并不能称作是分布式数据库。 如果放弃可用性（CP without A），意味着我们将假设一旦网络发生分区，节点之间的信息同步时间可以无限制地延长，此时，问题相当于退化到前面“全局事务”中讨论的一个系统使用多个数据源的场景之中，我们可以通过 2PC/3PC 等手段，同时获得分区容忍性和一致性。在现实中，选择放弃可用性的 CP 系统情况一般用于对数据质量要求很高的场合中，除了 DTP 模型的分布式数据库事务外，著名的 HBase 也是属于 CP 系统，以 HBase 集群为例，假如某个 RegionServer 宕机了，这个 RegionServer 持有的所有键值范围都将离线，直到数据恢复过程完成为止，这个过程要消耗的时间是无法预先估计的。 如果放弃一致性（AP without C），意味着我们将假设一旦发生分区，节点之间所提供的数据可能不一致。选择放弃一致性的 AP 系统目前是设计分布式系统的主流选择，因为 P 是分布式网络的天然属性，你再不想要也无法丢弃；而 A 通常是建设分布式的目的，如果可用性随着节点数量增加反而降低的话，很多分布式系统可能就失去了存在的价值，除非银行、证券这些涉及金钱交易的服务，宁可中断也不能出错，否则多数系统是不能容忍节点越多可用性反而越低的。目前大多数 NoSQL 库和支持分布式的缓存框架都是 AP 系统，以 Redis 集群为例，如果某个 Redis 节点出现网络分区，那仍不妨碍各个节点以自己本地存储的数据对外提供缓存服务，但这时有可能出现请求分配到不同节点时返回给客户端的是不一致的数据。 “选择放弃一致性的 AP 系统目前是设计分布式系统的主流选择”，“事务”原本的目的就是获得“一致性”，而在分布式环境中，“一致性”却不得不成为通常被牺牲、被放弃的那一项属性。但无论如何，我们建设信息系统，终究还是要确保操作结果至少在最终交付的时候是正确的，这句话的意思是允许数据在中间过程出错（不一致），但应该在输出时被修正过来。为此，人们又重新给一致性下了定义，将前面我们在 CAP、ACID 中讨论的一致性称为“强一致性”（Strong Consistency），有时也称为“线性一致性”（Linearizability，通常是在讨论共识算法的场景中），而把牺牲了 C 的 AP 系统又要尽可能获得正确的结果的行为称为追求“弱一致性”。不过，如果单纯只说“弱一致性”那其实就是“不保证一致性”的意思……人类语言这东西真的是博大精深。在弱一致性里，人们又总结出了一种稍微强一点的特例，被称为“最终一致性”（Eventual Consistency），它是指：如果数据在一段时间之内没有被另外的操作所更改，那它最终将会达到与强一致性过程相同的结果，有时候面向最终一致性的算法也被称为“乐观复制算法”。\n在本节讨论的主题“分布式事务”中，目标同样也不得不从之前三种事务模式追求的强一致性，降低为追求获得“最终一致性”。由于一致性的定义变动，“事务”一词的含义其实也同样被拓展了，人们把使用 ACID 的事务称为“刚性事务”，而把笔者下面将要介绍几种分布式事务的常见做法统称为“柔性事务”。\n实现柔性事务的方案 可靠事件队列 TCC SAGA ",
    "description": "",
    "tags": null,
    "title": "分布式事务",
    "uri": "/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/"
  },
  {
    "content": "选举算法： paxos: 角色\nPaxos将系统中的角色分为提议者 (Proposer)，决策者 (Acceptor)，和最终决策学习者 (Learner):\n• Proposer: 提出提案 (Proposal)。Proposal信息包括提案编号 (Proposal ID) 和提议的值 (Value)。\n• Acceptor: 参与决策，回应Proposers的提案。收到Proposal后可以接受提案，若Proposal获得多数Acceptors的接受，则称该Proposal被批准。\n• Learner: 不参与决策，从Proposers/Acceptors学习最新达成一致的提案(Value)。\n在多副本状态机中，每个副本同时具有Proposer、Acceptor、Learner三种角色。\n三只蓝军攻打一只强大的红军\n第一阶段: Prepare阶段\nProposer向Acceptors发出Prepare请求，Acceptors针对收到的Prepare请求进行Promise承诺。\n• Prepare: Proposer生成全局唯一且递增的Proposal ID (可使用时间戳加Server ID)，向所有Acceptors发送Prepare请求，这里无需携带提案内容，只携带Proposal ID即可。\n• Promise: Acceptors收到Prepare请求后，做出“两个承诺，一个应答”。\n○ 承诺1: 不再接受Proposal ID小于等于(注意: 这里是\u003c= )当前请求的Prepare请求;\n○ 承诺2: 不再接受Proposal ID小于(注意: 这里是\u003c )当前请求的Propose请求;\n○ 应答: 不违背以前作出的承诺下，回复已经Accept过的提案中Proposal ID最大的那个提案的Value和Proposal ID，没有则返回空值。\n¶ 第二阶段: Accept阶段\nProposer收到多数Acceptors承诺的Promise后，向Acceptors发出Propose请求，Acceptors针对收到的Propose请求进行Accept处理。\n• Propose: Proposer 收到多数Acceptors的Promise应答后，从应答中选择Proposal ID最大的提案的Value，作为本次要发起的提案。如果所有应答的提案Value均为空值，则可以自己随意决定提案Value。然后携带当前Proposal ID，向所有Acceptors发送Propose请求。\n• Accept: Acceptor收到Propose请求后，在不违背自己之前作出的承诺下，接受并持久化当前Proposal ID和提案Value。\n¶ 第三阶段: Learn阶段\nProposer在收到多数Acceptors的Accept之后，标志着本次Accept成功，决议形成，将形成的决议发送给所有Learners。 一致性协议算法： ZAB： https://pdai.tech/md/algorithm/alg-domain-distribute-x-zab.html\n负载均衡算法 一致性hash https://blog.csdn.net/gonghaiyu/article/details/108375298\n传统hash算法的弊端 资源数据分布通常有哈希分区和顺序分区两种方式\n顺序分布：数据分散度易倾斜、键值业务相关、可顺序访问、不支持批量操作。 哈希分布：数据分散度高、键值分布业务无关、无法顺序访问、支持批量操作。 顺序分区\n顺序分区通常指顺序访问某个资源，如在RocketMQ中，Topic(消息主题)可能对应多个实际的消息队列，消息投递时，如果有5个消息，只有三个队列，消息按照1-2-3-1-2这样的投递顺序。\n哈希分区-节点取余分区\n对特定数据采用hash算法得到一个整数，再通过整数对分区数取余就可以得到资源的存储路由。如redis的键或用户ID，再根据节点数量N使用公式：hash(key)%N计算出哈希值，用来决定数据映射到哪个分区节点。\n优点\n这种方式的突出优点就是简单，且常用于数据库的分库分表。如京东某系统中采用shardingjdbc，用这种方式进行分库分表路由处理。 缺点\n当节点数量发生变化时，如扩容或收缩节点（没有遇到过），数据节点关系需要重新计算，会导致数据的重新迁移。所以扩容通常采用翻倍扩容，避免数据映射全部打乱而全部迁移，翻倍迁移只发生50%的数据迁移。如果不翻倍缩扩容，如某一台机器宕机，那么应该落在该机器的请求就无法得到正确的处理，这时需要将宕掉的服务器使用算法去除，此时候会有(N-1)/N的服务器的缓存数据需要重新进行计算；如果新增一台机器，会有N /(N+1)的服务器的缓存数据需要进行重新计算。对于系统而言，这通常是不可接受的颠簸（因为这意味着大量缓存的失效或者数据需要转移）。 传统求余做负载均衡算法，缓存节点数由3个变成4个，缓存不命中率为75%。计算方法：穷举hash值为1-12的12个数字分别对3和4取模，然后比较发现只有前3个缓存节点对应结果和之前相同，所以有75%的节点缓存会失效，可能会引起缓存雪崩。\n",
    "description": "",
    "tags": null,
    "title": "分布式算法",
    "uri": "/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E7%AE%97%E6%B3%95/"
  },
  {
    "content": " ",
    "description": "",
    "tags": null,
    "title": "分页数据丢失或者重复问题",
    "uri": "/%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/%E5%88%86%E9%A1%B5%E6%95%B0%E6%8D%AE%E4%B8%A2%E5%A4%B1%E6%88%96%E8%80%85%E9%87%8D%E5%A4%8D%E9%97%AE%E9%A2%98/"
  },
  {
    "content": "动态规划问题的一般形式就是求最值。动态规划其实是运筹学的一种最优化方法，只不过在计算机问题上应用比较多，比如说让你求最长递增子序列呀，最小编辑距离呀等等。\n既然是要求最值，核心问题是什么呢？求解动态规划的核心问题是穷举。因为要求最值，肯定要把所有可行的答案穷举出来，然后在其中找最值呗。\n动态规划这么简单，就是穷举就完事了？我看到的动态规划问题都很难啊！\n首先，动态规划的穷举有点特别，因为这类问题存在「重叠子问题」，如果暴力穷举的话效率会极其低下，所以需要「备忘录」或者「DP table」来优化穷举过程，避免不必要的计算。\n而且，动态规划问题一定会具备「最优子结构」，才能通过子问题的最值得到原问题的最值。\n另外，虽然动态规划的核心思想就是穷举求最值，但是问题可以千变万化，穷举所有可行解其实并不是一件容易的事，只有列出正确的「状态转移方程」，才能正确地穷举。\n以上提到的重叠子问题、最优子结构、状态转移方程就是动态规划三要素。具体什么意思等会会举例详解，但是在实际的算法问题中，写出状态转移方程是最困难的，这也就是为什么很多朋友觉得动态规划问题困难的原因，我来提供我研究出来的一个思维框架，辅助你思考状态转移方程：\n明确 base case -\u003e 明确「状态」-\u003e 明确「选择」 -\u003e 定义 dp 数组/函数的含义。\n按上面的套路走，最后的结果就可以套这个框架：\n初始化 base case dp[0][0][…] = base\n进行状态转移 for 状态1 in 状态1的所有取值：\nfor 状态2 in 状态2的所有取值：\nfor …\ndp[状态1][状态2][…] = 求最值(选择1，选择2…)\n",
    "description": "",
    "tags": null,
    "title": "动态规划",
    "uri": "/%E7%AE%97%E6%B3%95%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"
  },
  {
    "content": "保证测试用例顺序 @FixMethodOrder(MethodSorters.NAME_ASCENDING)\nMVC 1、使用ContextConfiguration 指定spring 配置文件 2、在spring配置文件内配置自己需要加载的bean\n@RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration(locations = {\"classpath:spring-test-config.xml\"}) public class DrugGuidelineRepositoryTest { } \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cbeans xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns=\"http://www.springframework.org/schema/beans\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"\u003e \u003cimport resource=\"classpath*:spring-datasource.xml\"/\u003e \u003cimport resource=\"classpath*:spring-bean.xml\"/\u003e \u003c/beans\u003e \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cbeans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\"\u003e \u003ccontext:component-scan base-package=\"com.benmu.mts.baseinfo.domain.drugguideline\"\u003e \u003c/context:component-scan\u003e \u003c/beans\u003e Spring boot @RunWith(SpringRunner.class) @ActiveProfiles(“justdb”)\n@SpringBootTest(classes = DrugTestApp.class, webEnvironment = SpringBootTest.WebEnvironment.NONE)\nSpringRunner is alias for the SpringJUnit4ClassRunner.\n",
    "description": "",
    "tags": null,
    "title": "单元测试",
    "uri": "/spring/%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95/"
  },
  {
    "content": "描述的是数据流、信息流方向\n单工： 只支持数据在一个方向上传输，只有一方能接受或者发送。（广播模式） 半双工： 可以双向通讯，但是不能同时传输。（对讲机模式） 全双工（双工）duplex： 可以同时双方都接受和发送消息。（电话模式）\n",
    "description": "",
    "tags": null,
    "title": "单工、半双工、全双工",
    "uri": "/%E7%A1%AC%E4%BB%B6/%E5%8D%95%E5%B7%A5%E5%8D%8A%E5%8F%8C%E5%B7%A5%E5%85%A8%E5%8F%8C%E5%B7%A5/"
  },
  {
    "content": "曾经，北桥芯片和南桥芯片都是主板芯片组中最重要的组成部分。传统来说，靠上方的叫北桥，靠下方的叫南桥。北桥负责与CPU通信，并且连接高速设备（内存/显卡），并且与南桥通信；南桥负责与低速设备（硬盘/USB）通信，时钟/BIOS/系统管理/旧式设备控制，并且与北桥通信。\n“桥”的意思是指通信，桥两边匹配的是不同的速度。\n连接关系如下：\nCPU——北桥——内存\nCPU——北桥——显卡\nCPU——北桥——南桥——硬盘\nCPU——北桥——南桥——网卡\nCPU——北桥——南桥——PS/2键鼠\nCPU——北桥——南桥——USB设备\n如今北桥被集成到CPU内，io控制模块，南桥成为了PCIE-hub\n",
    "description": "",
    "tags": null,
    "title": "南北桥",
    "uri": "/%E7%A1%AC%E4%BB%B6/%E5%8D%97%E5%8C%97%E6%A1%A5/"
  },
  {
    "content": " title: “链表反转” date: 2021-08-08T21:42:40+08:00 draft: false 链表反转 链表\n1-\u003e2-\u003e3-\u003e4\n翻转\n4-\u003e3-\u003e2-\u003e1\n主要难点是防止Next被替换，下一个节点无法访问\n方式1： 使用临时变量保存Last和Next\n/** * Definition for singly-linked list. * type ListNode struct { * Val int * Next *ListNode * } */ func reverseList(head *ListNode) *ListNode { var lastNode,nextNode *ListNode for(head!=nil){ nextNode=head.Next head.Next=lastNode lastNode=head head=nextNode } //注意这里是返回前一个节点，因为head最后指向了nextNode是空的 return lastNode } 方式2：递归 从最末尾开始递归交换 3-4-\u003e4-3，1，2，(4，3)-\u003e1,(4,3),2\n",
    "description": "",
    "tags": null,
    "title": "双向链表",
    "uri": "/%E7%AE%97%E6%B3%95%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E5%8F%8C%E5%90%91%E9%93%BE%E8%A1%A8/"
  },
  {
    "content": "\n",
    "description": "",
    "tags": null,
    "title": "双指针",
    "uri": "/%E7%AE%97%E6%B3%95%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E5%8F%8C%E6%8C%87%E9%92%88/"
  },
  {
    "content": "https://zhuanlan.zhihu.com/p/476222316 嵌套jar包:Nested JARs java 没有提供给任何标准方式加载嵌套的jar文件（嵌套jar文件，就是跟jar包里面还有jar包，spring boot项目常常打成一个jar包就能启动，这是spring为我们提供给的便利），如果需要命令行运行一个不需要解包就可以运行的自包含应用程序会遇到麻烦。 为了解决这个问题，许多开发者使用“影子”jar。影子jar包包含了所有jar包的所有classes，是一个超级就jar包（uber jar）。但是使用影子 jar将会很难分别哪个jar包实际在使用。并且如果不同jar包有相同文件名的文件，也会有问题。springboot 使用了不同的放解决嵌套jar包的问题。\njar文件结构 example.jar | +-META-INF | +-MANIFEST.MF +-org | +-springframework | +-boot | +-loader | +-\u003cspring boot loader classes\u003e +-BOOT-INF +-classpath.idx +-layers.idx +-classes 项目的class文件 | +-mycompany | +-project | +-YourClasses.class +-lib 依赖的jar包 +-dependency1.jar +-dependency2.jar 索引文件 classpath.idx 提供了jar添加到classpath的顺序，对jar和war包都支持 layer.idx jar包内的文件清单，只对jar包支持\nSpring Boot’s “JarFile” Class 支持加载嵌套jar的核心类是org.springframework.boot.loader.jar.JarFile，他让你可以从标准的jar文件和子jar文件加载数据。当第一次加载时，会形成一个带offset物理映射，就像下面这样。\nmyapp.jar +-------------------+-------------------------+ | /BOOT-INF/classes | /BOOT-INF/lib/mylib.jar | |+-----------------+||+-----------+----------+| || A.class ||| B.class | C.class || |+-----------------+||+-----------+----------+| +-------------------+-------------------------+ ^ ^ ^ 0063 3452 3980 通过这种方式我们可以不必解开归档的文件加载嵌套实体，我们也不必把所有数据加载到内存里。\n",
    "description": "",
    "tags": null,
    "title": "启动",
    "uri": "/spring/springboot/%E5%90%AF%E5%8A%A8/"
  },
  {
    "content": "/etc/\n",
    "description": "",
    "tags": null,
    "title": "启动执行脚本",
    "uri": "/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/%E5%90%AF%E5%8A%A8%E6%89%A7%E8%A1%8C%E8%84%9A%E6%9C%AC/"
  },
  {
    "content": "统计某个目录下所有文件的字符数 find . -type f|grep .md |tr \\n \\0|xargs -0 cat|wc -m\n统计日志中某个数值次数 zcat request.log.2022-10-28.gz |grep uri=/mobile/wx/card/select |awk ‘BEGIN{FS=\" “} {print $2,$5}’|awk -F ’time=’ ‘{if($2 \u003e 500) print $1,$2}’\n",
    "description": "",
    "tags": null,
    "title": "命令组合",
    "uri": "/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/%E5%91%BD%E4%BB%A4%E7%BB%84%E5%90%88/"
  },
  {
    "content": "回溯法是求解某些问题的全部或部分解的通用算法，特别是带有限制条件的问题。它通过不断的产生问题的完整解的片段并不断增长完整解的片段来获取该问题的完整解。当发现某个完整解的片段不能生成最后的完整解时，就会丢弃所有以该片段解为基础的完整解。\n回溯法会首先列出完整解的片段的一个集合。这个集合原则上可以通过不同的方式最后给出给定的问题的所有解。这是通过不断地对该完整解的片段的集合中的片段解不断扩展而达到的。\n回溯（backtrack），一般用于求所有可能解，需要遍历所有数据。 解决一个回溯问题，实际上就是一个决策树的遍历过程。你只需要思考 3 个问题： 1、路径：也就是已经做出的选择。 2、选择列表：也就是你当前可以做的选择。 3、结束条件：也就是到达决策树底层，无法再做选择的条件。 result = [] def backtrack(路径, 选择列表): if 满足结束条件: result.add(路径) return\nfor 选择 in 选择列表: 做选择 backtrack(路径, 选择列表) 撤销选择 简单例子： 98 . 验证二叉搜索树 给你一个二叉树的根节点 root ，判断其是否是一个有效的二叉搜索树。\n有效 二叉搜索树定义如下：\n节点的左子树只包含 小于 当前节点的数。 节点的右子树只包含 大于 当前节点的数。 所有左子树和右子树自身必须也是二叉搜索树。\n示例 1：\n输入：root = [2,1,3] 输出：true 示例 2：\n输入：root = [5,1,4,null,null,3,6] 输出：false 解释：根节点的值是 5 ，但是右子节点的值是 4 。\n/**\nDefinition for a binary tree node. type TreeNode struct { Val int Left *TreeNode Right *TreeNode } */ func isValidBST(root *TreeNode) bool { return dst(root,math.MinInt64,math.MaxInt64) } func dst(root *TreeNode,floor,ceil int) bool{ if root==nil{ return true } if root.Val\u003c=floor || root.Val\u003e=ceil { return false } return dst(root.Left,floor,root.Val)\u0026\u0026dst(root.Right,root.Val,ceil) } 给你一个 无重复元素 的整数数组 candidates 和一个目标整数 target ，找出 candidates 中可以使数字和为目标数 target 的 所有 不同组合 ，并以列表形式返回。你可以按 任意顺序 返回这些组合。\ncandidates 中的 同一个 数字可以 无限制重复被选取 。如果至少一个数字的被选数量不同，则两种组合是不同的。 对于给定的输入，保证和为 target 的不同组合数少于 150 个。\n示例 1：\n**输入：**candidates = [2,3,6,7], target = 7 输出：[[2,2,3],[7]] 解释： 2 和 3 可以形成一组候选，2 + 2 + 3 = 7 。注意 2 可以使用多次。 7 也是一个候选， 7 = 7 。 仅有这两种组合。\n示例 2：\n输入: candidates = [2,3,5], target = 8 输出: [[2,2,2,2],[2,3,3],[3,5]]\n示例 3：\n输入: candidates = [2], target = 1 输出: []\n提示：\n1 \u003c= candidates.length \u003c= 30 2 \u003c= candidates[i] \u003c= 40 candidates 的所有元素 互不相同 1 \u003c= target \u003c= 40 ",
    "description": "",
    "tags": null,
    "title": "回溯（DFS）",
    "uri": "/%E7%AE%97%E6%B3%95%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E5%9B%9E%E6%BA%AFdfs/"
  },
  {
    "content": "RAM（random-access machine）随机访问机\n假定了一种通用的单处理器处理模型，认为底层执行一条指令时间都是常量。\n指令不能太复杂（比如一条排序的指令），可以是场景的 算术指令、数据移动指令、控制指令。\n分治法：\n将原问题分解橙几个规模较小但类似的子问题，递归求解这些子问题，然后再合并这些子问题的解来建立原来的问题的解。\n三步走：分解-\u003e解决-\u003e合并\n分治可以降低时间复杂度，把大的问题化小可以使时间从，n^2 降低到nlogn，因为不在需要遍历全体数据求解。\n",
    "description": "",
    "tags": null,
    "title": "基本概念",
    "uri": "/%E7%AE%97%E6%B3%95%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/"
  },
  {
    "content": "机械同感 (mechanical sympathy)来自于赛车比赛，它反映了车手对赛车有一种内在的感觉，所以他们能够赛车达到最佳状态。然而多数程序员缺少这种对编程与硬件交互的感同身受的情感。要么是没有，要么就是以为自己有，实际上却是基于很久以前硬件工作方式而建立的概念。这说得实在是太多，作为一个程序员，在写程序时是否考虑过自己的代码能否正确地运行在底层硬件上，又是否考虑过怎样榨干硬件性能让自己的代码跑得飞快，又是否考虑过自己的代码能否被人钻了空子发生安全问题。我想这三方面也许是学习硬件工作原理的最主要因素，即让自己的代码：正确、高效、安全地在硬件上跑。简单来说就是\n快准稳！\n5Why分析法 — 分析事故根本原因 角度一 “制造”，为什么会发生？\n问题 1：为什么数据库的线程数会增加？ 答：正在执行的SQL执行时间长。 问题 2：为什么正在执行的SQL执行时间长？ 答：因为正在执行的SQL发生了死锁。 问题 3：为什么SQL会发生死锁？ 答：同时删除相同的一批数据，而删除时出现乱序。 问题 4：为什么删除相同的一批数据？ 答：代码逻辑问题，不需要重复删除。 解决方案：更改代码逻辑，避免重复删除。\n角度二 “检验”，为什么没有发现？\n问题 1：为什么代码上线几个月都没有发现？ 答：未出现大量的死锁情况。 问题 2：为什么没有出现大量的死锁情况？ 答：未出现这种造成大量并发的数据，测试用例也未覆盖。 问题 3：在小量并发数据的情况也可能发生死锁，为什么没有发现该逻辑会产生死锁？ 答：未能及时从错误日志中发现问题。 问题 4：为什么未能及时从错误日志中发现问题？ 答：错误日志中有较多无用的日志，扰乱了日志分析。 解决方案：清理代码中无用的错误日志打印，及时检查错误日志，并解决问题。\n代码是用来给人看的，顺便给机器执行 ",
    "description": "",
    "tags": null,
    "title": "大概念",
    "uri": "/%E6%9D%82%E9%A1%B9/%E5%A4%A7%E6%A6%82%E5%BF%B5/"
  },
  {
    "content": "0day漏洞： 漏洞已被发现还没有发布解决补丁。\n桥接： 简单的说就是通过网桥可以把两个不同的物理局域网连接起来，是一种在链路层实现局域网互连的存储转发设备。网桥从一个局域网接收MAC帧，拆封、校对、校验之后 ，按另一个局域网的格式重新组装,发往它的物理层，通俗的说就是通过一台设备（可能不止一个）把几个网络串起来形成的连接，比如图中就是一种通过桥接来实现无路由双机上网的连接方案。 虚拟机中的网络模式 VMware 桥接模式 VMware桥接模式，也就是将虚拟机的虚拟网络适配器与主机的物理网络适配器进行交接，虚拟机中的虚拟网络适配器可通过主机中的物理网络适配器直接访问到外部网络(例如图中所示的局域网和Internet，下同)。简而言之，这就好像在上图所示的局域网中添加了一台新的、独立的计算机一样。因此，虚拟机也会占用局域网中的一个IP地址，并且可以和其他终端进行相互访问。桥接模式网络连接支持有线和无线主机网络适配器。如果你想把虚拟机当做一台完全独立的计算机看待，并且允许它和其他终端一样的进行网络通信，那么桥接模式通常是虚拟机访问网络的最简单途径。\nVMware NAT模式 NAT，是Network Address Translation的缩写，意即网络地址转换。NAT模式也是VMware创建虚拟机的默认网络连接模式。使用NAT模式网络连接时，VMware会在主机上建立单独的专用网络，用以在主机和虚拟机之间相互通信。虚拟机向外部网络发送的请求数据\"包裹\"，都会交由NAT网络适配器加上\"特殊标记\"并以主机的名义转发出去，外部网络返回的响应数据\"包裹\"，也是先由主机接收，然后交由NAT网络适配器根据\"特殊标记\"进行识别并转发给对应的虚拟机，因此，虚拟机在外部网络中不必具有自己的IP地址。从外部网络来看，虚拟机和主机在共享一个IP地址，默认情况下，外部网络终端也无法访问到虚拟机。\n",
    "description": "",
    "tags": null,
    "title": "奇怪的小知识",
    "uri": "/%E6%9D%82%E9%A1%B9/%E5%A5%87%E6%80%AA%E7%9A%84%E5%B0%8F%E7%9F%A5%E8%AF%86/"
  },
  {
    "content": "在线流程图 https://mermaid.live/\n正则可视化 https://tooltt.com/regulex/\npython官方学习文档 docs.python.org\n朗文词典 https://www.ldoceonline.com/\n壁纸网站 https://wallhaven.cc/\n",
    "description": "",
    "tags": null,
    "title": "好用的网站",
    "uri": "/%E6%9D%82%E9%A1%B9/%E5%A5%BD%E7%94%A8%E7%9A%84%E7%BD%91%E7%AB%99/"
  },
  {
    "content": "从词源上来说： terminal是电线的末端、 shell是乌龟的壳 tty是teletype远程打字机的缩写 console是一种家具\n简单来说在unix环境下：\nterminal = tty = 文本输入/输出环境 console = 物理终端 shell = 命令行解释器 tty是一种特殊的设备文件，多数情况下tty和terminal是同义词，一些tty由内核代表硬件设备提供，ex：键盘输入。另一些的tty被称为伪tty，由终端仿真器提供。\n",
    "description": "",
    "tags": null,
    "title": "如何区分terminal、tty、console、shell",
    "uri": "/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/%E5%A6%82%E4%BD%95%E5%8C%BA%E5%88%86terminalttyconsoleshell/"
  },
  {
    "content": "场景： 库里有10亿手机号，如何快速判断一个手机号是否在数据库中。 首先对这些数据进行缓存是肯定的，有没有什么更经济的方式缓存呢，这时候布隆举着盾牌就出现了。\n布隆过滤器 布隆过滤器（Bloom Filter）是由布隆在1970年提出的。它实际上是一个很长的二进制向量（位图）和一系列随机映射函数（哈希函数）。\n布隆过滤器可以用于检索一个元素是否在一个集合中。 优点：空间效率和查询时间都比一般的算法要好的多。\n缺点有2个：\n在判断元素在集合中有误差，只有判断元素不在集合中是准确的 删除比较困难 位图（Bitmap） Redis当中有一种数据结构就是位图，布隆过滤器其中重要的实现就是位图的实现，也就是位数组，并且在这个数组中每一个位置只有0和1两种状态，每个位置只占用1个 bit，其中0表示没有元素存在，1表示有元素存在。\n如下图所示就是一个简单的布隆过滤器示例（一个key值经过哈希运算和位运算就可以得出应该落在哪个位置）：\n哈希 上面我们发现，lonely和wolf落在了同一个位置，这种不同的key值经过哈希运算后得到相同值的现象就称之为哈希碰撞。发生哈希碰撞之后再经过位运算，那么最后肯定会落在同一个位置。\n如果发生过多的哈希碰撞，就会影响到判断的准确性，所以为了减少哈希碰撞，我们一般会综合考虑以下2个因素：\n增大位图数组的大小（位图数组越大，占用的内存越大）。 增加哈希函数的次数（同一个key值经过1个函数相等了，那么经过2个或者更多个哈希函数的计算，都得到相等结果的概率就自然会降低了）。 上面两个方法我们需要综合考虑：比如增大位数组，那么就需要消耗更多的空间，而经过越多的哈希计算也会消耗cpu影响到最终的计算时间，所以位数组到底多大，哈希函数次数又到底需要计算多少次合适需要具体情况具体分析。\n删除元素 布隆过滤器判断一个元素存在就是判断对应位置是否为1来确定的，但是如果要删除掉一个元素是不能直接把1改成0的，因为这个位置可能存在其它元素，所以如果要支持删除，那我们应该怎么做呢？\n最简单的做法就是加一个计数器，就是说位数组的每个位如果不存在就是0，存在几个元素就存具体的数字，而不仅仅只是存1。那么这就有一个问题，本来存1就是一位就可以满足了，但是如果要存具体的数字比如说2，那就需要2位了，所以带有计数器的布隆过滤器会占用更大的空间。\n",
    "description": "",
    "tags": null,
    "title": "布隆过滤器",
    "uri": "/%E4%B8%AD%E9%97%B4%E4%BB%B6/redis/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8/"
  },
  {
    "content": "计数器法 计数器法是限流算法里最简单也是最容易实现的一种算法。比如我们规定，对于A接口来说，我们1分钟的访问次数不能超过100个。那么我们可以这么做：在一开始的时候，我们可以设置一个计数器counter，每当一个请求过来的时候，counter就加1，如果counter的值大于100并且该请求与第一个 请求的间隔时间还在1分钟之内，那么说明请求数过多；如果该请求与第一个请求的间隔时间大于1分钟，且counter的值还在限流范围内，那么就重置 counter。\n滑动时间窗口算法 滑动时间窗口，又称rolling window。为了解决计数器法统计精度太低的问题，引入了滑动窗口算法。下面这张图，很好地解释了滑动窗口算法：\n在上图中，整个红色的矩形框表示一个时间窗口，在我们的例子中，一个时间窗口就是一分钟。然后我们将时间窗口进行划分，比如图中，我们就将滑动窗口划成了6格，所以每格代表的是10秒钟。每过10秒钟，我们的时间窗口就会往右滑动一格。每一个格子都有自己独立的计数器counter，比如当一个请求 在0:35秒的时候到达，那么0:30~0:39对应的counter就会加1。\n计数器算法其实就是滑动窗口算法。只是它没有对时间窗口做进一步地划分，所以只有1格。\n由此可见，当滑动窗口的格子划分的越多，那么滑动窗口的滚动就越平滑，限流的统计就会越精确。\n漏桶算法 漏桶算法，又称leaky bucket。\n从图中我们可以看到，整个算法其实十分简单。首先，我们有一个固定容量的桶，有水流进来，也有水流出去。对于流进来的水来说，我们无法预计一共有多少水会流进来，也无法预计水流的速度。但是对于流出去的水来说，这个桶可以固定水流出的速率。而且，当桶满了之后，多余的水将会溢出。\n我们将算法中的水换成实际应用中的请求，我们可以看到漏桶算法天生就限制了请求的速度。当使用了漏桶算法，我们可以保证接口会以一个常速速率来处理请求。所以漏桶算法天生不会出现临界问题。\n令牌桶算法 令牌桶算法，又称token bucket。同样为了理解该算法，我们来看一下该算法的示意图：\n从图中我们可以看到，令牌桶算法比漏桶算法稍显复杂。首先，我们有一个固定容量的桶，桶里存放着令牌（token）。桶一开始是空的，token以 一个固定的速率r往桶里填充，直到达到桶的容量，多余的令牌将会被丢弃。每当一个请求过来时，就会尝试从桶里移除一个令牌，如果没有令牌的话，请求无法通过。\n",
    "description": "",
    "tags": null,
    "title": "常见限流算法",
    "uri": "/%E7%AE%97%E6%B3%95%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E5%B8%B8%E8%A7%81%E9%99%90%E6%B5%81%E7%AE%97%E6%B3%95/"
  },
  {
    "content": "\n",
    "description": "",
    "tags": null,
    "title": "广度优先（BFS）",
    "uri": "/%E7%AE%97%E6%B3%95%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88bfs/"
  },
  {
    "content": "https://blog.51cto.com/u_3631118/3121421\n",
    "description": "",
    "tags": null,
    "title": "异步模式",
    "uri": "/spring/mvc/%E5%BC%82%E6%AD%A5%E6%A8%A1%E5%BC%8F/"
  },
  {
    "content": "\n",
    "description": "",
    "tags": null,
    "title": "微信授权登录",
    "uri": "/%E6%9D%82%E9%A1%B9/%E5%BE%AE%E4%BF%A1%E6%8E%88%E6%9D%83%E7%99%BB%E5%BD%95/"
  },
  {
    "content": "\n",
    "description": "",
    "tags": null,
    "title": "排序",
    "uri": "/%E7%AE%97%E6%B3%95%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%8E%92%E5%BA%8F/"
  },
  {
    "content": "https://www.yuque.com/books/share/227872c0-1f19-4c83-960e-5e13e39343c8/fi6mb2\n为了防止出现内存地址碰撞，操作系统引入了虚拟内存，进程持有的虚拟地址会通过 CPU 芯片中的内存管理单元（MMU）的映射关系，来转换变成物理地址，然后再通过物理地址访问内存。\n互斥与同步： 互斥：不能同时执行 同步：要求按照顺序执行\n系统调用： http://c.biancheng.net/view/1195.html\n",
    "description": "",
    "tags": null,
    "title": "操作系统",
    "uri": "/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"
  },
  {
    "content": "\n",
    "description": "",
    "tags": null,
    "title": "数据结构",
    "uri": "/%E7%AE%97%E6%B3%95%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"
  },
  {
    "content": "touch 修改文件的创建和修改时间，现在常用于创建一个文件。\nfind find path -name “支持 * ？” [-delete]\ngrep ln ln -s 软连接 ln 硬连接，软连接更常用，不存在文件时也可以创建软连接，类似于快捷方式。硬连接是指向一个文件实体的指针，文件夹不创建硬连接，不同文件系统或者硬件不能创建硬连接，硬连接可以多人共享文件，防止误删。\n",
    "description": "",
    "tags": null,
    "title": "文件相关",
    "uri": "/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/%E6%96%87%E4%BB%B6%E7%9B%B8%E5%85%B3/"
  },
  {
    "content": " cat: 直接把文件一次性输出\nmore：在打开一个很大的文件的时，vim等工具会把整个文件加载到内存，但是有时我们只是简单的查看一下，此时可以用到more\nless：less是more是一个升级版，正所谓 less is more\nless 常用参数 意义 -N 展示行号 命令 意义 space 下一页 b 上半页 u 上半页 d 下半页 tr 文本替换工具 ex：把换行符替换为null值\ntr \\\\n \\\\0 ",
    "description": "",
    "tags": null,
    "title": "文本相关",
    "uri": "/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/%E6%96%87%E6%9C%AC%E7%9B%B8%E5%85%B3/"
  },
  {
    "content": "GMT时间： 格林威治时间，以本初子午线为0时区，每个时区调整时区显示。\nUTC时间： utc格式：UTC本地时间 = UTC标准时间 拼上 时间偏移量。 ex:若现在UTC时间是 10:30z（z表示偏移量=0，不可省略），则北京时间为 10:30 +0800、纽约时间为 10:30 -0500，分别表示同日下午6点半、同日上午五点半。\nISO8601标准时间格式： 基于utc时间，前端时间为时区时间方便使用，后段时间为时区偏移量，方便辨别。 ex:2021-03-01T18:03:24.208+08:00 java中的时间 可以用Instant代替 Date，LocalDateTime代替 Calendar，DateTimeFormatter 代替 SimpleDateFormat。\n",
    "description": "",
    "tags": null,
    "title": "时间",
    "uri": "/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%97%B6%E9%97%B4/"
  },
  {
    "content": "datetime 包 datetime类 根据String 生成datetime datetime.datetime.strptime('2017-3-22 15:25','%Y-%m-%d %H:%M') https://docs.python.org/3/library/datetime.html#examples-of-usage-datetime\n",
    "description": "",
    "tags": null,
    "title": "时间处理",
    "uri": "/python/%E6%97%B6%E9%97%B4%E5%A4%84%E7%90%86/"
  },
  {
    "content": "[[事务]]\n本地事务 Local Transaction 单一数据源，依赖数据库实现一致性。\n数据库实现方案 原子性\u0026持久性 众所周知，数据必须要成功写入磁盘、磁带等持久化存储器后才能拥有持久性，只存储在内存中的数据，一旦遇到应用程序忽然崩溃，或者数据库、操作系统一侧的崩溃，甚至是机器突然断电宕机等情况就会丢失，后文我们将这些意外情况都统称为“崩溃”（Crash）。实现原子性和持久性的最大困难是“写入磁盘”这个操作并不是原子的，不仅有“写入”与“未写入”状态，还客观地存在着“正在写”的中间状态。正因为写入中间状态与崩溃都不可能消除，所以如果不做额外保障措施的话，将内存中的数据写入磁盘，并不能保证原子性与持久性。下面通过具体事例来说明。\n未提交事务，写入后崩溃：程序还没修改完三个数据，但数据库已经将其中一个或两个数据的变动写入磁盘，此时出现崩溃，一旦重启之后，数据库必须要有办法得知崩溃前发生过一次不完整的购物操作，将已经修改过的数据从磁盘中恢复成没有改过的样子，以保证原子性。 已提交事务，写入前崩溃：程序已经修改完三个数据，但数据库还未将全部三个数据的变动都写入到磁盘，此时出现崩溃，一旦重启之后，数据库必须要有办法得知崩溃前发生过一次完整的购物操作，将还没来得及写入磁盘的那部分数据重新写入，以保证持久性。 为了能够顺利地完成崩溃恢复，在磁盘中写入数据就不能像程序修改内存中变量值那样，直接改变某表某行某列的某个值，而是必须将修改数据这个操作所需的全部信息，包括修改什么数据、数据物理上位于哪个内存页和磁盘块中、从什么值改成什么值，等等，以日志的形式——即仅进行顺序追加的文件写入的形式（这是最高效的写入方式）先记录到磁盘中。只有在日志记录全部都安全落盘，数据库在日志中看到代表事务成功提交的“提交记录”（Commit Record）后，才会根据日志上的信息对真正的数据进行修改，修改完成后，再在日志中加入一条“结束记录”（End Record）表示事务已完成持久化，这种事务实现方法被称为“Commit Logging”（提交日志）。\nCommit Logging 保障数据持久性、原子性的原理：首先，日志一旦成功写入 Commit Record，那整个事务就是成功的，即使真正修改数据时崩溃了，重启后根据已经写入磁盘的日志信息恢复现场、继续修改数据即可，这保证了持久性；其次，如果日志没有成功写入 Commit Record 就发生崩溃，那整个事务就是失败的，系统重启后会看到一部分没有 Commit Record 的日志，那将这部分日志标记为回滚状态即可，整个事务就像完全没好有发生过一样，这保证了原子性。\ncommit logging 在提交之前不允许写入磁盘会占用个过多内存缓冲区，性能不高。针对这个问题提出了Write-Ahead Logging方案。 Write-Ahead Logging： 所谓“提前写入”（Write-Ahead），就是允许在事务提交之前，提前写入变动数据的意思。 Write-Ahead Logging 先将何时写入变动数据，按照事务提交时点为界，划分为 FORCE 和 STEAL 两类情况。\nFORCE：当事务提交后，要求变动数据必须同时完成写入则称为 FORCE，如果不强制变动数据必须同时完成写入则称为 NO-FORCE。现实中绝大多数数据库采用的都是 NO-FORCE 策略，因为只要有了日志，变动数据随时可以持久化，从优化磁盘 I/O 性能考虑，没有必要强制数据写入立即进行。 STEAL：在事务提交前，允许变动数据提前写入则称为 STEAL，不允许则称为 NO-STEAL。从优化磁盘 I/O 性能考虑，允许数据提前写入，有利于利用空闲 I/O 资源，也有利于节省数据库缓存区的内存。 write-Ahead logging 恢复 分析阶段（Analysis）：该阶段从最后一次检查点（Checkpoint，可理解为在这个点之前所有应该持久化的变动都已安全落盘）开始扫描日志，找出所有没有 End Record 的事务，组成待恢复的事务集合，这个集合至少会包括 Transaction Table 和 Dirty Page Table 两个组成部分。 重做阶段（Redo）：该阶段依据分析阶段中产生的待恢复的事务集合来重演历史（Repeat History），具体操作为：找出所有包含 Commit Record 的日志，将这些日志修改的数据写入磁盘，写入完成后在日志中增加一条 End Record，然后移除出待恢复事务集合。 回滚阶段（Undo）：该阶段处理经过分析、重做阶段后剩余的恢复事务集合，此时剩下的都是需要回滚的事务，它们被称为 Loser，根据 Undo Log 中的信息，将已经提前写入磁盘的信息重新改写回去，以达到回滚这些 Loser 事务的目的。 - FORCE STEAL Commit Logging redo log x Write-Ahead Loggin redo log undo log 隔离性： 隔离性是保证，不同事务之间读和写之间不影响。这天生和并发有关，这时需要解决并发的重要手段：锁。 数据库为了隔离性一般会提供三种锁：\n写锁 -排它锁-exclusiveLock-XLock：如果数据加了写锁，只有持有写锁的事务才能对数据进行写操作，数据加锁时，其他事务不能写入也不能加读锁。 读锁-共享锁-ShareLock-SLock:多个事务可以对同一数据添加读锁，添加以后其他事务不能对其写入数据，但仍然可以对读取。对于持有读锁的事务，如果只有自己持有读锁那么允许升级为写锁，写入数据。 范围锁（RangeLock）：对于某个范围直接加排它锁，这个范围内的数据不能写入，和一组排它锁不一样，在这个范围不可新增和删除数据。 隔离级别 存在问题 描述 读取未提交 脏读+之后 会读到其他事务未提交的事务 读取已提交 不可重复读+之后 对同一行数据的两次查询得到了不同的结果。 可重复读 幻读\u0026write skew 两个完全相同的范围查询得到了不同的结果集。 串行化 对读和写入的数据全部加上读锁、写锁、范围锁，可实现串行化，性能比较差，相当于一条一条执行。 除了都以锁来实现外，以上四种隔离级别还有另一个共同特点，就是幻读、不可重复读、脏读等问题都是由于一个事务在读数据过程中，受另外一个写数据的事务影响而破坏了隔离性，针对这种“一个事务读+另一个事务写”的隔离问题，近年来有一种名为“多版本并发控制”（Multi-Version Concurrency Control，MVCC）的无锁优化方案被主流的商业数据库广泛采用。MVCC 是一种读取优化策略，它的“无锁”是特指读取时不需要加锁。MVCC 的基本思路是对数据库的任何修改都不会直接覆盖之前的数据，而是产生一个新版副本与老版本共存，以此达到读取时可以完全不加锁的目的。在这句话中，“版本”是个关键词，你不妨将版本理解为数据库中每一行记录都存在两个看不见的字段：CREATE_VERSION 和 DELETE_VERSION，这两个字段记录的值都是事务 ID，事务 ID 是一个全局严格递增的数值，然后根据以下规则写入数据\n插入数据时：CREATE_VERSION 记录插入数据的事务 ID，DELETE_VERSION 为空。 删除数据时：DELETE_VERSION 记录删除数据的事务 ID，CREATE_VERSION 为空。 修改数据时：将修改数据视为“删除旧数据，插入新数据”的组合，即先将原有数据复制一份，原有数据的 DELETE_VERSION 记录修改数据的事务 ID，CREATE_VERSION 为空。复制出来的新数据的 CREATE_VERSION 记录修改数据的事务 ID，DELETE_VERSION 为空。 此时，如有另外一个事务要读取这些发生了变化的数据，将根据隔离级别来决定到底应该读取哪个版本的数据。\n隔离级别是可重复读：总是读取 CREATE_VERSION 小于或等于当前事务 ID 的记录，在这个前提下，如果数据仍有多个版本，则取最新（事务 ID 最大）的。 隔离级别是读已提交：总是取最新的版本即可，即最近被 Commit 的那个版本的数据记录。 另外两个隔离级别都没有必要用到 MVCC，因为读未提交直接修改原始数据即可，其他事务查看数据的时候立刻可以看到，根本无须版本字段。可串行化本来的语义就是要阻塞其他事务的读取操作，而 MVCC 是做读取时无锁优化的，自然就不会放到一起用。\nMVCC 是只针对“读+写”场景的优化，如果是两个事务同时修改数据，即“写+写”的情况，那就没有多少优化的空间了，此时加锁几乎是唯一可行的解决方案，\nMySQL：\nPostgreSQL：\n关于 MySQL Repeatable Read Isolation 常见的三个误区 https://cloud.tencent.com/developer/article/1676633\n",
    "description": "",
    "tags": null,
    "title": "本地事务",
    "uri": "/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%9C%AC%E5%9C%B0%E4%BA%8B%E5%8A%A1/"
  },
  {
    "content": "@Conditional \u0026 Condition @Conditional是Spring4新提供的注解，它的作用是按照一定的条件进行判断，满足条件给容器注册bean。 @Conditional 注解允许引入多个Condition\n@Retention(RetentionPolicy.RUNTIME) @Target({ElementType.TYPE, ElementType.METHOD}) public @interface Conditional { /** * All {@link Condition}s that must {@linkplain Condition#matches match} * in order for the component to be registered. */ Class\u003c? extends Condition\u003e[] value(); } 我们可以根据自己的需求实现Condition，满足条件时bean才会被加载，同时如果bean上添加了@Import和@ComponentScan时，在满足条件后才会加载\npublic interface Condition { boolean matches(ConditionContext context, AnnotatedTypeMetadata metadata); } spring boot时代 spring boot 时代，扩展了@Conditional的功能，并在springboot内部大力使用。 @ConditionalOnMissingClass \u0026 @ConditionalOnClass 就拿比常用的@ConditionalOnMissingClass举例子\n@Target({ ElementType.TYPE, ElementType.METHOD }) @Retention(RetentionPolicy.RUNTIME) @Documented @Conditional(OnClassCondition.class) public @interface ConditionalOnMissingClass { /** * The names of the classes that must not be present. * @return the names of the classes that must not be present */ String[] value() default {}; } 使用了@Conditional注解，使用的condition是OnClassCondition，那我们就来看一下onClassCondition 其中springBootCondition实现了matches，其核心是getMatchOutcome方法，其实现是在OnClassCondition内。\n@Override public ConditionOutcome getMatchOutcome(ConditionContext context, AnnotatedTypeMetadata metadata) { ClassLoader classLoader = context.getClassLoader(); ConditionMessage matchMessage = ConditionMessage.empty(); List\u003cString\u003e onClasses = getCandidates(metadata, ConditionalOnClass.class); if (onClasses != null) { List\u003cString\u003e missing = filter(onClasses, ClassNameFilter.MISSING, classLoader); if (!missing.isEmpty()) { return ConditionOutcome.noMatch(ConditionMessage.forCondition(ConditionalOnClass.class) .didNotFind(\"required class\", \"required classes\").items(Style.QUOTE, missing)); } matchMessage = matchMessage.andCondition(ConditionalOnClass.class) .found(\"required class\", \"required classes\") .items(Style.QUOTE, filter(onClasses, ClassNameFilter.PRESENT, classLoader)); } List\u003cString\u003e onMissingClasses = getCandidates(metadata, ConditionalOnMissingClass.class); if (onMissingClasses != null) { List\u003cString\u003e present = filter(onMissingClasses, ClassNameFilter.PRESENT, classLoader); if (!present.isEmpty()) { return ConditionOutcome.noMatch(ConditionMessage.forCondition(ConditionalOnMissingClass.class) .found(\"unwanted class\", \"unwanted classes\").items(Style.QUOTE, present)); } matchMessage = matchMessage.andCondition(ConditionalOnMissingClass.class) .didNotFind(\"unwanted class\", \"unwanted classes\") .items(Style.QUOTE, filter(onMissingClasses, ClassNameFilter.MISSING, classLoader)); } return ConditionOutcome.match(matchMessage); } 其中关键的是ClassNameFilter类。\nprotected enum ClassNameFilter { PRESENT { @Override public boolean matches(String className, ClassLoader classLoader) { return isPresent(className, classLoader); } }, MISSING { @Override public boolean matches(String className, ClassLoader classLoader) { return !isPresent(className, classLoader); } }; public abstract boolean matches(String className, ClassLoader classLoader); public static boolean isPresent(String className, ClassLoader classLoader) { if (classLoader == null) { classLoader = ClassUtils.getDefaultClassLoader(); } try { forName(className, classLoader); return true; } catch (Throwable ex) { return false; } } private static Class\u003c?\u003e forName(String className, ClassLoader classLoader) throws ClassNotFoundException { if (classLoader != null) { return classLoader.loadClass(className); } return Class.forName(className); } } dicing世纪是使用ClassLoader尝试加载类，根据异常情况返回是否存在。\n",
    "description": "",
    "tags": null,
    "title": "条件加载",
    "uri": "/spring/%E6%9D%A1%E4%BB%B6%E5%8A%A0%E8%BD%BD/"
  },
  {
    "content": "学习一手spring的注视，不再抓瞎。\n/** * Return the auto-configuration class names that should be considered. By default * this method will load candidates using {@link SpringFactoriesLoader} with * {@link #getSpringFactoriesLoaderFactoryClass()}. * @param metadata the source metadata * @param attributes the {@link #getAttributes(AnnotationMetadata) annotation * attributes} * @return a list of candidate configurations */ ",
    "description": "",
    "tags": null,
    "title": "注释",
    "uri": "/java/%E6%B3%A8%E9%87%8A/"
  },
  {
    "content": "删除用户 先用命令 cat /etc/passwd 查看一下所有的用户 可以看到你需要删除的用户名 用命令 who 查询当前登录的用户 用命令 ps -u 用户名 查看该用户的pid 用命令 kill pid 杀掉他的sshd或者是shell进程 再用命令 userdel -r 用户名 删除用户 ",
    "description": "",
    "tags": null,
    "title": "用户相关",
    "uri": "/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/%E7%94%A8%E6%88%B7%E7%9B%B8%E5%85%B3/"
  },
  {
    "content": "java类加载过程 其中loadClass的类加载过程有如下几步:\n加载 » 验证 » 准备 » 解析 » 初始化 » 使用 » 卸载\n加载:在硬盘上查找并通过IO读入字节码文件，使用到类时才会加载，例如调用类的 main()方法，new对象等等，在加载阶段会在内存中生成一个代表这个类的 java.lang.Class对象，作为方法区这个类的各种数据的访问入口\n验证:校验字节码文件的正确性 准备:给类的静态变量分配内存，并赋予默认值\n解析:将符号引用替换为直接引用，该阶段会把一些静态方法(符号引用，比如main()方法)替换为指向数据所存内存的指针或句柄等(直接引用)，这是所谓的静态链接过 程(类加载期间完成)，动态链接是在程序运行期间完成的将符号引用替换为直接引用\n初始化:对类的静态变量初始化为指定的值，执行静态代码块\n类被加载到方法区中后主要包含 运行时常量池、类型信息、字段信息、方法信息、类加载器的 引用、对应class实例的引用等信息。\nClassLoader 所有类加载器的基类，它是抽象的，定义了类加载最核心的操作。所有继承与classloader的加载器，都会优先判断是否被父类加载器加载过，防止多次加载，防止加载冲突。看一下核心代码loadClass\nprotected Class\u003c?\u003e loadClass(String name, boolean resolve) throws ClassNotFoundException { // 加锁防止重复加载 synchronized (getClassLoadingLock(name)) { // First, check if the class has already been loaded Class\u003c?\u003e c = findLoadedClass(name); if (c == null) { long t0 = System.nanoTime(); try { if (parent != null) { c = parent.loadClass(name, false); } else { //找不到父classLoader就是最顶级的classLoader：bootstrapClassLoader c = findBootstrapClassOrNull(name); } } catch (ClassNotFoundException e) { // ClassNotFoundException thrown if class not found // from the non-null parent class loader } if (c == null) { // If still not found, then invoke findClass in order // to find the class. long t1 = System.nanoTime(); c = findClass(name); // this is the defining class loader; record the stats sun.misc.PerfCounter.getParentDelegationTime().addTime(t1 - t0); sun.misc.PerfCounter.getFindClassTime().addElapsedTimeFrom(t1); sun.misc.PerfCounter.getFindClasses().increment(); } } if (resolve) { resolveClass(c); } return c; } } BootStrapClassLoader 位于java.lang.classload，所有的classload都要经过这个classload判断是否已经被加载过，采用native code实现，是JVM的一部分，主要加载JVM自身工作需要的类，如java.lang.、java.uti.等； 这些类位于$JAVA_HOME/jre/lib/rt.jar。Bootstrap ClassLoader不继承自ClassLoader，因为它不是一个普通的Java类，底层由C++编写，已嵌入到了JVM内核当中，当JVM启动后，Bootstrap ClassLoader也随着启动，负责加载完核心类库后，并构造Extension ClassLoader和App ClassLoader类加载器。\n/** * Returns a class loaded by the bootstrap class loader; * or return null if not found. */private Class\u003c?\u003e findBootstrapClassOrNull(String name) { if (!checkName(name)) return null; return findBootstrapClass(name); } // 这里就是native了 // return null if not found private native Class\u003c?\u003e findBootstrapClass(String name); SecureClassLoader 继承了ClassLoader，主要是对ClassLoader进行了限制，只允许加载指定路径下的class\nURLClassLoader 继承自secureClassLoader，这个类加载器用于从引用JAR文件和目录的url的搜索路径加载类和资源。任何以“/”结尾的URL都被认为指向目录。否则，URL被假定为引用一个JAR文件，该文件将在需要时打开。 创建URLClassLoader实例的线程的AccessControlContext将在随后加载类和资源时使用。 默认情况下，被加载的类只被授予访问创建URLClassLoader时指定的url的权限。\n打破双亲委派 tomcat\n相关资料： https://blog.csdn.net/weixin_50020236/article/details/124098698\n",
    "description": "",
    "tags": null,
    "title": "类加载",
    "uri": "/java/jvm/%E7%B1%BB%E5%8A%A0%E8%BD%BD/"
  },
  {
    "content": "PUSH模式 为每个订阅的用户推消息 缺点：大V推送的用户太多\nPULL模式 用户上线以后去拉去新消息 缺点：比较复杂，而且要多次查询再排序\n",
    "description": "",
    "tags": null,
    "title": "类微博feed流",
    "uri": "/%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/%E7%B1%BB%E5%BE%AE%E5%8D%9Afeed%E6%B5%81/"
  },
  {
    "content": "系统资源 top 定义：display sorted information about processes\n展示项目 描述 CPU Percentage of processor usage, broken into user, system, and idle components. The time period for which these percentages are calculated depends on the event counting mode. Disks Number and total size of disk reads and writes. LoadAvg Load average over 1, 5, and 15 minutes. The load average is the average number of jobs in the run queue. MemRegions Number and total size of memory regions, and total size of memory regions broken into private (broken into non-library and library) and shared components. Networks Number and total size of input and output network packets PhysMem Physical memory usage, broken into wired, active, inactive, used, and free components. Procs Total number of processes and number of processes in each process state. SharedLibs Resident sizes of code and data segments, and link editor memory usage. Threads Number of threads. iotop 磁盘情况查看 ulimit 查看系统资源限制 -a 列出所有当前资源极限\n-c 设置core文件的最大值.单位:blocks\n-d 设置一个进程的数据段的最大值.单位:kbytes\n-f Shell 创建文件的文件大小的最大值，单位：blocks\n-h 指定设置某个给定资源的硬极限。如果用户拥有 root 用户权限，可以增大硬极限。任何用户均可减少硬极限\n-l 可以锁住的物理内存的最大值\n-m 可以使用的常驻内存的最大值,单位：kbytes\n-n 每个进程可以同时打开的最大文件数\n-p 设置管道的最大值，单位为block，1block=512bytes\n-s 指定堆栈的最大值：单位：kbytes\n-S 指定为给定的资源设置软极限。软极限可增大到硬极限的值。如果 -H 和 -S 标志均未指定，极限适用于以上二者\n-t 指定每个进程所使用的秒数,单位：seconds\n-u 可以运行的最大并发进程数\n-v Shell可使用的最大的虚拟内存，单位：kbytes\n网络相关 netstat netstat -atl\n参数 解释 -a 列出所有 -l 只查看listen端口 -v 增加详细程度，特别是通过添加一列来显示与每个打开的端口关联的进程ID(pid) -p Show the PID and name of the program to which each socket belongs. -u udp -t tcp - lsof mac下查看网络端口查看 lsof - list open files 在linux下一切皆文件，一个网络连接也是一个文件。 lsof -i 查看网络连接的文件 在mac系统下netstat是简化版的，用lsof 替代\nifconfig lo0 :localhost eth0:eth0是光纤以太网接口卡。学名FiberEthernetAdapter0\nexport 环境变量相关操作 Linux export 命令用于设置或显示环境变量。\n在 shell 中执行程序时，shell 会提供一组环境变量。export 可新增，修改或删除环境变量，供后续执行的程序使用。export 的效力仅限于该次登陆操作，如果在配置文件中添加可以持续有效。 export [-fnp][变量名称]=[变量设置值]\n-f 代表[变量名称]中为函数名称。 -n 删除指定的变量。变量实际上并未删除，只是不会输出到后续指令的执行环境中。 -p 列出所有的shell赋予程序的环境变量。 例子 在.zprofile 里面 export WS=/Users/yuwenhao/Programs/work-space\n",
    "description": "",
    "tags": null,
    "title": "系统监控命令",
    "uri": "/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/%E7%B3%BB%E7%BB%9F%E7%9B%91%E6%8E%A7%E5%91%BD%E4%BB%A4/"
  },
  {
    "content": "埃筛法 ",
    "description": "",
    "tags": null,
    "title": "素数计算",
    "uri": "/%E7%AE%97%E6%B3%95%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E7%B4%A0%E6%95%B0%E8%AE%A1%E7%AE%97/"
  },
  {
    "content": "\n",
    "description": "",
    "tags": null,
    "title": "经典算法目录",
    "uri": "/%E7%AE%97%E6%B3%95%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/leetcode%E7%BB%8F%E5%85%B8100%E9%A2%98/%E7%BB%8F%E5%85%B8%E7%AE%97%E6%B3%95%E7%9B%AE%E5%BD%95/"
  },
  {
    "content": "基础信息 名字解释 mat = matrix (矩阵) 制图时常常需要使用到运算，同理matlab中的mat也是这个意思。 plot= 绘制\n官方网站： https://matplotlib.org/stable/index.html\n概念： import matplotlib as mpl import matplotlib.pyplot as plt import numpy as np figure 画板，包含多个axes和artists\nfig = plt.figure() # an empty figure with no Axes\nfig, ax = plt.subplots() # a figure with a single Axes fig, axs = plt.subplots(2, 2) # a figure with a 2x2 grid of Axes axes 轴集合, 可以是x轴y轴，3d的会有z轴。\naxis 轴\nartist everything visible on the Figure is an Artist\n相关问题 中文显示问题 1、先输出所有字体，找到中文字体\nimport matplotlib.font_manager a = sorted([f.name for f in matplotlib.font_manager.fontManager.ttflist]) for i in a: print(i) 2、设置对应字体\nplt.rcParams[\"font.sans-serif\"] = [\"Songti SC\"] # 设置字体 ",
    "description": "",
    "tags": null,
    "title": "绘图库matplotlib",
    "uri": "/python/%E7%BB%98%E5%9B%BE%E5%BA%93matplotlib/"
  },
  {
    "content": "缓存雪崩 原因：\n大量缓存数据同时失效，导致某一瞬间之后，相当于没有缓存。\n解决：\n缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。 设置热点数据永远不过期。 缓存击穿 原因：\n从击穿这个字眼上来看，是有瞬间大量的请求过来，访问同一资源。这时候会有大量请求直接访问db。\n解决：\n设置热点数据永远不过期。 加互斥锁。 缓存穿透 原因：\n大量请求绕过缓存访问db里面不存在的数据，例如访问id=-1的数据，这时候也会给db造成较大压力。\n解决：\n接口对参数进行基本的校验id\u003e0 短时间缓存null值数据 ",
    "description": "",
    "tags": null,
    "title": "缓存雪崩、缓存击穿、缓存穿透",
    "uri": "/%E4%B8%AD%E9%97%B4%E4%BB%B6/redis/%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9%E7%BC%93%E5%AD%98%E5%87%BB%E7%A9%BF%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F/"
  },
  {
    "content": "spring boot 2.7之前 依赖 @SpringBootApplication–\u003e@EnableAutoConfiguration， 而EnableAutoConfiguration 又@Import({AutoConfigurationImportSelector.class})，所以主要看AutoConfigurationImportSelector。\nprotected List\u003cString\u003e getCandidateConfigurations(AnnotationMetadata metadata, AnnotationAttributes attributes) { List\u003cString\u003e configurations = SpringFactoriesLoader.loadFactoryNames(this.getSpringFactoriesLoaderFactoryClass(), this.getBeanClassLoader()); Assert.notEmpty(configurations, \"No auto configuration classes found in META-INF/spring.factories. If you are using a custom packaging, make sure that file is correct.\"); return configurations; } 可以看到，所以主要看AutoConfigurationImportSelector 扫描了jar包下的META-INF/spring.factories。把autoConfig的类取出来然后执行。\nspring boot 2.7以后 更加标准的使用spi的方式，按照/META-INF/spring/org.springframework.boot.autoconfigure.AutoConfiguration.imports，层级创建文件，文件内添加autoConfig的类即可。\n",
    "description": "",
    "tags": null,
    "title": "自动配置",
    "uri": "/spring/springboot/%E8%87%AA%E5%8A%A8%E9%85%8D%E7%BD%AE/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "限流",
    "uri": "/%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/%E9%99%90%E6%B5%81/"
  },
  {
    "content": "什么是零拷贝 “零”：表示次数是0，它表示拷贝数据的次数是0\n“拷贝”：指数据从一个存储区域转移到另一个存储区域\n合起来，那零拷贝就是不需要将数据从一个存储区域复制到另一个存储区域。\n零拷贝是指计算机执行IO操作时，CPU不需要将数据从一个存储区域复制到另一个存储区域，进而减少上下文切换以及CPU的拷贝时间。它是一种IO操作优化技术。\n传统IO的执行流程 比如想实现一个下载功能，服务端的任务就是：将服务器主机磁盘中的文件从已连接的socket中发出去，关键代码如下\nwhile((n = read(diskfd, buf, BUF_SIZE)) \u003e 0)\nwrite(sockfd, buf , n);\n传统的IO流程包括read以及write的过程\nread:将数据从磁盘读取到内核缓存区中，在拷贝到用户缓冲区\nwrite:先将数据写入到socket缓冲区中，最后写入网卡设备\n流程图如下 1.应用程序调用read函数，向操作系统发起IO调用，上下文从用户态切换至内核态\n2.DMA控制器把数据从磁盘中读取到内核缓冲区\n3.CPU把内核缓冲区数据拷贝到用户应用缓冲区，上下文从内核态切换至用户态，此时read函数返回\n4.用户应用进程通过write函数，发起IO调用，上下文从用户态切换至内核态\n5.CPU将缓冲区的数据拷贝到socket缓冲区\n6.DMA控制器将数据从socket缓冲区拷贝到网卡设备，上下文从内核态切换至用户态，此时write函数返回\n从流程图中可以看出传统的IO流程包括4次上下文的切换，4次拷贝数据(两次CPU拷贝以及两次DMA拷贝)\n前置知识 内核空间和用户空间 我们电脑上跑着的应用程序，其实是需要经过操作系统，才能做一些特殊操作，如磁盘文件读写、内存的读写等等。因为这些都是比较危险的操作，不可以由应用程序乱来，只能交给底层操作系统来。\n因此，操作系统为每个进程都分配了内存空间，一部分是用户空间，一部分是内核空间。内核空间是操作系统内核访问的区域，是受保护的内存空间，而用户空间是用户应用程序访问的内存区域。 以32位操作系统为例，它会为每一个进程都分配了4G(2的32次方)的内存空间。\n内核空间：主要提供进程调度、内存分配、连接硬件资源等功能\n用户空间：提供给各个程序进程的空间，它不具有访问内核空间资源的权限，如果应用程序需要使用到内核空间的资源，则需要通过系统调用来完成。进程从用户空间切换到内核空间，完成相关操作后，再从内核空间切换回用户空间。\n用户态和内核态 如果进程运行于内核空间，被称为进程的内核态。\n如果进程运行于用户空间，被称为进程的用户态。\n什么是上下文切换 什么是上下文\nCPU 寄存器，是CPU内置的容量小、但速度极快的内存。而程序计数器，则是用来存储 CPU 正在执行的指令位置、或者即将执行的下一条指令位置。它们都是 CPU 在运行任何任务前，必须的依赖环境，因此叫做CPU上下文。\n什么是上下文切换\n它是指，先把前一个任务的CPU上下文（也就是CPU寄存器和程序计数器）保存起来，然后加载新任务的上下文到这些寄存器和程序计数器，最后再跳转到程序计数器所指的新位置，运行新任务。\n一般我们说的上下文切换，就是指内核（操作系统的核心）在CPU上对进程或者线程进行切换。进程从用户态到内核态的转变，需要通过系统调用来完成。系统调用的过程，会发生CPU上下文的切换。 虚拟内存 现代操作系统使用虚拟内存，即虚拟地址取代物理地址，使用虚拟内存可以有2个好处：\n1.虚拟内存空间可以远远大于物理内存空间\n2.多个虚拟内存可以指向同一个物理地址\n正是多个虚拟内存可以指向同一个物理地址，可以把内核空间和用户空间的虚拟地址映射到同一个物理地址，这样的话，就可以减少IO的数据拷贝次数，示意图如下 DMA技术 DMA，英文全称是Direct Memory Access，即直接内存访问。DMA本质上是一块主板上独立的芯片，允许外设设备和内存存储器之间直接进行IO数据传输，其过程不需要CPU的参与。\n简单的说它就是帮住CPU转发一下IO请求以及拷贝数据，那为什么需要它呢？其实主要是效率问题。它帮忙CPU做事情，这时候，CPU就可以闲下来去做别的事情，提高了CPU的利用效率。大白话解释就是，CPU老哥太忙太累啦，所以他找了个小弟（名叫DMA） ，替他完成一部分的拷贝工作，这样CPU老哥就能着手去做其他事情。\n下面看下DMA具体是做了哪些工作\n1.用户应用程序调read函数，向操作系统发起IO调用，进入阻塞状态等待数据返回\n2.CPU接到指令后，对DMA控制器发起指令调度\n3.DMA收到请求后，将请求发送给磁盘\n4.磁盘将数据放入磁盘控制缓冲区并通知DMA\n5.DMA将数据从磁盘控制器缓冲区拷贝到内核缓冲区\n6.DMA向CPU发送数据读完的信号，CPU负责将数据从内核缓冲区拷贝到用户缓冲区\n7.用户应用进程由内核态切回用户态，解除阻塞状态\n如何实现零拷贝 零拷贝并不是没有拷贝数据，而是减少用户态、内核态的切换次数以及CPU拷贝次数；实现零拷贝主要有三种方式分别是\n1.mmap + write\n2.sendfile\n3.带有DMA收集拷贝功能的sendfile\nmmap mmap的函数原型如下\nvoid *mmap(void *addr, size_t length, int prot, int flags, int fd, off_t offset);\naddr:指定映射的虚拟内存地址\nlength:映射的长度\nprot:映射内存的保护模式\nflags:指定映射的类型\nfd:进行映射的文件句柄\noffset:文件偏移量\n前面一小节，我们介绍了虚拟内存，可以把内核空间和用户空间的虚拟地址映射到同一个物理地址，从而减少数据拷贝次数！mmap就是用了虚拟内存这个特点，它将内核中的读缓冲区与用户空间的缓冲区进行映射，所有的IO都在内核中完成。mmap+write实现的零拷贝流程如下：\n1.用户进程通过调用mmap方法向操作系统内核发起IO调用，上下文从用户态切换至内核态\n2.CPU利用DMA控制器，将数据从硬盘拷贝到内核缓冲区\n3.上下文从内核态切换回用户态，mmap方法返回\n4.用户进程通过调用write方法向操作系统内核再次发起IO调用，上下文从用户态切换至内核态\n5.CPU将内核缓冲区的数据拷贝到socket缓冲区\n6.CPU利用DMA控制器，将数据从socket缓冲器拷贝到网卡，上下文从内核态切换至用户态，write方法返回\n可以发现，mmap+write实现的零拷贝其中发生了4次上线文切换以及3次拷贝(2次DMA拷贝+1次cpu拷贝)\nsendfile sendfile是Linux2.1版本后内核引入 的一个系统调用函数，原型如下\nssize_t sendfile(int out_fd, int in_fd, off_t *offset, size_t count);\nout_fd:为待写入内容的文件描述符\nin_fd:为待读出内容的文件描述符\noffset:文件偏移量\ncount:指定在fdout和fdin之间传输的字节数\nsendfile表示在两个文件描述符之间传输数据，它是在操作系统内核中操作的，避免了数据从内核缓冲区和用户缓冲区之间的拷贝操作，因此可以使用它来实现零拷贝。sendfile实现的零拷贝流程如下：\n1.用户进程发起sendfile系统调用，上下文从用户态切换至内核态\n2.DMA控制器将数据从硬盘拷贝到内核缓冲区\n3.CPU将读缓冲区中的数据拷贝到socket缓冲区\n4.DMA控制器异步把数据从socket缓冲器拷贝到网卡\n5.上下文从内核态切换至用户态，sendfile函数返回\n可以发现，sendfile实现的零拷贝仅仅发生了2次上下文切换以及3次拷贝(2次DMA拷贝+1次CPU拷贝)\nsendfile +DMA scatter/gather实现的零拷贝\nlinux2.4版本后，对sendfile做了优化升级，引入SG-DMA技术，其实就是对DMA拷贝加入了scatter/gather操作，它可以直接从内核空间缓冲区中将数据读取到网卡，这样的话还可以省去CPU拷贝。\n1.用户进程发起sendfile系统调用，上下文从用户态切换至内核态\n2.DMA控制器将数据从磁盘拷贝到内核缓冲器\n3.CPU把内核缓冲区中的文件描述符信息（包括内核缓冲区的内存地址和偏移量）直接发送到socket缓冲区\n4.DMA控制器根据文件描述符信息直接把数据从内核缓冲区拷贝到网卡\n5.上下文切换至用户态，sendfile返回\n可以发现sendfile + DMA scatter/gather实现的零拷贝发生了2次上下文切换以及2次数据拷贝，这就是真正的零拷贝技术，全程没有通过CPU来搬运数据，所有的数据都是通过DMA进行传输的。\njava提供的零拷贝方式 mmap Java NIO有一个MappedByteBuffer的类可以用来实现内存映射。它的底层是调用的linux内核的mmap的API\npublic class MmapTest { public static void main(String[] args) { try { FileChannel readChannel = FileChannel.open(Paths.get(\"./jay.txt\"), StandardOpenOption.READ); MappedByteBuffer data = readChannel.map(FileChannel.MapMode.READ_ONLY, 0, 1024 * 1024 * 40); FileChannel writeChannel = FileChannel.open(Paths.get(\"./siting.txt\"), StandardOpenOption.WRITE, StandardOpenOption.CREATE); //数据传输 writeChannel.write(data); readChannel.close(); writeChannel.close(); }catch (Exception e){ System.out.println(e.getMessage()); } } } sendfile FileChannel的transferTo()/transferFrom()，底层就是sendfile() 系统调用函数。Kafka 这个开源项目就用到它，平时面试的时候，回答面试官为什么这么快，就可以提到零拷贝sendfile这个点\npublic class SendFileTest { public static void main(String[] args) { try { FileChannel readChannel = FileChannel.open(Paths.get(\"./jay.txt\"), StandardOpenOption.READ); long len = readChannel.size(); long position = readChannel.position(); FileChannel writeChannel = FileChannel.open(Paths.get(\"./siting.txt\"), StandardOpenOption.WRITE, StandardOpenOption.CREATE); //数据传输 readChannel.transferTo(position, len, writeChannel); readChannel.close(); writeChannel.close(); } catch (Exception e) { System.out.println(e.getMessage()); } } } ",
    "description": "",
    "tags": null,
    "title": "零拷贝",
    "uri": "/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/%E9%9B%B6%E6%8B%B7%E8%B4%9D/"
  },
  {
    "content": "Redis 缓存雪崩、缓存击穿、缓存穿透的概念和解决方案 缓存雪崩： 描述： 大量缓存集中失效，查询数据量很大，引起数据库压力过大。 解决方案：\n缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。 设置热点数据永远不过期。 缓存击穿： 描述: 缓存击穿是指缓存中没有但数据库中有的数据（一般是缓存时间到期），这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力 解决方案：\n设置热点数据永远不过期。 加互斥锁，解锁后重入。 缓存穿透： 描述 大量访问数据库中不存在缓存中也不存在的数据，导致数据库压力过大，也是攻击的一种手段。 解决方案：\n接口层增加校验，如用户鉴权校验，id做基础校验，id\u003c=0的直接拦截； 从缓存取不到的数据，在数据库中也没有取到，这时也可以将key-value对写为key-null，缓存有效时间可以设置短点，如30秒（设置太长会导致正常情况也没法使用）。这样可以防止攻击用户反复用同一个id暴力攻击 如何实现接口幂等 token方式 先下发token，完成之后再清除token\n乐观锁 基于乐观锁来控制版本\n分布式事务 1、2pc\n死锁 如果在一个系统中以下四个条件同时成立，那么就能引起死锁：\n互斥：至少有一个资源必须处于非共享模式，即一次只有一个进程可使用。如果另一进程申请该资源，那么申请进程应等到该资源释放为止。 占有并等待：—个进程应占有至少一个资源，并等待另一个资源，而该资源为其他进程所占有。 非抢占：资源不能被抢占，即资源只能被进程在完成任务后自愿释放。 循环等待：有一组等待进程 {P0，P1，…，Pn}，P0 等待的资源为 P1 占有，P1 等待的资源为 P2 占有，……，Pn-1 等待的资源为 Pn 占有，Pn 等待的资源为 P0 占有。 解决死锁： 1、打破四个必要条件之一即可，比如检测是否会产生循环，长时间获取不到资源就失败等等 2、在产生死锁后，检测然后回复。\n大多数程序都不会考虑死锁问题\n",
    "description": "",
    "tags": null,
    "title": "面试题整理",
    "uri": "/interview/%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/"
  },
  {
    "content": "MySQL PREPARE 语句简介 在MySQL 4.1版之前，查询以文本格式发送到MySQL服务器。反过来，MySQL使用文本协议将数据返回给客户端。MySQL必须 完全 解析查询并将结果集转换为字符串，然后再将其返回给客户端。\n文本协议具有严重的性能影响。为了解决这个问题，MySQL从4.1版开始添加了一个名为prepared的新功能。\n准备好的语句利用客户端/服务器二进制协议。它将包含占位符（？）的查询传递给MySQL服务器，如下例所示：\nSELECT * FROM products WHERE productCode = ?;\n当MySQL使用不同的productcode值执行此查询时，它不必完全解析查询。因此，这有助于MySQL更快地执行查询，尤其是当MySQL多次执行查询时。因为预准备语句使用占位符（？），这有助于避免SQL注入的许多变体，从而使您的应用程序更安全。\nMySQL PREPARE 语句用法 为了使用MySQL预处理语句，您需要使用其他三个MySQL语句，如下所示：\nPREPARE - 准备要执行的语句。 EXECUTE - 执行由PREPARE语句准备的预准备语句。 DEALLOCATE PREPARE - 发布准备好的声明。 下图说明了如何使用预准备语句：\nMySQL编写了语句实例 让我们看一下使用MySQL预处理语句的示例。\nPREPARE stmt1 FROM ‘SELECT productCode, productName FROM products WHERE productCode = ?’;\nSET @pc = ‘S10_1678’; EXECUTE stmt1 USING @pc;\nDEALLOCATE PREPARE stmt1;\n首先，我们使用PREPARE语句准备执行语句。我们使用 SELECT语句根据指定的产品代码查询products表中的产品数据 。我们使用问号（？）作为产品代码的占位符。\n接下来，我们声明了一个产品代码变量 @pc并将其值设置为S10_1678。\n然后，我们使用EXECUTE语句用产品代码变量执行预准备语句@pc。\n最后，我们用它 DEALLOCATE PREPARE来发布准备好的声明。\n",
    "description": "",
    "tags": null,
    "title": "预处理",
    "uri": "/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql/%E9%A2%84%E5%A4%84%E7%90%86/"
  },
  {
    "content": "费曼学习法 计划制定 决策时需要消耗很多意志力，最后通常只会选择最舒适的事。避免避免决策疲劳。\n前一天晚上想好第二天要干啥 不重要事情 养成习惯在碎片化的时间完成不重要的事情，买东西、背单词、等在公交车上、午饭时等时间完成。\n核心任务化繁为简 普通人集中精力完成任务大概6小时：\n3+2原则：3个大任务 1-2小时。2个小任务半小时 135原则：1个大任务、3个中任务、5个小任务。 自己设定，根据自己实际情况来，如果任务太多就适当减少。 分解任务更具有执行性 任务如果很大，那么这个任务通常很难启动，那就拆分任务，那么任务将更具有执行性。\n",
    "description": "",
    "tags": null,
    "title": "高效人生",
    "uri": "/%E8%83%A1%E8%AF%8C%E5%85%AB%E6%89%AF%E5%A4%A7%E9%81%93%E7%90%86/%E9%AB%98%E6%95%88%E4%BA%BA%E7%94%9F/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "高效开发",
    "uri": "/%E6%9D%82%E9%A1%B9/%E9%AB%98%E6%95%88%E5%BC%80%E5%8F%91/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "aop",
    "uri": "/spring/aop/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "Categories",
    "uri": "/categories/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "content",
    "uri": "/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "docker\u0026k8s",
    "uri": "/dockerk8s/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "elasticsearch",
    "uri": "/%E4%B8%AD%E9%97%B4%E4%BB%B6/elasticsearch/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "Excalidraw",
    "uri": "/excalidraw/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "golang",
    "uri": "/golang/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "interview",
    "uri": "/interview/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "java",
    "uri": "/java/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "jvm",
    "uri": "/java/jvm/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "leetcode经典100题",
    "uri": "/%E7%AE%97%E6%B3%95%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/leetcode%E7%BB%8F%E5%85%B8100%E9%A2%98/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "lib",
    "uri": "/java/lib/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "linux",
    "uri": "/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "mvc",
    "uri": "/spring/mvc/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "mysql",
    "uri": "/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "office",
    "uri": "/office/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "python",
    "uri": "/python/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "redis",
    "uri": "/%E4%B8%AD%E9%97%B4%E4%BB%B6/redis/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "rocketmq",
    "uri": "/%E4%B8%AD%E9%97%B4%E4%BB%B6/rocketmq/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "spring",
    "uri": "/spring/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "springboot",
    "uri": "/spring/springboot/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "Tags",
    "uri": "/tags/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "中间件",
    "uri": "/%E4%B8%AD%E9%97%B4%E4%BB%B6/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "分布式",
    "uri": "/%E5%88%86%E5%B8%83%E5%BC%8F/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "工具",
    "uri": "/%E5%B7%A5%E5%85%B7/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "并发编程",
    "uri": "/java/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "操作系统",
    "uri": "/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "数据库",
    "uri": "/%E6%95%B0%E6%8D%AE%E5%BA%93/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "杂项",
    "uri": "/%E6%9D%82%E9%A1%B9/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "权限控制",
    "uri": "/%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/%E6%9D%83%E9%99%90%E6%8E%A7%E5%88%B6/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "硬件",
    "uri": "/%E7%A1%AC%E4%BB%B6/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "算法\u0026数据结构",
    "uri": "/%E7%AE%97%E6%B3%95%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "类库\u0026框架",
    "uri": "/%E7%B1%BB%E5%BA%93%E6%A1%86%E6%9E%B6/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "胡诌八扯大道理",
    "uri": "/%E8%83%A1%E8%AF%8C%E5%85%AB%E6%89%AF%E5%A4%A7%E9%81%93%E7%90%86/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "解决方案",
    "uri": "/%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "计算机基础",
    "uri": "/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"
  }
]

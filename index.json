[
  {
    "content": "@Configuration+@Bean\n@Configuration public class AppConfig{ @Bean public JDBCTempalte t1(){ } @Bean public TranslationManager transactionManager(){ } @Bean public DataSource dataSource(){ xxx } } @Bean 修饰方法后，方法名作为beanname 加入叫spring容器 被Configuration修饰以后，该对象将变成代理对象，在获取bean修饰的方法时，如果spring容器有bean则会直接返回，没有会执行并生成bean\n",
    "description": "",
    "tags": null,
    "title": "@Configuration",
    "uri": "/spring/configuration/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "arthas",
    "uri": "/%E5%B7%A5%E5%85%B7/arthas/"
  },
  {
    "content": "操作字节码生成代理类\nClass UserServiceProxy extends UserService{ public void test(){ //切面逻辑 super.test() } //切面逻辑 }\n",
    "description": "",
    "tags": null,
    "title": "cglib",
    "uri": "/java/cglib/"
  },
  {
    "content": "领域驱动设计 Domain-driven design (DDD) is a major software design approach, focusing on modelling software to match a domain according to input from that domain’s experts. —wikipedia\n领域驱动是一种软件设计方式，聚焦于软件模型和领域专家（十分了解具体业务的人）的输出相匹配。\n解决的问题-系统老化 软件总是从简单发展到复杂，老化的原因主要是，真实世界和软件世界存在差异，并随着需求变更逐渐拉大。\n传统数据驱动设计存在的问题 传统MVC架构倾向于从数据库ER图开始进行设计。随着业务越来越多，变化越来越，事务脚本会越来越复杂，可能一个类里面有大量的逻辑。这时候系统将逐渐老化。 数据驱动和领域驱动 Data Driven Design –\u003e Domain Driven Design\n领域驱动设计是一种面向变化的一种设计，设计的核心模型从数据驱动的数据库表转移到领域模型。领域模型将由开发人员和领域专家共同设计，这样实际的模型将更贴近真实世界。\n优点 代码更贴近真实世界，需求调整变更 更容易 逻辑更内聚，代码复用度更高，也更易于测试 业务逻辑不再需要背负技术债，根据业务场景变化开发即可 缺点 DDD并非银弹\n概念多，学习成本高，难上手，新手往往不知所措。如果不熟悉DDD的思想，生硬地照搬ddd的规范，写出来的代码可能比传统的三层架构还糟糕，得不偿失。 实现一个功能写的代码量比传统的三层架构多 模型之间转换操作比较多，编码繁琐 概念 *领域：某一类业务相关知识的集合，在一个领域下应使用统一语言对概念描述 *统一语言（UL）：从业务中提炼出来的概念术语，领域专家、产品、开发可以互相理解的沟通语言 *子域：一个子域是领域的一部分 *实体（Entity）：具有唯一标识，有状态（程序需要追踪其状态的变化），具有生命周期、mutable的领域对象 *值对象（valueObject）：没有唯一标识、无状态、无生命周期、可复用、immutable的领域对象，类似基本类型int、long、String *聚合：一组具有关联关系领域对象，可包含实体和值对象 *聚合根：聚合的根，可以理解为可以代表整体概念的实体，操作子实体和值对象需要通过聚合根遍历，类似树形数据结构的根节点，这样可以保证数据的完整性 *领域事件：某个操作触发的事件，领域事件可以跟踪领域对象生命周期的状态变化过程。例如一个实体经过多次修改，每次产生一个实体修改事件，把所有实体修改事件按发生的顺序可以重建某个时间点的快照对象。领域事件也是同一个用例操作多个聚合的实现方式 *领域服务：同一个操作中需要操作到多个聚合根对象的逻辑需要抽到领域服务，或者同一个聚合中可以被多个用例复用的公共逻辑 实体和值对象如何区别： 主要是通过有没有唯一标识确定，相同的对象在不同场景可能表现不同，比如用户的收货地址和订单的收货地址，用户的收货地址是实体，而订单的收货地址可能就是值对象，如果用户的收货地址改变，订单的收货地址是不会变的。\n开发流程：\n首先对需要处理的业务问题进行总览。 然后领域对象(Entity)进行划分，明确每个领域对象的包含的信息和职责边界。 并进行跨对象，多对象的逻辑组织(Domain Service) 接着在上层应用中根据业务描述去编排Entity和Domain Service。 最后再做一些下水道工作，去对下层的数据访问，RPC调用去做一些具体实现。 CQRS ： 按照领域建模固然很好，但是面对各种各样的查询条件和表单时，仅仅依赖领域对象和聚合来组织代码时，往往会显得很笨拙，但是如果我们放宽对查询的要求，可以在不破坏模型的情况下，尽可能的保证查询的效率和灵活性。这就引出了CQRS\nCQRS全称Command Query Responsibility Segregation，即命令查询职责分离，顾名思义，将命令和查询分离。\n查询，就是查询数据（CRUD中的R），不会对数据产生变化，因此它是幂等的,不用担心对系统产生影响，因此也可以针对查询添加缓存操作提升查询性能。\n那命令是啥呢？这里命令则是对数据产生变化的操作的总称（CRUD中的CUD）。\n大多数软件系统中，查询频率要远大于命令操作，这是将查询与命令分离的根本原因。\n通过CQRS模式将读模型和写模型分离，使得我们可以优化读性能和写性能之外，还可以让我们的代码更加清晰简洁，更加体现出领域，更易维护。\n一些比较好的例子 CQRS：https://zhuanlan.zhihu.com/p/505023604 https://developer.aliyun.com/article/719251 https://juejin.cn/post/7131186996277411876\n",
    "description": "",
    "tags": null,
    "title": "DDD Domain-Driven Design",
    "uri": "/%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/ddd-domain-driven-design/"
  },
  {
    "content": "简介 docker compose用于更加方便的管理docker容器，采用yml文件配置的方式代替，敲入docker命令，配置时更加清晰，也更适合多个节点配置。\nhub.docker.com\n配置文件编写 docker compose 详解\n",
    "description": "",
    "tags": null,
    "title": "docker compose",
    "uri": "/dockerk8s/docker-compose/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "dubbo",
    "uri": "/%E5%88%86%E5%B8%83%E5%BC%8F/dubbo/"
  },
  {
    "content": "统计字符出现个数 =LEN(G13)-LEN(SUBSTITUTE(G13,\"、\",\"\"))+1\n",
    "description": "",
    "tags": null,
    "title": "excel公式",
    "uri": "/office/excel%E5%85%AC%E5%BC%8F/"
  },
  {
    "content": "开启GC日志 打开gc日志：-XX:+PrintGCDetails 指定输入位置：-Xloggc:$LOGS_DIR/gc.log\n分析日志 GC (Allocation Failure)造成的young gc。\ngc日志头 解释 GC (Allocation Failure) Allocation Failure表示向young generation(eden)给新对象申请空间，但是young generation(eden)剩余的合适空间不够所需的大小导致的minor gc。 Full GC (Ergonomics) 默认使用 UseParallelGC 垃圾回收器，该垃圾回收器默认启动了 AdaptiveSizePolicy。 ",
    "description": "",
    "tags": null,
    "title": "gc日志分析",
    "uri": "/java/jvm/gc%E6%97%A5%E5%BF%97%E5%88%86%E6%9E%90/"
  },
  {
    "content": "命令 命令 参数 描述 示例 checkout -b 检出一个新分支 checkout - 切换到上一个分支 branch -m 重命名分支 git branch -m 原始名称 新名称 branch -u –set-upstream 设置当前分支对应的远程分支 git branch -u origin/dev branch –unset-upstream 反向操作 git branch –unset-upstream push -f 强制本地分支推送远程分支 push -u –set-upstream push 并且 设置当前分支对应的远程分支 git branch –unset-upstream origin [分支名] rebase 把一个分支整合到另一个分支的办法有两种：merge（合并） 和 rebase（衍合）。 rebase相当于在fetch之后，重新提交数据。 千万不要在在public分支操作rebase，例如develop，不要用rebase合并自己的feature分支。 有一篇很好的文章讲merge和rebase https://www.atlassian.com/git/tutorials/merging-vs-rebasing#the-golden-rule-of-rebasing\ngit工作流程 git flow 配置 ignore 注视 folder 同名的 folder 目录、src/folder 文件、src/utils/folder 文件都会被忽略，即：不会被提交到远程仓库中。 folder/ 只忽略文件夹 ! 表示取反，不忽略xxx 通配符 星号“*” ：匹配多个字符； 双星号“**” ：匹配多个字符； 问号“?”：匹配除 ‘/’外的任意一个字符； 方括号“[xxxx]”：匹配多个列表中的字符； ",
    "description": "",
    "tags": null,
    "title": "git",
    "uri": "/%E5%B7%A5%E5%85%B7/git/"
  },
  {
    "content": "https://docs.jboss.org/hibernate/validator/6.2/reference/en-US/html_single/#validator-gettingstarted\n",
    "description": "",
    "tags": null,
    "title": "hibernate-validator 校验器",
    "uri": "/java/hibernate-validator-%E6%A0%A1%E9%AA%8C%E5%99%A8/"
  },
  {
    "content": "Cookie \u0026 Session cookie的属性 HttpOnly: 如果您在cookie中设置了HttpOnly属性，那么通过js脚本将无法读取到cookie信息，这样能有效的防止XSS攻击 path：对应url的作用域，默认是当前路径 ex：/a/b 默认是/a max-age：指定的是从文档被访问后的存活时间，这个时间是个相对值(比如:3600s),相对的是文档第一次被请求时服务器记录的Request_time(请求时间) Expires：指定的时间可以是相对文件的最后访问时间(Atime)或者修改时间(MTime),而max-age相对对的是文档的请求时间(Atime)\n删除cookie 把cookie的过期时间设为0或者过去\n",
    "description": "",
    "tags": null,
    "title": "HTTP",
    "uri": "/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/http/"
  },
  {
    "content": "X.509 是证书的标准格式。 x509是一个证书格式，证书的版本信息包含有：\n证书的序列号，每个证书都有一个唯一的证书序列号；\n证书所使用的签名算法；\n证书的发行机构名称，命名规则一般采用X.500格式；\n证书的有效期，现在通用的证书一般采用UTC时间格式，它的计时范围为1950-2049;\n证书所有人的名称，命名规则一般采用X.500格式；\n证书所有人的公开密钥；\n证书发行者对证书的签名。\nX.509文件格式\nCer/crt用于保存证书，并以没有私钥的二进制数存储。\npem和cer/crt区别是它以Ascii来表示，可以用于存放证书或者私钥。\npfx/p12用于存放个人证书/私钥。通常包含保护密码，2进制方式。\np10是证书请求。\np7r是CA对证书请求的回复，只用于导入。\np7b以树状展示证书链，同时支持单个证书，不含私钥。\n",
    "description": "",
    "tags": null,
    "title": "HTTPS",
    "uri": "/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/https/"
  },
  {
    "content": "编译大项目gc over limit 调整堆大小 ",
    "description": "",
    "tags": null,
    "title": "idea",
    "uri": "/%E5%B7%A5%E5%85%B7/idea/"
  },
  {
    "content": "TCP 建立连接 断开连接 报文内容 SYN(synchronous建立联机)\nACK(acknowledgement 确认)\nPSH(push传送)\nFIN(finish结束)\nRST(reset重置)\nURG(urgent紧急)\n每个请求都有一个顺序号 Sequence number(顺序号码)\nlinux IO TCP网络通信整体流程 服务端准备连接流程 SOCKET函数 为了执行网络I/O，我们要做的第一件事情就是调用socket函数，指定期望的协议类型。该函数会创建一个通信的端点，并返回引用该端点的文件描述符，该文件描述符也称为套接字描述符(socket descriptor)，简称sockfd。\nBIND()函数 bind()函数把一个本地协议地址赋予一个套接字。\n如果一个TCP客户端或者服务器没有调用bind绑定端口，或者指定IP地址，那么内核就会为该套接字选择一个临时端口号。\nLISTEN()函数 通过socket()函数创建了套接字之后，再执行listen()函数，会把套接字转换为一个被动套接字，指示内核应该接收指向该套接字的连接请求，并导致套接字从CLOSED状态转换到LISTEN状态。\n在客户端请求服务器之后，服务器内核会把请求套接字放入到未完成队列中： 如下图：\n服务器接收到客户端SYN请求后，于是请求套接字进入未完成连接队列，等到服务端响应了ACK和SYN完成三次握手后，于是，套接字进入已完成连接队列。已完成连接队列中的套接字可以被服务器进程执行accept函数获取到。\nACCEPT()函数 服务器一旦执行了socket()、bind()、listen()函数之后，就表示已经初始化好了监听套接字，并且把自己变为了被动套接字，等待客户端的请求。这个时候，我们需要继续调用accept()函数，让服务器进入阻塞等待获取客户端的已连接套接字。\n当进程调用accept()时，已完成连接队列中的队头将返回给进程，或者如果队列为空，那么进程将被投入睡眠，直到TCP在该队列中放入一项才唤醒它。\n在调用accept()之后，阻塞等待客户连接到达，然后获取一个已连接套接字：\n关于监听套接字和已连接套接字\n注意，这里要区分好服务端的监听套接字和已连接套接字，服务端调用socket()返回的是监听套接字，bind()和listen()函数入参也是监听套接字。\n一旦有客户端请求过来了于是产生了一个已连接套接字，后续和客户端的交互是通过这个已连接套接字进行的。监听套接字只负责监听客户端请求并获取和客户端的已连接套接字。\n客户端发起连接流程 CONNECT()函数 connect()函数由客户端调用，请求与服务端建立连接，这个函数会触发三次握手。大致流程如下：\n客户端： connect调用是的当前套接字从CLOSED状态进入SYN_SENT状态，如果节而受到了服务器的SYN+ACK响应，则转移到ESTABLISHED状态； 如果connect失败，则表示套接字不在可用，必须关闭，不能再次尝试调用connect函数； 服务端： 每当接收到SYN时，TCP在未完成连接队列中创建一个新的条目，然后响应TCP三次握手的第二个分节； 每当收到三次握手的第三个分节的时候，就把条目从未完成队列移到已完成连接队列的队尾。此时，服务端accept调用将被唤醒并得到一个已连接套接字。 注意：客户在调用connect函数之前，不是一定要调用bind函数，这个时候内核会确定源IP地址，并选择一个临时端口号作为源端口号。\n所以大家在监控TCP连接的时候，可以发现请求客户端的端口都是没有什么规律的。因为这个端口号是临时端口号。\n当服务器队列满了，有新的客户端connect请求的SYN到达时怎么办？\n这个时候，TCP会忽略这个SYN分节，也不会向客户端发送RST，好让客户TCP有机会重发SYN，以便在不久之后可以在这些队列中找到可用的空间。\n如果直接响应RST，客户的connect()调用会立刻返回错误，导致应用进程必须要处理这种情况。\n因为从服务端的角度来看，经理一个RTT之后，TCP条目就会从未完成队列移动到已完成连接队列。所以，未完成连接队列中的任何一项的存留时间是一个RTT。\n一旦connect()成功之后，客户端和服务器就可以通过数据交换相关函数进行数据交换了。\n整体流程 概念说明 1. 内核态（内核空间）和用户态（用户空间）的区别和联系？ 用户空间是用户进程所在的内存区域，系统空间是操作系统所在的内存区域。 为了保证内核的安全，处于用户态的程序只能访问用户空间，而处于内核态的程序可以访问用户空间和内核空间。 2. 文件描述符fd Linux将所有设备都当做文件来处理，文件描述符来标识每个文件对象。 当程序打开一个现有文件或者创建一个新文件时，内核向进程返回一个文件描述符。 3. 缓存IO Linux的缓存IO机制中，操作系统会将IO的数据缓存在文件系统的页缓存中，也就是说，数据会先被拷贝到操作系统内核的缓冲区，然后才会从操作系统内核的缓冲区拷贝到应用程序的地址空间。\n涉及系统调用 recvfrom： 从socket读取数据\nselect： select() allow a program to monitor multiple file descriptors, waiting until one or more of the file descriptors become “ready” for some class of I/O operation select 监控多个io操作的文件描述符，直到一个或者多个文件描述符编程ready状态\npoll： 与select类似，链表实现的，没有上限限制\nepoll： epoll就是event poll ，基于事件驱动 主要用到三个函数调用： epoll_create：创建epoll对象 epoll_ctl：把文件描述符交给epoll对象监控 epoll_wait: waits for I/O events, blocking the calling thread if no events are currently available.\nIO模型 一般而言，一个输入操作，一般会经历如下处理过程：等待数据准备好，从内核复制到进程。这里的数据复制，一般是应用进程调用了某个IO方法之后，陷入系统调用，在内核态完成的。\nlinux系统产生了下面五种网络模式的方案：\n阻塞式I/O模型 如上图，在应用进程调用 recvfrom()之后，陷入内核态，直到数据报到达并且复制到应用进程缓冲区之后才返回到用户态。\n或者在系统调用期间发生错误，也会立刻返回。\n这种I/O称为阻塞I/O。\n非阻塞式I/O模型 如上图，当我们把套接字设置为非阻塞模式的时候，内核会这样处理I/O操作：当请求的I/O操作非得把本进程投入睡眠才能完成时，就不要投入睡眠，而是返回一个错误，在上面的例子中，调用recvfrom()之后，因为数据没有准备好，所以内核直接返回一个EWOULDBLOCK错误，直到数据准备好了，才复制数据到进程空间，并返回系统调用继续处理进程逻辑。\n而应用进程会不断循环调用recvfrom()函数，这种处理方式我们称为polling(轮训)，持续到轮训内核，查看数据是否准备好。这种方式的缺点是会消耗大量的CPU时间。\n注意：当recvfrom发起系统调用发现数据准备好了，将数据从内核复制到用户空间的时候，应用进程还是会被阻塞，只不过不会阻塞在等待数据准备好这个流程，从而减少了阻塞时间。\n这种轮训对于单进程或者单线程的程序特别有用。\nI/O复用模型 I/O复用(I/O multiplexing)，指的是通过一个支持同时感知多个描述符的函数系统调用，阻塞在这个系统调用上，等待某一个或者几个描述符准备就绪，就返回可读条件。常见的如select，poll，epoll系统调用可以实现此类功能功能。这种模型不用阻塞在真正的I/O系统调用上。\n工作原理如下图所示：\n如上图，这种模型与非阻塞式I/O相比，把轮训判断数据是否准备好的处理方式替换为了通过select()系统调用的方式来实现。\n**select()是实现I/O多路复用的经典系统调用函数。**select()可以同时等待多个套接字的变为可读，只要有任意一个套接字可读，那么就会立刻返回，处理已经准备好的套接字了。\n在多线中使用阻塞I/O，即每个文件描述符一个线程，与I/O复用模型很类似，每个线程可以自由调用阻塞式I/O系统调用。\n信号驱动式I/O模型 所谓信号驱动式I/O(signal-driven I/O)，就是指在描述符准备就绪的时候，让内核发送一个SIGIO信号通知应用进程进行后续的数据读取等处理。工作原理如下图所示：\n注册了SIGIO信号处理函数，开启了信号驱动式IO之后，就可以继续执行程序了，等到数据报准备好之后，内核会发送一个SIGIO信号给应用进程，然后应用进程在信号处理函数中调用recvfrom读取数据报。\n这种模型在内核等待数据报达到期间进程不会被阻塞，可以继续执行。\n异步I/O模型 可以发现，上面所有的I/O模型都会在某一个执行点阻塞，并不是真正的异步的。接下来我们就介绍下真正的异步I/O模型(asynchronous I/O)。如下图：\n通过异步处理函数如aio_read告知内核启动某个动作，并且让内核在整个操作完成之后再通知应用进程，内核会在把数据复制到用户空间缓冲区之后再进行通知。整个IO过程应用进程都不会被阻塞。\n五种I/O模型对比 下面我们通过一个表格来总结下这五种I/O模型 下面是执行流程的对比图：\n可以很清晰的看到各种I/O模型的不同表现。\nIO多路复用 「多路复用」原常用于通讯，多个线路通过复用器共用一个高速线路，以此来减少线路的使用。 所以「IO多路复用」，也是一个类似的概念，通过一个线程来实现多个io流的管理，但是这里只是管理，具体读写还是具体线程实现的。\n",
    "description": "",
    "tags": null,
    "title": "IO相关",
    "uri": "/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/io%E7%9B%B8%E5%85%B3/"
  },
  {
    "content": "redis 命令行客户端 https://gitee.com/mirrors/iredis#using-dsn\n",
    "description": "",
    "tags": null,
    "title": "iredis",
    "uri": "/%E5%B7%A5%E5%85%B7/iredis/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "java启动参数",
    "uri": "/java/jvm/java%E5%90%AF%E5%8A%A8%E5%8F%82%E6%95%B0/"
  },
  {
    "content": "日志发展史 上古时代 jdk1.3之前 System.out.println(\"\") 问题： 没有日志级别，上线以后会有很多无关的日志，而且只能在控制台看，不方便定位。\n发展流程 log4j-\u003ejul-\u003ejcl-\u003eslf4j-\u003elog4j2-\u003elogback\nlog4j 作者ceki\n从控制台写到文件 日志信息按天和文件大小划分 划分日志等级，按日志等级记录文件 高等级日志发送邮件 异步io 格式控制\nlog4j发布以后，活的很好的反响，作者想让sun公司被纳入jdk，sun公司不接受，最后被apatch收纳。\njul jdk官方日志库 jul （java.util.logging） log4j火了以后，jdk官方自己开发了一个库jul，但是并没有被所有人 认可\nJCL 日志门面 jakarta（jdk内部的一个开发小组）Commons Logging jcl不实现日志功能，但是整合整合日志库\n依靠类加载器寻找日志库\nslf4j ceki发现JCL不好用，apache也不着急开发日志门面，自己出去单独搞了slf4j\n桥接器：slf4j 和日志框架直接 连接的工具 适配器：多个模块使用不同的日志门面和日志框架，可以别的日志框架转换到slf4j上\nlog4j2 apache 重写log4j，性能升级\nlogback ceki 也知道log4j性能问题，开发了替代log4j的高性能产品\n",
    "description": "",
    "tags": null,
    "title": "java日志",
    "uri": "/%E6%9D%82%E9%A1%B9/java%E6%97%A5%E5%BF%97/"
  },
  {
    "content": "强引用(FinalReference)： 普通引用 JVM停止运行时终止 软引用(SoftReference)： 在类似于浏览器访问页面缓存的场景，比如点击回退，如果缓存了页面就直接展示，缓存被清除了再加载也没事。 内存不足时终止 弱引用(WeakReference)： gc运行后终止 ThreadLocalMap的key，为了减少内存泄漏，在对象只有虚引用的时候，gc了就被清除了。 虚引用(PhantomReference)： 任何时候都可能\n",
    "description": "",
    "tags": null,
    "title": "java的引用类型",
    "uri": "/java/java%E7%9A%84%E5%BC%95%E7%94%A8%E7%B1%BB%E5%9E%8B/"
  },
  {
    "content": "G1 GC收集器 -XX:MaxGCPauseMillis 期望的最大GC暂停时间，默认为：200ms。 -XX:ParallelGCThreads 默认根据运行JVM计算机的可用线程数决定 -XX:G1NewSizePercent 新生代初大小，默认为：5%。 -XX:G1MaxNewSizePercent 新生代最大大小，默认为：60%。\n",
    "description": "",
    "tags": null,
    "title": "java程序的启动",
    "uri": "/java/jvm/java%E7%A8%8B%E5%BA%8F%E7%9A%84%E5%90%AF%E5%8A%A8/"
  },
  {
    "content": "bean shell ",
    "description": "",
    "tags": null,
    "title": "jmeter",
    "uri": "/%E5%B7%A5%E5%85%B7/jmeter/"
  },
  {
    "content": "查看程序中对象数量 jmap -histo pid |head -20\n",
    "description": "",
    "tags": null,
    "title": "jvm内存分析：",
    "uri": "/java/jvm/jvm%E5%86%85%E5%AD%98%E5%88%86%E6%9E%90/"
  },
  {
    "content": "![][https://note.youdao.com/yws/public/resource/e5863162eca29c2b31e8b59c9707817d/xmlnote/317C13052E514DA9B6229368DD48EDB5/105252]\nKafka核心总控制器Controller 在Kafka集群中会有一个或者多个broker，其中有一个broker会被选举为控制器(Kafka Controller)，它负责管理整个 集群中所有分区和副本的状态。\n当某个分区的leader副本出现故障时，由控制器负责为该分区选举新的leader副本。 当检测到某个分区的ISR集合发生变化时，由控制器负责通知所有broker更新其元数据信息。 当使用kafka-topics.sh脚本为某个topic增加分区数量时，同样还是由控制器负责让新分区被其他节点感知到。 Controller选举机制 在kafka集群启动的时候，会自动选举一台broker作为controller来管理整个集群，选举的过程是集群中每个broker都会 尝试在zookeeper上创建一个 /controller 临时节点，zookeeper会保证有且仅有一个broker能创建成功，这个broker就会成为集群的总控器controller。\n当这个controller角色的broker宕机了，此时zookeeper临时节点会消失，集群里其他broker会一直订阅这个临时节点，发现临时节点消失了，就竞争再次创建临时节点，就是我们上面说的选举机制，zookeeper又会保证有一个broker 成为新的controller。\n具备控制器身份的broker需要比其他普通的broker多一份职责，具体细节如下:\n监听broker相关的变化。为Zookeeper中的/brokers/ids/节点添加BrokerChangeListener，用来处理broker 增减的变化。\n监听topic相关的变化。为Zookeeper中的/brokers/topics节点添加TopicChangeListener，用来处理topic增减 的变化;为Zookeeper中的/admin/delete_topics节点添加TopicDeletionListener，用来处理删除topic的动作。\n从Zookeeper中读取获取当前所有与topic、partition以及broker有关的信息并进行相应的管理。对于所有topic 所对应的Zookeeper中的/brokers/topics/topic节点添加PartitionModificationsListener，用来监听topic中的 分区分配变化。\n更新集群的元数据信息，同步到其他普通的broker节点中。\nPartition副本选举Leader机制 controller感知到分区leader所在的broker挂了(controller监听了很多zk节点可以感知到broker存活)，controller会从 ISR列表(参数unclean.leader.election.enable=false的前提下)里挑第一个broker作为leader(第一个broker最先放进ISR 列表，可能是同步数据最多的副本)，如果参数unclean.leader.election.enable为true，代表在ISR列表里所有副本都挂 了的时候可以在ISR列表以外的副本中选leader，这种设置，可以提高可用性，但是选出的新leader有可能数据少很多。 副本进入ISR列表有两个条件:\n副本节点不能产生分区，必须能与zookeeper保持会话以及跟leader副本网络连通 副本能复制leader上的所有写操作，并且不能落后太多。(与leader副本同步滞后的副本，是由 replica.lag.time.max.ms 配置决定的，超过这个时间都没有跟leader同步过的一次的副本会被移出ISR列表) 消费者消费消息的offset记录机制 每个consumer会定期将自己消费分区的offset提交给kafka内部topic:__consumer_offsets，提交过去的时候，key是 consumerGroupId+topic+分区号，value就是当前offset的值，kafka会定期清理topic里的消息，最后就保留最新的 那条数据\n因为__consumer_offsets可能会接收高并发的请求，kafka默认给其分配50个分区(可以通过 offsets.topic.num.partitions设置)，这样可以通过加机器的方式抗大并发。\n消费者Rebalance机制 rebalance就是说如果消费组里的消费者数量有变化或消费的分区数有变化，kafka会重新分配消费者消费分区的关系。 比如consumer group中某个消费者挂了，此时会自动把分配给他的分区交给其他的消费者，如果他又重启了，那么又会 把一些分区重新交还给他。 注意:rebalance只针对subscribe这种不指定分区消费的情况，如果通过assign这种消费方式指定了分区，kafka不会进 行rebanlance。\n如下情况可能会触发消费者rebalance\n消费组里的consumer增加或减少了 2. 动态给topic增加了分区 消费组订阅了更多的topic rebalance过程中，消费者无法从kafka消费消息，这对kafka的TPS会有影响，如果kafka集群内节点较多，比如数百 个，那重平衡可能会耗时极多，所以应尽量避免在系统高峰期的重平衡发生。\nkafka在redis中存的内容 ",
    "description": "",
    "tags": null,
    "title": "kafka",
    "uri": "/%E4%B8%AD%E9%97%B4%E4%BB%B6/kafka/"
  },
  {
    "content": "LDAP是轻量目录访问协议,英文全称是Lightweight Directory Access Protocol,一般都简称为LDAP.\n现在市场上有关LDAP的产品已有很多,各大软件公司都在他们的产品中集成了LDAP服务,如Microsoft的ActiveDirectory、Lotus的Domino Directory、IBM的WebSphere中也集成了LDAP服务.LDAP的开源实现是OpenLDAP,它比商业产品一点也不差,而且源码开放.\nOpenLDAP是最常用的目录服务之一,它是一个由开源社区及志愿者开发和管理的一个开源项目,提供了目录服务的所有功能,包括目录搜索、身份认证、安全通道、过滤器等等.大多数的Linux发行版里面都带有OpenLDAP的安装包.OpenLDAP服务默认使用非加密的TCP/IP协议来接收服务的请求,并将查询结果传回到客户端.由于大多数目录服务都是用于系统的安全认证部分比如:用户登录和身份验证,所以它也支持使用基于 SSL/TLS 的加密协议来保证数据传送的保密性和完整性.OpenLDAP是使用OpenSSL来实现SSL/TLS加密通信的.\nLDAP的信息模型是建立在”条目”(entries)的基础上.一个条目是一些属性的集合,并且具有一个全局唯一的”可区分名称”DN,一个条目可以通过DN来引用.每一个条目的属性具有一个类型和一个或者多个值.类型通常是容易记忆的名称,比如”cn”是通用名称(common name),或者”mail”是电子邮件地址.条目的值的语法取决于属性类型.比如,cn属性可能具有一个值”Babs Jensen” .一个mail属性可能包含”bbs@example.com” .一个jpegphoto属性可能包含一幅JPEG(二进制)格式的图片.\nLDAP常用关键字列表 LDAP通过属性objectClass来控制哪一个属性必须出现或允许出现在一个条目中,它的值决定了该条目必须遵守的模式规则.\nEntry 条目,也叫记录项,是LDAP中最基本的颗粒,就像字典中的词条,或者是数据库中的记录.通常对LDAP的添加、删除、更改、检索都是以条目为基本对象的.\ndn:每一个条目都有一个唯一的标识名(distinguished Name,DN),如上述中一个 dn:”uid=mac,ou=People,dc=example,dc=cn”.通过DN的层次型语法结构,可以方便地表示出条目在LDAP树中的位置,通常用于检索. rdn:一般指dn逗号最左边的部分,如cn=baby.它与RootDN不同,RootDN通常与RootPW同时出现,特指管理LDAP中信息的最高权限用户. Base DN:LDAP目录树的最顶部就是根,也就是所谓的“Base DN”,如”dc=example,dc=com”. schema 对象类(ObjectClass)、属性类型(AttributeType)、语法(Syntax)分别约定了条目、属性、值,他们之间的关系如下图所示.所以这些构成了模式(Schema)——对象类的集合.条目数据在导入时通常需要接受模式检查,它确保了目录中所有的条目数据结构都是一致的.\nschema(一般在/etc/ldap/schema/目录)在导入时要注意前后顺序.\n对于LDAP目录中保存的信息,可以使用LDIF(LDAP Interchange Format)格式来保存.这是一种标准文本文件格式,使用这种格式保存得的LDAP服务器数据库中的数据可方便读取和修改,这也是其他大多数服务配置文件所采取的格式.\nAttribute 属性(Attribute)类似于程序设计中的变量,可以被赋值.在OpenLDAP中声明了许多常用的Attribute(用户也可自己定义Attribute).\n每个条目都可以有很多属性(Attribute),比如常见的人都有姓名、地址、电话等属性.每个属性都有名称及对应的值,属性值可以有单个、多个,比如你有多个邮箱.\n属性不是随便定义的,需要符合一定的规则,而这个规则可以通过schema制定.比如,如果一个entry没有包含在 inetorgperson 这个 schema 中的objectClass: inetOrgPerson,那么就不能为它指定employeeNumber属性,因为employeeNumber是在inetOrgPerson中定义的.\nLDAP为人员组织机构中常见的对象都设计了属性(比如commonName,surname).下面有一些常用的别名:\n属性\n别名\n语法\n描述\n值（举例）\ncommonName\ncn\nDirectory String\n姓名\nsean\nsurname\nsn\nDirectory String\n姓\nChow\norganizationalUnitName\nou\nDirectory String\n单位（部门）名称\nIT\norganization\no\nDirectory String\n组织（公司）名称\nexample\ntelephoneNumber\nTelephone Number\n电话号码\n110\nobjectClass\n内置熟悉\ntop\n常见的Attribute含义如下:\nc:国家. cn:common name,指一个对象的名字.如果指人,需要使用其全名. dc:domain Component,常用来指一个域名的一部分. givenName:指一个人的名字,不能用来指姓. l:指一个地名,如一个城市或者其他地理区域的名字. mail:电子信箱地址. o:organizationName,指一个组织的名字. ou:organizationalUnitName,指一个组织单元的名字. sn:surname,指一个人的姓. telephoneNumber:电话号码,应该带有所在的国家的代码. uid:userid,通常指某个用户的登录名,与Linux系统中用户的uid不同. 作者：华阳_3bcf\n链接：https://www.jianshu.com/p/3716b84c4c1d\n来源：简书\n著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。\nhttps://zhuanlan.zhihu.com/p/74512921\n在 LDAP 里， 一切都是等级化的，或者称之为层级化（hiearchical）。\n一棵树有树干，树枝和树叶；树叶长在树枝上，树枝依附于树干。这就是一个简单的层级结构。LDAP 的结构同一棵树类似。假设 LDAP 里存储的是公司的信息，那么可以把公司（company）本身理解为树干，公司里面的各个部门，比如组（group），理解为树干，把用户（user）理解为树叶。这样的结构称之为目录信息树（DIrectory Information Tree，DIT）。\n",
    "description": "",
    "tags": null,
    "title": "ldap-轻量目录访问协议",
    "uri": "/%E6%9D%83%E9%99%90%E6%8E%A7%E5%88%B6/ldap-%E8%BD%BB%E9%87%8F%E7%9B%AE%E5%BD%95%E8%AE%BF%E9%97%AE%E5%8D%8F%E8%AE%AE/"
  },
  {
    "content": "figlet 字符画制作工具 figlet -w yuvenhol~\n__ __ __ __ _ _ /\\/| \\ \\ / / _ _ \\ \\ / / ___ _ __ | |__ ___ | | |/\\/ \\ V / | | | | \\ \\ / / / _ \\ | '_ \\ | '_ \\ / _ \\ | | | | | |_| | \\ V / | __/ | | | | | | | | | (_) | | | |_| \\__,_| \\_/ \\___| |_| |_| |_| |_| \\___/ |_| ",
    "description": "",
    "tags": null,
    "title": "linux 工具",
    "uri": "/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/linux-%E5%B7%A5%E5%85%B7/"
  },
  {
    "content": " 目录 解释 /bin bin 是 Binaries (二进制文件) 的缩写, 这个目录存放着最经常使用的命令。 /sbin s 就是 Super User 的意思，是 Superuser Binaries (超级用户的二进制文件) 的缩写，这里存放的是系统管理员使用的系统管理程序。 /etc 存放系统管理和配置文件 /opt 额外安装的可选应用程序包所放置的位置。 /proc 虚拟文件系统目录，是系统内存的映射，可以查看正在运行程序的状态。 /boot 这里存放的是启动 Linux 时使用的一些核心文件，包括一些连接文件以及镜像文件。 /root 该目录为系统管理员，也称作超级权限者的用户主目录。 /dev dev 是 Device(设备) 的缩写, 该目录下存放的是 Linux 的外部设备，在 Linux 中访问设备的方式和访问文件的方式是相同的。 /lost+found 这个目录平时是空的，系统非正常关机而留下“无家可归”的文件（windows下叫什么.chk）就在这里 /var 用于存放运行时需要改变数据的文件，也是某些大文件的溢出区 /tmp 用于存放各种临时文件，是公用的临时文件存储点。 /mnt 临时挂载别的文件系统的，我们可以将光驱挂载在/mnt/上，然后进入该目录就可以查看光驱里的内容了。 /media linux 系统会自动识别一些设备，例如U盘、光驱等等，当识别后，Linux 会把识别的设备挂载到这个目录下。 /home 存放所有用户文件的根目录，是用户主目录的基点 /usr 用于存放系统应用程序，比较重要的目录。这是最庞大的目录，要用到的应用程序和文件几乎都在这个目录。 /usr/local 本地系统管理员软件安装目录（安装系统级的应用） /usr/doc linux文档 /usr/man 帮助文档 /usr/lib 常用的动态链接库和软件包的配置文件 /usr/sbin 超级用户的一些管理程序 /usr/include linux下开发和编译应用程序所需要的头文件 /usr/src 源代码，linux内核的源代码就放在/usr/src/linux里 usr/local/bin 本地增加的命令 /usr/local/lib 本地增加的库 ",
    "description": "",
    "tags": null,
    "title": "linux目录",
    "uri": "/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/linux%E7%9B%AE%E5%BD%95/"
  },
  {
    "content": "top 定义：display sorted information about processes\n展示项目 描述 CPU Percentage of processor usage, broken into user, system, and idle components. The time period for which these percentages are calculated depends on the event counting mode. Disks Number and total size of disk reads and writes. LoadAvg Load average over 1, 5, and 15 minutes. The load average is the average number of jobs in the run queue. MemRegions Number and total size of memory regions, and total size of memory regions broken into private (broken into non-library and library) and shared components. Networks Number and total size of input and output network packets PhysMem Physical memory usage, broken into wired, active, inactive, used, and free components. Procs Total number of processes and number of processes in each process state. SharedLibs Resident sizes of code and data segments, and link editor memory usage. Threads Number of threads. iotop 磁盘情况查看 lsof lsof - list open files 在linux下一切皆文件，一个网络连接也是一个文件。 lsof -i 查看网络连接的文件 在mac系统下netstat是简化版的，用lsof 替代\nnetstat netstat -an\nexport 环境变量相关操作 Linux export 命令用于设置或显示环境变量。\n在 shell 中执行程序时，shell 会提供一组环境变量。export 可新增，修改或删除环境变量，供后续执行的程序使用。export 的效力仅限于该次登陆操作，如果在配置文件中添加可以持续有效。 export [-fnp][变量名称]=[变量设置值]\n-f 代表[变量名称]中为函数名称。 -n 删除指定的变量。变量实际上并未删除，只是不会输出到后续指令的执行环境中。 -p 列出所有的shell赋予程序的环境变量。 例子 在.zprofile 里面 export WS=/Users/yuwenhao/Programs/work-space\ntouch 修改文件的创建和修改时间，现在常用于创建一个文件。\nfind find path -name “支持 * ？” [-delete]\ngrep alias alias[别名]=[指令名称] 删除unlias 别名\nln ln -s 软连接 ln 硬连接，软连接更常用，不存在文件时也可以创建软连接，类似于快捷方式。硬连接是指向一个文件实体的指针，文件夹不创建硬连接，不同文件系统或者硬件不能创建硬连接，硬连接可以多人共享文件，防止误删。\nnohup nohup command \u003e myout.file 2\u003e\u00261 \u0026 2表示异常输出 1表示标准输出 2\u003e\u00261 异常输出打到标准输出里。\n",
    "description": "",
    "tags": null,
    "title": "linux系统监控命令",
    "uri": "/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/linux%E7%B3%BB%E7%BB%9F%E7%9B%91%E6%8E%A7%E5%91%BD%E4%BB%A4/"
  },
  {
    "content": "这次的史诗级漏洞是怎么回事呢？ 主角就是log4j2，黑客已经利用 Log4j 漏洞来接管受害者的计算机，以执行从加密货币挖矿、发送垃圾邮件、到通过大型僵尸网络发起分布式拒绝服务(DDoS)攻击的任何事情。\nlog4j2的强大之处在于，除了可以输出程序中的变量，它还提供了一个叫Lookup的东西，lookup相当于是一个接口，可以用来输出更多内容，lookup，顾名思义就是查找、搜索的意思，那在log4j2中，就是允许在输出日志的时候，通过某种方式去查找要输出的内容。\n假如某一个Java程序中，将浏览器的类型记录到了日志中：\nlogger.info(userAgent); User-Agent就属于外界输入的信息，而不是自己程序里定义出来的。只要是外界输入的，就有可能存在恶意的内容，假如有人发来了一个HTTP请求，他的User-Agent是这样一个字符串：\n${jndi:ldap://127.0.0.1/exploit}\n接下来，log4j2将会对这行要输出的字符串进行解析，它发现了字符串中有 ${，要单独处理，发现是JNDI扩展内容_（什么是JNDI？简单粗暴的理解下，它的作用类似于JDBC，JDBC（Java Data Base Connectivity,java数据库连接）是一种用于执行SQL语句的Java API，可以为多种关系数据库提供统一访问，JDBC为工具/数据库开发人员提供了一个标准的API，据此可以构建更高级的工具和接口，使数据库开发人员能够用纯 Java API 编写数据库应用程序。JNDI(Java Naming and Directory Interface)是一个应用程序设计的API，为开发人员提供了查找和访问各种命名和目录服务的通用、统一的接口，类似JDBC都是构建在抽象层上。）如图：_\n再对JNDI进一步解析，发现了是LDAP协议_（LDAP即Lightweight Directory Access Protocol（轻量级目录访问协议），目录是一个为查询、浏览和搜索而优化的专业分布式数据库，这个东西用在统一身份认证领域比较多，**简单理解就是：**一个类似于字典的数据源，你可以通过LDAP协议，传一个name进去，就能获取到数据。）_LDAP服务器在127.0.0.1，要查找的key是exploit，然后调用具体负责LDAP的模块去请求对应的数据。问题来了！JNDI支持一个叫命名引用的方式，也就是JNDI可以远程下载class文件来构建对象！！！下载后加载起来构建对象，咱就是一整个震惊住的那么一个大动作啊，如果远程下载的URL指向的是一个黑客的服务器，并且下载的class文件里面藏有恶意代码，那歇逼了，什么样的后果都可能出现，这是JNDI注入。\n这次“核弹”漏洞造成的影响 log4j2的使用面很广泛，现在Java技术栈在Web、后端开发、大数据等领域应用非常广泛，国内除了阿里巴巴、京东、美团等一大片以Java为主要技术栈的公司外，还有多如牛毛的中小企业选择Java。除此之外还有像kafka、elasticsearch、flink这样的大量中间件都是用Java语言开发的。它们大量使用了log4j2作为日志输出。如果输出的日志有外部输入混进来，那直接就是远程代码执行RCE，灭顶之灾！好吧这些是大佬们的遭遇和分析，至少目前为止对很多人，至少我这种菜鸟没有产生什么大的影响…\n有关解决和修复 方式一：禁用lookup或JNDI服务\n罪魁祸首就是lookup和JNDI，那么直接修改配置文件log4j2.formatMsgNoLookups=True或禁用JNDI服务，不过一般产生问题的服务都是线上已经在跑的服务，禁用的时候要注意评估一下是否允许。\n方式二：升级新版本\n新版的log4j2已经修复了这个问题，升级即可解决。修复后的log4j2在JNDI lookup中增加了很多的限制：\n1.默认不再支持二次跳转（也就是命名引用）的方式获取对象\n2.只有在log4j2.allowedLdapClasses列表中指定的class才能获取。\n3.只有远程地址是本地地址或者在log4j2.allowedLdapHosts列表中指定的地址才能获取\n这样处理等于是去掉了通过打印日志去远程加载class的方式。\n",
    "description": "",
    "tags": null,
    "title": "log4j漏洞",
    "uri": "/%E6%9D%82%E9%A1%B9/log4j%E6%BC%8F%E6%B4%9E/"
  },
  {
    "content": "\n",
    "description": "",
    "tags": null,
    "title": "LRU",
    "uri": "/%E7%AE%97%E6%B3%95%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/lru/"
  },
  {
    "content": "简介 mapStruct 是一个类型安全的bean转换工具，基于 JSR 269 ，也同样可以使用命令行构建。\n详细文档：https://mapstruct.org/documentation/stable/reference/html/#customizing-mappings-with-before-and-after\n依赖引入 \u003cproperties\u003e \u003corg.mapstruct.version\u003e1.5.2.Final\u003c/org.mapstruct.version\u003e \u003c/properties\u003e ... \u003cdependencies\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.mapstruct\u003c/groupId\u003e \u003cartifactId\u003emapstruct\u003c/artifactId\u003e \u003cversion\u003e${org.mapstruct.version}\u003c/version\u003e \u003c/dependency\u003e \u003c/dependencies\u003e \u003c!-- 如果和lombok 结合可能有贬义冲突，需要配置如下 --\u003e \u003cbuild\u003e \u003cplugins\u003e \u003cplugin\u003e \u003cgroupId\u003eorg.apache.maven.plugins\u003c/groupId\u003e \u003cartifactId\u003emaven-compiler-plugin\u003c/artifactId\u003e \u003cversion\u003e3.8.1\u003c/version\u003e \u003cconfiguration\u003e \u003csource\u003e1.8\u003c/source\u003e \u003ctarget\u003e1.8\u003c/target\u003e \u003cannotationProcessorPaths\u003e \u003cpath\u003e \u003cgroupId\u003eorg.mapstruct\u003c/groupId\u003e \u003cartifactId\u003emapstruct-processor\u003c/artifactId\u003e \u003cversion\u003e${org.mapstruct.version}\u003c/version\u003e \u003c/path\u003e \u003c/annotationProcessorPaths\u003e \u003c/configuration\u003e \u003c/plugin\u003e \u003c/plugins\u003e \u003c/build\u003e 使用 基础 定义一个基础mapping @Mapper public interface CarMapper { @Mapping(target = \"manufacturer\", source = \"make\") @Mapping(target = \"seatCount\", source = \"numberOfSeats\") CarDto carToCarDto(Car car); @Mapping(target = \"fullName\", source = \"name\") PersonDto personToPersonDto(Person person); } mapStruct会再在编译期生成对应的映射方法，依赖于get set方法，所以需要提前写好get\u0026set方法。\n映射编排 Mapping Composition 可以定义一个注解，组合编排mapping\n@Retention(RetentionPolicy.CLASS) @Mapping(target = \"id\", ignore = true) @Mapping(target = \"creationDate\", expression = \"java(new java.util.Date())\") @Mapping(target = \"name\", source = \"groupName\") public @interface ToEntity { } 自定义方法 如果有一些需要手写的方法，可以自定义一个方法，再Mapping方法中如果用到了类型转转，会自动使用我们自定义的方法。\n@Mapper public interface CarMapper { @Mapping(...) ... CarDto carToCarDto(Car car); default PersonDto personToPersonDto(Person person) { //hand-written mapping logic } } 使用source\u0026target参数 如果source和target不能通过变量名自动转化，那么可以使用注解手动映射。\n@Mapper public interface AddressMapper { @Mapping(target = \"description\", source = \"person.description\") @Mapping(target = \"houseNumber\", source = \"address.houseNo\") DeliveryAddressDto personAndAddressToDeliveryAddressDto(Person person, Address address); } 嵌套（nested）bean映射 @Mapper public interface CustomerMapper { @Mapping( target = \"name\", source = \"record.name\" ) @Mapping( target = \".\", source = \"record\" ) @Mapping( target = \".\", source = \"account\" ) Customer customerDtoToCustomer(CustomerDto customerDto); } 其中 \".\" 代表this对象\n更新已经创建的bean @Mapper public interface CarMapper { void updateCarFromDto(CarDto carDto, @MappingTarget Car car); } 没有get/set 但是是public修饰时 public class Customer { private Long id; private String name; //getters and setter omitted for brevity } public class CustomerDto { public Long id; public String customerName; } @Mapper public interface CustomerMapper { CustomerMapper INSTANCE = Mappers.getMapper( CustomerMapper.class ); @Mapping(target = \"name\", source = \"customerName\") Customer toCustomer(CustomerDto customerDto); @InheritInverseConfiguration CustomerDto fromCustomer(Customer customer); } 支持builder\u0026constructor创建影射对象 支持map结构映射 public class Customer { private Long id; private String name; //getters and setter omitted for brevity } @Mapper public interface CustomerMapper { @Mapping(target = \"name\", source = \"customerName\") Customer toCustomer(Map\u003cString, String\u003e map); } ",
    "description": "",
    "tags": null,
    "title": "MapStruct-类型安全的bean转换工具",
    "uri": "/java/mapstruct-%E7%B1%BB%E5%9E%8B%E5%AE%89%E5%85%A8%E7%9A%84bean%E8%BD%AC%E6%8D%A2%E5%B7%A5%E5%85%B7/"
  },
  {
    "content": "资料 官网 ：https://maven.apache.org/ 官方仓库浏览：https://mvnrepository.com/、https://search.maven.org/\n功能 编译、打包、测试、依赖管理等\n仓库 通常情况下企业内仓储依赖是\ngraph LR 本地仓库A \u0026 本地仓库B \u0026 本地仓库C --\u003e 企业私服Nexus--\u003e阿里云Nexus--\u003e中央仓库 其中repository Manager 企业内会用nexus等\n文件规范 java 源文件：src/main/java\n测试用例目录：src/test/java\n输出文件： target/\n配置文件： src/main/resources/\nweb：src/main/webapp\n包含/WEB-INF/web.xml\npom 增加\n\u003cpackaging\u003ewar\u003c/packaging\u003e settings文件 settings文件有两处配置，总配置和用户\nThe Maven install: ${maven.home}/conf/settings.xml A user’s install: ${user.home}/.m2/settings.xml Servers 配置账号密码 sshkey等\n1. `\u003cservers\u003e` 2. `\u003cserver\u003e` 3. `\u003cid\u003eserver001\u003c/id\u003e` 4. `\u003cusername\u003emy_login\u003c/username\u003e` 5. `\u003cpassword\u003emy_password\u003c/password\u003e` 6. `\u003cprivateKey\u003e${user.home}/.ssh/id_dsa\u003c/privateKey\u003e` 7. `\u003cpassphrase\u003esome_passphrase\u003c/passphrase\u003e` 8. `\u003cfilePermissions\u003e664\u003c/filePermissions\u003e` 9. `\u003cdirectoryPermissions\u003e775\u003c/directoryPermissions\u003e` 10. `\u003cconfiguration\u003e\u003c/configuration\u003e` 11. `\u003c/server\u003e` 12. `\u003c/servers\u003e` Mirrors 镜像：对repository的代理，默认的repository的id:central，所以一般mirrorOf会配置central,也可以是*，会对所有的repository替换。\n虽然 mirrors 可以配置多个子节点，但是它只会使用其中的一个节点，即 默认情况下配置多个 mirror 的情况下，只有第一个生效，只有当前一个 mirror 无法连接的时候，才会去找后一个；而我们想要的效果是：当a.jar在第一个 mirror 中不存在的时候，maven会去第二个 mirror 中查询下载，但是maven不会这样做！\n1. `\u003cmirrors\u003e` 2. `\u003cmirror\u003e` 3. `\u003cid\u003eplanetmirror.com\u003c/id\u003e` 4. `\u003cname\u003ePlanetMirror Australia\u003c/name\u003e` 5. `\u003curl\u003ehttp://downloads.planetmirror.com/pub/maven2\u003c/url\u003e` 6. `\u003cmirrorOf\u003ecentral\u003c/mirrorOf\u003e` 7. `\u003c/mirror\u003e` 8. `\u003c/mirrors\u003e` POM文件 POM介绍 pom project object model 完整官方文档：https://maven.apache.org/pom.html\n基础例子 \u003cproject xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 https://maven.apache.org/xsd/maven-4.0.0.xsd\"\u003e \u003c!-- maven 模型版本--\u003e \u003cmodelVersion\u003e4.0.0\u003c/modelVersion\u003e \u003c!-- 分组编号一般是公司域名--\u003e \u003cgroupId\u003eorg.codehaus.mojo\u003c/groupId\u003e \u003c!-- 工件编号一般是项目模块--\u003e \u003cartifactId\u003emy-project.xxx\u003c/artifactId\u003e \u003cversion\u003e1.0\u003c/version\u003e \u003c/project\u003e maven 约定大于配置 好处：\n省去配置 规范开发规范 package: package同时会执行compile\ntest Test开头的类名和test开头的方法名才会被执行\n如果引入junit 包，上一条就失效\n项目依赖 项目依赖是指maven通过以来传播、依赖优先、可选依赖、排除依赖、依赖范围等特性来管理项目ClassPath。 依赖传播 我们的项目通常会依赖第三方组件，第三方组建又会依赖其他组件遇到这种情况Maven会将依赖网络中的所有节点都会加入ClassPath。\n依赖优先 就近原则,链路短的优先 相同路径下配置在前的优先\n但是一个pom文件下，后面的优先（并不规范，一个pom文件里不应该写两个一样的依赖） 可选依赖 如果不希望依赖的包传递引用包，可以打断依赖传递\n\u003coptional\u003etrue\u003c/optional\u003e 排除依赖 \u003cexclusions\u003e \u003cexclusion\u003e \u003c!-- 排除依赖 --\u003e \u003c/exclusion\u003e \u003c/exclustions\u003e 依赖范围 \u003cscope\u003e\u003c/scope\u003e 可选的范围\ncomplie（默认），编译和打包都会依赖 provided：编译时依赖，打包不会依赖。ex: servlet-api.jar(tomcat 存在),lombok runtime:运行时范围，打包时依赖，编译时不依赖。mysql-connector-java.jar\n官方解释：this scope indicates that the dependency is not required for compilation, but is for execution. It is in the runtime and test classpaths, but not the compile classpath. test:测试类依赖 system:类似provided，可指定本地位置 ",
    "description": "",
    "tags": null,
    "title": "maven",
    "uri": "/%E5%B7%A5%E5%85%B7/maven/"
  },
  {
    "content": "META-INFO WEB-INFO ",
    "description": "",
    "tags": null,
    "title": "META-INF和WEB-INFO",
    "uri": "/java/meta-inf%E5%92%8Cweb-info/"
  },
  {
    "content": "jdbc方式 @Test public void test() throws SQLException { Connection conn=null; PreparedStatement pstmt=null; try { // 1.加载驱动 //Class.forName(\"com.mysql.jdbc.Driver\"); // 2.创建连接 conn= DriverManager. // SPI ,mysql Driver Connector，的META-INF.services下会有 java.sql.Driver 的实现类 getConnection(\"jdbc:mysql://localhost:3306/mybatis_example\", \"root\", \"123456\"); // 开启事务 conn.setAutoCommit(false); // SQL语句 参数#{} ${} \u003cif\u003e String sql=\" select id,user_name,create_time from t_user where id=?;\"; // 获得sql执行者 ： // 1. 执行预处理 pstmt=conn.prepareStatement(sql); pstmt.setInt(1,1); // 执行查询 pstmt.execute(); ResultSet rs= pstmt.getResultSet(); //ResultSet rs= pstmt.executeQuery(); rs.next(); User user =new User(); user.setId(rs.getLong(\"id\")); user.setUserName(rs.getString(\"user_name\")); user.setCreateTime(rs.getDate(\"create_time\")); System.out.println(user.toString()); pstmt=conn.prepareStatement(sql); pstmt.setInt(1,1); // 提交事务 conn.commit(); } catch (Exception e) { e.printStackTrace(); // 回滚事务 conn.rollback(); } finally{ // 关闭资源 try { if(conn!=null){ conn.close(); } if(pstmt!=null){ pstmt.close(); } } catch (SQLException e) { e.printStackTrace(); } } } 存在的问题\n数据库连接创建，释放频繁造成西戎资源的浪费，从而影响系统性能，使 用数据库连接池可以解决问题。 sql语句在代码中硬编码，造成代码的不已维护，实际应用中sql的变化可 能较大，sql代码和java代码没有分离开来维护不方便。 使用preparedStatement向有占位符传递参数存在硬编码问题因为sql中 的where子句的条件不确定，同样是修改不方便 对结果集中解析存在硬编码问题，sql的变化导致解析代码的变化，系统维 护不方便。 ",
    "description": "",
    "tags": null,
    "title": "mybatis",
    "uri": "/%E7%B1%BB%E5%BA%93%E6%A1%86%E6%9E%B6/mybatis/"
  },
  {
    "content": "mysql 逻辑框架图 ",
    "description": "",
    "tags": null,
    "title": "mysql",
    "uri": "/%E4%B8%AD%E9%97%B4%E4%BB%B6/mysql/"
  },
  {
    "content": "类型 标准数据类型 Python3 中有六个标准的数据类型：\nNumber（数字）\nint、float、bool、complex。其中bool是int的子类。False == 0 String（字符串）\nList（列表）\nTuple（元组）\nSet（集合）\nDictionary（字典） Python3 的六个标准数据类型中：\n**不可变数据（3 个）：**Number（数字）、String（字符串）、Tuple（元组）；\n**可变数据（3 个）：**List（列表）、Dictionary（字典）、Set（集合）。\n对象 python对象三要素 id（对象地址）、type、value\nl1=[1,2,3] l2=[1,2,3] # 调用对象__eq__() l1==l2 \u003e\u003e\u003e true # 对比内存地址 l1 is l2 \u003e\u003e\u003e false 赋值(=)、浅拷贝(copy())、深拷贝(deepcopy() #赋值 a=[1,2,[4,5]] #浅拷贝 b=copy(a) #深拷贝 c=deepcopy(b) ",
    "description": "",
    "tags": null,
    "title": "python 语法知识",
    "uri": "/python/python-%E8%AF%AD%E6%B3%95%E7%9F%A5%E8%AF%86/"
  },
  {
    "content": "官网命令介绍 https://redis.io/commands/ https://pdai.tech/md/db/nosql-redis/db-redis-x-redis-ds.html\n数据结构 字符串 常用命令： SET GET MSET（json的key） MGET SETNX（分布式锁） INCR（原子操作） INCRYBY （批量） GET\nhash结构 Hash常用操作 HSET key field value //存储一个哈希表key的键值 HSETNX key field value //存储一个不存在的哈希表key的键值 HMSET key field value [field value …] //在一个哈希表key中存储多个键值对 HGET key field //获取哈希表key对应的field键值 HMGET key field [field …] //批量获取哈希表key中多个field键值 HDEL key field [field …] //删除哈希表key中的field键值 HLEN key //返回哈希表key中field的数量 HGETALL key //返回哈希表key中所有的键值 HINCRBY key field increment //为哈希表key中field键的值加上增量increment\n相比较String 优点 同类数据归类整合储存，方便数据管理 相比string操作消耗内存与cpu更小 相比string储存更节省空间 缺点 过期功能不能使用在field上，只能用在key上 Redis集群架构下不适合大规模使用。大key容易造成数据分布不均匀 List结构 队列结构，最大2^32-1个元素，主要用于头尾添加访问元素。 LPUSH RPUSH LPOP RPOP LRANGE 返回获取 BLPOP Block LPOP，会阻塞 BRPOP\n应用 stack=LPUSH+LPOP queue=LPUSH+RPOP blocking queue=LPUSH+BRPOP\nSET结构 基础命令 SADD SREM 删除元素 SMEMBERS 查看全部元素 SRANDMEMBER key count 随机从key中抽取count个元素 SPOP 随机从key中抽取count个元素，并排除 pop·· SISMEMBER 是否包含 SCARD获取总数\n集合命令 SINTER 求交集 SUNION 并集 SDIFF 查集（第一个集合，在后续集合中不存在的元素）\n应用 抽奖 关注模型\n共同关注的人 SINTER 我关注的人也关注了他 SISMEMBER 可能喜欢 SDIFF ZSET 有序集合 常用操作： ZADD key score ZRANGE key start stop 排序 ZREVRANGE 倒序 ZUNIONSTORE 并集并放入一个key\n应用： 排行榜\nredis注意事项 redis最应该避免大key，不要一个key里面存太多数据。\n常见面试问题 Redis的单线程和高性能 Redis是单线程吗? Redis 的单线程主要是指 Redis 的网络 IO 和键值对读写是由一个线程来完成的，这也是 Redis 对外 提供键值存储服务的主要流程。但 Redis 的其他功能，比如持久化、异步删除、集群数据同步等，其实是由额外的线程执行的。\nRedis 单线程为什么还能这么快? 因为它所有的数据都在内存中，所有的运算都是内存级别的运算，而且单线程避免了多线程的切换性 能损耗问题。正因为 Redis 是单线程，所以要小心使用 Redis 指令，对于那些耗时的指令(比如 keys)，一定要谨慎使用，一不小心就可能会导致 Redis 卡顿。\nRedis 单线程如何处理那么多的并发客户端连接? Redis的IO多路复用:redis利用epoll来实现IO多路复用，将连接信息和事件放到队列中，依次放到 文件事件分派器，事件分派器将事件分发给事件处理器。 redis 一个命令过来大体分四步 1、建立连接 2、读取数据 3、执行命令 4、应答 连接建立优化先入队列，数据接收完成以后，传给事件处理器，不过需要注意命令的执行仍然会按照入队的顺序执行，只不过优化减少了IO时间。\n",
    "description": "",
    "tags": null,
    "title": "redis基础知识",
    "uri": "/%E4%B8%AD%E9%97%B4%E4%BB%B6/redis/redis%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/"
  },
  {
    "content": "简介 Sentinel 是面向分布式、多语言异构化服务架构的流量治理组件，主要以流量为切入点，从流量路由、流量控制、流量整形、熔断降级、系统自适应过载保护、热点流量防护等多个维度来帮助开发者保障微服务的稳定性。\nSentinel 基本概念 资源 资源是 Sentinel 的关键概念。它可以是 Java 应用程序中的任何内容，例如，由应用程序提供的服务，或由应用程序调用的其它应用提供的服务，甚至可以是一段代码。在接下来的文档中，我们都会用资源来描述代码块。\n只要通过 Sentinel API 定义的代码，就是资源，能够被 Sentinel 保护起来。大部分情况下，可以使用方法签名，URL，甚至服务名称作为资源名来标示资源。\n规则 围绕资源的实时状态设定的规则，可以包括流量控制规则、熔断降级规则以及系统保护规则。所有规则可以动态实时调整。\nSentinel 功能和设计理念 流量控制 流量控制有以下几个角度:\n资源的调用关系，例如资源的调用链路，资源和资源之间的关系； 运行指标，例如 QPS、线程池、系统负载等； 控制的效果，例如直接限流、冷启动、排队等。 Sentinel 的设计理念是让您自由选择控制的角度，并进行灵活组合，从而达到想要的效果。\n熔断降级 什么是熔断降级 除了流量控制以外，降低调用链路中的不稳定资源也是 Sentinel 的使命之一。由于调用关系的复杂性，如果调用链路中的某个资源出现了不稳定，最终会导致请求发生堆积。\nSentinel 和 Hystrix 的原则是一致的: 当调用链路中某个资源出现不稳定，例如，表现为 timeout，异常比例升高的时候，则对这个资源的调用进行限制，并让请求快速失败，避免影响到其它的资源，最终产生雪崩的效果。\n熔断降级设计理念 Sentinel 对这个问题采取了两种手段:\n通过并发线程数进行限制 和资源池隔离的方法不同，Sentinel 通过限制资源并发线程的数量，来减少不稳定资源对其它资源的影响。这样不但没有线程切换的损耗，也不需要您预先分配线程池的大小。当某个资源出现不稳定的情况下，例如响应时间变长，对资源的直接影响就是会造成线程数的逐步堆积。当线程数在特定资源上堆积到一定的数量之后，对该资源的新请求就会被拒绝。堆积的线程完成任务后才开始继续接收请求。\n通过响应时间对资源进行降级 除了对并发线程数进行控制以外，Sentinel 还可以通过响应时间来快速降级不稳定的资源。当依赖的资源出现响应时间过长后，所有对该资源的访问都会被直接拒绝，直到过了指定的时间窗口之后才重新恢复。\n系统负载保护 Sentinel 同时提供系统维度的自适应保护能力。防止雪崩，是系统防护中重要的一环。当系统负载较高的时候，如果还持续让请求进入，可能会导致系统崩溃，无法响应。在集群环境下，网络负载均衡会把本应这台机器承载的流量转发到其它的机器上去。如果这个时候其它的机器也处在一个边缘状态的时候，这个增加的流量就会导致这台机器也崩溃，最后导致整个集群不可用。\n针对这个情况，Sentinel 提供了对应的保护机制，让系统的入口流量和系统的负载达到一个平衡，保证系统在能力范围之内处理最多的请求。\n开源框架适配 web servlet: CommonFilter dubbo http client 等等 https://sentinelguard.io/zh-cn/docs/open-source-framework-integrations.html 控制台 Sentinel 提供一个轻量级的开源控制台，它提供机器发现以及健康情况管理、监控（单机和集群），规则管理和推送的功能。这里，我们将会详细讲述如何通过简单的步骤就可以使用这些功能。 引入JAR包 客户端需要引入 Transport 模块来与 Sentinel 控制台进行通信。您可以通过 pom.xml 引入 JAR 包:\n\u003cdependency\u003e \u003cgroupId\u003ecom.alibaba.csp\u003c/groupId\u003e \u003cartifactId\u003esentinel-transport-simple-http\u003c/artifactId\u003e \u003cversion\u003ex.y.z\u003c/version\u003e \u003c/dependency\u003e 配置启动参数 启动时加入 JVM 参数 -Dcsp.sentinel.dashboard.server=consoleIp:port 指定控制台地址和端口。若启动多个应用，则需要通过 -Dcsp.sentinel.api.port=xxxx 指定客户端监控 API 的端口（默认是 8719）。\n除了修改 JVM 参数，也可以通过配置文件取得同样的效果。更详细的信息可以参考 启动配置项。\n触发客户端初始化 确保客户端有访问量，Sentinel 会在客户端首次调用的时候进行初始化，开始向控制台发送心跳包。\n简单的demo public class SentinelDemoTest { // 配置规则. private static void initFlowRules() { List\u003cFlowRule\u003e rules = new ArrayList\u003c\u003e(); FlowRule rule = new FlowRule(); rule.setResource(\"HelloWorld\"); rule.setGrade(RuleConstant.FLOW_GRADE_QPS); rule.setCount(8); rules.add(rule); FlowRuleManager.loadRules(rules); } private static void initDegradeRules() { List\u003cDegradeRule\u003e rules = new ArrayList\u003c\u003e(); DegradeRule rule = new DegradeRule(); rule.setResource(\"HelloWorld\"); rule.setGrade(RuleConstant.DEGRADE_GRADE_EXCEPTION_COUNT); rule.setCount(2); rule.setTimeWindow(1); rules.add(rule); DegradeRuleManager.loadRules(rules); } /** * 异常捕获式限流 * try-with-resources 语句 */ @Test public void t1() throws InterruptedException { initFlowRules(); while (true) { Thread.sleep(100); try (Entry entry = SphU.entry(\"HelloWorld\")) { // 被保护的逻辑 System.out.println(\"hello world\"); } catch (BlockException ex) { // 处理被流控的逻辑 System.out.println(\"blocked!\"); } } } /** * 异常捕获式限流 * try finally 语句 */ @Test public void t1_1() throws InterruptedException { initFlowRules(); // 配置规则. while (true) { Thread.sleep(100); Entry entry = null; try { entry = SphU.entry(\"HelloWorld\"); // 被保护的逻辑 System.out.println(\"hello world\"); // 处理被流控的逻辑 System.out.println(\"blocked!\"); } catch (BlockException e) { e.printStackTrace(); } finally { if (entry != null) { entry.exit(); } } } } /** * 条件判断式限流 */ @Test public void t2() throws InterruptedException { // 配置规则. initFlowRules(); while (true) { Thread.sleep(100); boolean entryOk = SphO.entry(\"HelloWorld\"); if (entryOk) { // 被保护的逻辑 System.out.println(\"hello world\"); } else { // 处理被流控的逻辑 System.out.println(\"blocked!\"); } SphO.exit(); } } /** * 降级 */ @Test public void t4() { initDegradeRules(); while (true) { Entry entry = null; try { Thread.sleep(100); entry = SphU.entry(\"HelloWorld\"); throw new RuntimeException(\"exception\"); } catch (BlockException e) { System.out.println(\"degrade\"); } catch (Exception e) { System.out.println(\"pass\"); Tracer.trace(e); } finally { if (entry != null) { entry.exit(); } } } } } 核心源码 在 Sentinel 里面，所有的资源都对应一个资源名称以及一个 Entry。Entry 可以通过对主流框架的适配自动创建，也可以通过注解的方式或调用 API 显式创建；每一个 Entry 创建的时候，同时也会创建一系列功能插槽（slot chain）。这些插槽有不同的职责，例如:\nNodeSelectorSlot 1.负责收集资源的路径，并将这些资源的调用路径，以树状结构存储起来，用于根据调用路径来限流降级2.构造一个Node用于存储当前请求的统计数据； ClusterBuilderSlot 为了获得同一资源在不同上下文中的总统计信息，同一资源全局共享同一个ClusterNode。ClusterBuilderSlot主要负责构建这个ClusterNode； StatisticSlot 则用于记录、统计不同纬度的 runtime 指标监控信息； FlowSlot 则用于根据预设的限流规则以及前面 slot 统计的状态，来进行流量控制； AuthoritySlot 则根据配置的黑白名单和调用来源信息，来做黑白名单控制； DegradeSlot 则通过统计信息以及预设的规则，来做熔断降级； SystemSlot 则通过系统的状态，例如 load1 等，来控制总的入口流量； ",
    "description": "",
    "tags": null,
    "title": "sentinel",
    "uri": "/%E7%B1%BB%E5%BA%93%E6%A1%86%E6%9E%B6/sentinel/"
  },
  {
    "content": "bash有几种不同的运行模式，login shell与non-login shell,.interactive shell.与non-interactive shell(比如执行shel脚本)。这两种 分类方法是交叉的，也就是说一个login shell7可能是一个interactive shell,也可能是个non-interactive shell。. 在下列情况下，我们可以获得一个login shell: 1.登录系统时获得的J顶层shell,无论是通过本地终端登录，还是通过网络ssh登录。这种情况下获得的login shell是一个交互式shell。. 2.在终端下使用-login选项调用bash,可以获得一个交互式login shell。. 3.在脚本中使用-login选项调用bash(比如在shell脚本第一行做如下指定：#！/bin/bash–login),此时得到一个非交互式的login shell。 4.使用\"su-“切换到指定用户时，获得此用户的login shell。如果不使用”.\"，则获得non-login shell。 login shell与non-login shell的主要区别在于它们启动时会读取不同的配置文件，从而导致环境不一样。 login shell的行为： login shell,启动时首先读取/etc/profile:全局配置，然后依次查找~/.bash_profile、~/.bash_login、~/.profile三个配置文件，并且 读取第一个找到的并且可读的文件。login shell退出时读取并执行~/.bash_logout中的命令。 non-login shell的行为： 交互式的non-login shell)启动时读取~.bashrc资源文件。非交互式的non–login shell不读取上述所有配置文件，而是查找环境变量 BASH ENV,读取并执行BASH ENV指向的文件中的命令。 如果使用命令\"sh\"调用bash,bash会尽可能保持向后兼容。作为login shellF启动时，bash依次读取/etc/profile和~l.profile配置文件。作为 non-login shell/启动时，bash读取环境变量ENV指向的文件。 通常我们要定制一些配置时，将配置写在.bashrc中，然后在/.bash_profile中读取~/.bashrc,这样可以保证login shell和交互式non-login shell得到相同的配置。至于/etc/profile就不要轻易去改啦，毕竟会影响系统全局的配置。\n",
    "description": "",
    "tags": null,
    "title": "shell 的login shell与non-login shell",
    "uri": "/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/shell-%E7%9A%84login-shell%E4%B8%8Enon-login-shell/"
  },
  {
    "content": "几篇还不错的文章： SLF4J和Logback和Log4j和Logging的区别与联系\njava日志体系\n",
    "description": "",
    "tags": null,
    "title": "slf4j",
    "uri": "/%E6%9D%82%E9%A1%B9/slf4j/"
  },
  {
    "content": "生命周期 补充： @PostConstruct 代表bean构建完成后置处理，在属性注入之后，基于初始化前实现 beanPostProcessor .beforeInitlazation。\n循环依赖 三级缓存 singletonObjects：依赖注入完成的bean earlySingletionObjects：早期bean，未完成依赖注入，但是 singletonFactories：对象工厂，表示用来创建早期bean对象的工厂 存放顺序: singletonFactories–\u003eearlySingletionObjects–\u003esingletonObjects 读取顺序：singletonObjects–\u003eearlySingletionObjects–\u003e存放顺序\n",
    "description": "",
    "tags": null,
    "title": "spring bean",
    "uri": "/spring/spring-bean/"
  },
  {
    "content": "spring cache是spring对各种cache的一种抽象管理，可以使用redis、caffeine等。\n\u003c-- 必要 --\u003e \u003cdependency\u003e \u003cgroupId\u003eorg.springframework.boot\u003c/groupId\u003e \u003cartifactId\u003espring-boot-starter-cache\u003c/artifactId\u003e \u003cversion\u003e2.2.5.RELEASE\u003c/version\u003e \u003c/dependency\u003e \u003c-- 缓存中一种 --\u003e \u003cdependency\u003e \u003cgroupId\u003ecom.github.ben-manes.caffeine\u003c/groupId\u003e \u003cartifactId\u003ecaffeine\u003c/artifactId\u003e \u003cversion\u003e2.9.2\u003c/version\u003e \u003c/dependency\u003e 在使用缓存之前，需要创建一个CacheManager\n@Bean public CacheManager cacheManager() { CaffeineCacheManager caffeineCacheManager = new CaffeineCacheManager(); caffeineCacheManager.setCaffeine( Caffeine.newBuilder() .expireAfterWrite(10, TimeUnit.MINUTES) .maximumSize(10_000)); return caffeineCacheManager; } http://t.zoukankan.com/hager-p-13197673.html\nhttps://www.freesion.com/article/401730391/\n",
    "description": "",
    "tags": null,
    "title": "Spring cache",
    "uri": "/spring/spring-cache/"
  },
  {
    "content": "BeanFactory ApplicationContext ApplicationContext 也实现了beanFactory，实际上具体实现依靠获取Context内的BeanFacoty实例DefaultListableBeanFactory 来实现功能的。\ngraph TD 10[ContextLoaderListener.contextInitialized] --创建WebApplicationContext--\u003e15[ContextLoader.initWebApplicationContext] --\u003e 18[configureAndRefreshWebApplicationContext] --初始化context--\u003e20 subgraph refresh 20[ConfigurableApplicationContext.refresh] --prepareRefresh--\u003e21[准备刷新:包括spring环境等] -- obtainFreshBeanFactory--\u003e22[创建bean工程] -- prepareBeanFactory--\u003e23[bean工程初始化配置] -- postProcessBeanFactory --\u003e24[添加beanFactory的后置护理器] -- invokeBeanFactoryPostProcessors --\u003e25[调用beanFactory后置处理器.bean扫描是在这一步操作的] -- registerBeanPostProcessors --\u003e26[注册bean后置处理器] -- initMessageSource --\u003e27[国际化等] -- initApplicationEventMulticaster--\u003e28[创基一个事件广播器来处理事件] -- onRefresh --\u003e29[初始化前添加特殊bean 默认啥都不干] -- registerListeners --\u003e 30[注册event listener] -- finishBeanFactoryInitialization --\u003e31[实例化剩余的bean] -- finishRefresh--\u003e32[主要是发送ContextRefreshedEvent 通知完成refresh] end",
    "description": "",
    "tags": null,
    "title": "spring Context",
    "uri": "/spring/spring-context/"
  },
  {
    "content": "Spring Web MVC是基于Servlet API构建的原始Web框架，从一开始就已包含在Spring框架中。正式名 称“ Spring Web MVC”来自其源模块的名称(spring-webmvc)，但它通常被称为“ Spring MVC”。 xml下配置servlet的映射非常麻烦 开发效率低 必须要继承父类、重写方法 侵入性强 如果想在一个Servlet中处理同一业务模块的的功能分发给不同方法进行处理非常麻烦 参数解析麻烦:单个参数（转换类型）—\u003epojo对象 Json文本—\u003epojo对象 数据响应麻烦:pojo对象—\u003ejson … Content-type 跳转页面麻烦, 对path的控制、 如果使用其他模板也很麻烦 、设置编码麻烦…等等… 所以SpringMVC 就是在Servlet的基础上进行了封装，帮我把这些麻烦事都给我们做了。\n核心方法在 DispatcherServlet::doDispatch\n需要了解的类和方法 RequestMappingHandler 请求映射处理器，用于将一个request和一个handler给映射起来。有好多种形式进行映射，常见的是BeanNameUrlHandlerMapping（bean name和url映射）和DefaultAnnotationHandlerMapping（RequestMapping等注解映射），一般都用DefaultAnnotationHandlerMapping,mvc使用mvc:annotation-driven开启。\nRequestMappingHandlerMapping ,\ndispatcherServlet是核心分分发器，其核心方法时doDispatch()。 根据请求路径\nHandler（具体的Controller 方法） HandlerMapping（根据request定为到对应的HandlerExecutionChain） HandlerExecutionChain（handler的执行链，包含了拦截器和HandlerMethod） HandlerMethod(包装了Handler) HandlerAdapter()\nHandlerMethodReturnValueHandlerComposite HandlerMethodReturnValueHandler\nHandlerMethodArgumentResolverComposite HandlerMethodArgumentResolver\nmessageConverter （依赖 HandlerMethodReturnValueHandler和HandlerMethodArgumentResolver 处理请求前后 ）\n",
    "description": "",
    "tags": null,
    "title": "spring mvc",
    "uri": "/spring/spring-mvc/"
  },
  {
    "content": "给linux实例添加新增SSH公钥 #!/bin/bash # ssh public key to be added. sshPublicKey=\"{{sshPublicKey}}\" mkdir -p ~/.ssh \u0026\u0026 chmod 700 ~/.ssh touch ~/.ssh/authorized_keys chmod 600 ~/.ssh/authorized_keys echo $sshPublicKey \u003e\u003e ~/.ssh/authorized_keys echo \"operation success!\" ",
    "description": "",
    "tags": null,
    "title": "SSH",
    "uri": "/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/ssh/"
  },
  {
    "content": "为啥是去中心化的： 阿帕网当初设计的时候为了防止苏联人攻击损坏一个节点，其他节点不可用，所以做成了去中心化的。 IEEE和ISO\nOSI 七层模型是ISO提供的，都是学者相对学术 IEEE是 五工程师协会提出的，更加实际可实现\nIP地址和MAC地址的区别\nIP地址可以变动、mac地址是不变的，相同子网内寻址使用MAC地址，不同网络使用IP地址\nSYN(synchronous建立联机) ACK(acknowledgement 确认) PSH(push传送) FIN(finish结束) RST(reset重置) URG(urgent紧急)\nSequence number(顺序号码)\n",
    "description": "",
    "tags": null,
    "title": "TCP IP协议",
    "uri": "/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/tcp-ip%E5%8D%8F%E8%AE%AE/"
  },
  {
    "content": "栈上分配 为什么需要栈上分配\n在我们的应用程序中，其实有很多的对象的作用域都不会逃逸出方法外，也就是说该对象的生命周期会随着方法的调用开始而开始，方法的调用结束而结束，对于这种对象，是不是该考虑将对象不在分配在堆空间中呢？ 我们通过JVM内存分配可以知道JAVA中的对象都是在堆上进行分配，当对象没有被引用的时候，需要依靠GC进行回收内存，如果对象数量较多的时候，会给GC带来较大压力，也间接影响了应用的性能。\n什么是栈上分配\n所以,栈上分配是JVM提出的一种调优方案,JVM通过逃逸分析确定该对象不会被外部访问,如果不会逃逸可以将该对象在栈上分配内存，每个方法或者说每个线程都有属于自己独立的栈帧,随着方法的调用结束,这样该对象所占用的内存空间就可以随栈帧出栈而销毁，就减轻了垃圾回收的压力。\n对象逃逸分析：就是分析对象动态作用域，当一个对象在方法中被定义后，它可能被外部方法所引用，例如作为调用参数传递到其他地方中。\n分析如下案例:\npublic User test1(){ User user = new User(); user.setId(1); user.setName(“1”); return user; }\npublic void test2(){ User user = new User(); user.setId(1); user.setName(“1”);\n//保存数据库 //userMapper.save(user); } 很显然test1方法中的user对象被返回了，这个对象的作用域范围不确定，test2方法中的user对象我们可以确定当方法结束这个对象就可以认为是无效对象了，对于这样的对象我们其实可以将其分配在栈内存里，让其在方法结束时跟随栈内存一起被回收掉。\nJVM对于这种情况可以通过开启逃逸分析参数(-XX:+DoEscapeAnalysis)来优化对象内存分配位置，使其通过标量替换优先分配在栈上(栈上分配)，JDK7之后默认开启逃逸分析，如果要关闭使用参数(-XX:-DoEscapeAnalysis)\n标量替换：通过逃逸分析确定该对象不会被外部访问，并且对象可以被进一步分解时，JVM不会创建该对象，而是将该对象成员变量分解若干个被这个方法使用的成员变量所代替，这些代替的成员变量在栈帧或寄存器上分配空间，这样就不会因为没有一大块连续空间导致对象内存不够分配。开启标量替换参数(-XX:+EliminateAllocations)，JDK7之后默认开启。\n栈上分配的优点:\n1.可以在方法调用结束后自行销毁对象,无需垃圾回收器的介入,有效减小JVM的GC压力 2.栈上分配速度很快,有效提高程序性能\n栈上分配的缺点:\n1.栈的空间是有限的,栈空间存放不了大对象,遇到大对象的创建则还是会存放在堆空间中\nTLAB 可能很多人会有疑惑，已经提供了栈上分配，为什么还要有什么TLAB，甚至混淆了两者之间的差别，包括我自己，之前也存在很多疑惑，下面为大家揭开原因 全名: 本地线程分配缓冲(Thread Local Allocation Buffer,TLAB)，这是一个线程专用的内存分配区域。\n为什么需要TLAB\n在线程初始化时，同时也会申请一块指定大小的内存，只给当前线程使用，这样每个线程都单独拥有一个空间，如果需要分配内存，就在自己的空间上分配，这样就不存在竞争的情况，可以大大提升分配效率。\n如何开启TLAB\nJVM默认开启了TLAB功能，也可以使用-XX: +UseTLAB 显示开启\n如何观察TLAB使用情况\nJVM提供了-XX:+PrintTLAB 参数打开跟踪TLAB的使用情况\n如何调整TLAB默认大小 -XX:TLABSize 通过该参数指定分配给每一个线程的TLAB空间的大小\n简单理解\n为了避免多线程情况下抢占空间,每个线程会提前在EDEN区中,额外划分一块内存区域,指定对象直接进入区域使用, jdk8默认开启\nTLAB的缺点:\n1.TLAB空间一般不会很大(占用了Eden区),所以大对象也无法在TLAB上进行分配,遇到大对象最终也只能分配到堆空间中\n如下图:对象分配流程图\n最后栈上分配和TLAB的对比\n名称\t针对点\t处于对象分配流程的位置 栈上分配\t减少GC的负担\t1 TLAB\t加速堆上对象分配速度\t2\n",
    "description": "",
    "tags": null,
    "title": "TLAB \u0026 栈上分配",
    "uri": "/java/jvm/tlab-%E6%A0%88%E4%B8%8A%E5%88%86%E9%85%8D/"
  },
  {
    "content": "zookeeper 什么是zookeeper 它是一个分布式协调框架，是Apache Hadoop 的一个子项目，它主要是用来解决分布式应用中经常遇到的一些数据管理问题，如:统一命名服务、状态同 步服务、集群管理、分布式应用配置项的管理等。\n核心概念 简单的理解Zookeeper 是一个用于存储少量数据的基于内存 的数据库，主要有如下两个核心的概念:\n文件系统数据结构 监听通知机制。 文件系统数据结构 Zookeeper维护一个类似文件系统的数据结构: 每个子目录项都被称作为 znode(目录节点)，和文件系统类似，我们能够自由的增加、删除 znode，在一个znode下增加、删除子znode。\n有四种类型的znode:\nPERSISTENT­持久化目录节点 客户端与zookeeper断开连接后，该节点依旧存在，只要不手动删除该节点，他将永远存在\nPERSISTENT_SEQUENTIAL­持久化顺序编号目录节点 客户端与zookeeper断开连接后，该节点依旧存在，只是Zookeeper给该节点名称进行顺序编号\nEPHEMERAL­临时目录节点 客户端与zookeeper断开连接后，该节点被删除(和sessionId绑定的，session断开或者超时会被删除)\nEPHEMERAL_SEQUENTIAL­临时顺序编号目录节点 客户端与zookeeper断开连接后，该节点被删除，只是Zookeeper给该节点名称进行顺序编号\nContainer 节点(3.5.3 版本新增，如果Container节点下面没有子节点，则Container节点 在未来会被Zookeeper自动清除,定时任务默认60s 检查一次)\nTTL 节点( Time To Live 默认禁用，只能通过系统配置 zookeeper.extendedTypesEnabled=true 开启，不稳定)\n监听通知机制 客户端注册监听它关心的任意节点，或者目录节点及递归子目录节点\n如果注册的是对某个节点的监听，则当这个节点被删除，或者被修改时，对应的客户端将被通知 如果注册的是对某个目录的监听，则当这个目录有子节点被创建，或者有子节点被删除，对应的客户端将被通知 如果注册的是对某个目录的递归子节点进行监听，则当这个目录下面的任意子节点有目录结构 的变化(有子节点被创建，或被删除)或者根节点有数据变化时，对应的客户端将被通知。 get -w /xxx 监听只会监听当前节点，子节点修改不会被监听 注意:所有的通知都是一次性的，及无论是对节点还是对目录进行的监听，一旦触发，对应的监 听即被移除。递归子节点，监听是对所有子节点的，所以，每个子节点下面的事件同样只会被触发一次。\n应用场景 分布式配置中心 分布式注册中心 分布式锁 分布式队列 集群选举 分布式屏障 发布/订阅 节点元数据 可以通过stat命令，或者get -s cZxid:创建znode的事务ID(Zxid的值)。 mZxid:最后修改znode的事务ID。 pZxid:最后添加或删除子节点的事务ID(子节点列表发生变化才会发生改变)。 ctime:znode创建时间。 mtime:znode最近修改时间。\ndataVersion:znode的当前数据版本。 cversion:znode的子节点结果集版本(一个节点的子节点增加、删除都会影响这个版本）。 aclVersion：znode的acl版本 ephemeralOwner:znode是临时znode时，表示znode所有者的 session ID。 如果 znode不是临时znode，则该字段设置为零。 dataLength:znode数据字段的长度。 numChildren:znode的子znode的数量。\nACL 权限控制( Access Control List ) Zookeeper 的ACL 权限控制,可以控制节点的读写操作,保证数据的安全性，Zookeeper ACL 权 限设置分为 3 部分组成，分别是:权限模式(Scheme)、授权对象(ID)、权限信息 (Permission)。最终组成一条例如“scheme:id:permission”格式的 ACL 请求信息。\nScheme(权限模式):用来设置 ZooKeeper 服务器进行权限验证的方式。ZooKeeper 的权限 验证方式大体分为两种类型:\n一种是范围验证。所谓的范围验证就是说 ZooKeeper 可以针对一个 IP 或者一段 IP 地址授予某 种权限。比如我们可以让一个 IP 地址为“ip:192.168.0.110”的机器对服务器上的某个数据节 点具有写入的权限。或者也可以通过“ip:192.168.0.1/24”给一段 IP 地址的机器赋权。\n另一种权限模式就是口令验证，也可以理解为用户名密码的方式。在 ZooKeeper 中这种验证方 式是 Digest 认证，而 Digest 这种认证方式首先在客户端传送“username:password”这种形 式的权限表示符后，ZooKeeper 服务端会对密码 部分使用 SHA-1 和 BASE64 算法进行加密， 以保证安全性。\n还有一种Super权限模式, Super可以认为是一种特殊的 Digest 认证。具有 Super 权限的客户端 可以对 ZooKeeper 上的任意数据节点进行任意操作。\n授权对象(ID)\n授权对象就是说我们要把权限赋予谁，而对应于 4 种不同的权限模式来说，如果我们选择采用 IP 方式，使用的授权对象可以是一个 IP 地址或 IP 地址段;而如果使用 Digest 或 Super 方式，则 对应于一个用户名。如果是 World 模式，是授权系统中所有的用户。\n权限信息(Permission)\n权限就是指我们可以在数据节点上执行的操作种类，如下所示:在 ZooKeeper 中已经定义好的 权限有 5 种:\n数据节点(c: create)创建权限，授予权限的对象可以在数据节点下创建子节点; 数据节点(w: wirte)更新权限，授予权限的对象可以更新该数据节点;\n数据节点(r: read)读取权限，授予权限的对象可以读取该节点的内容以及子节点的列表信息; 数据节点(d: delete)删除权限，授予权限的对象可以删除该数据节点的子节点; 数据节点(a: admin)管理者权限，授予权限的对象可以对该数据节点体进行 ACL 权限设置。\n命令:\ngetAcl:获取某个节点的acl权限信息\nsetAcl:设置某个节点的acl权限信息\naddauth: 输入认证授权信息，相当于注册用户信息，注册时输入明文密码，zk将以密文的形式存 储\n可以通过系统参数zookeeper.skipACL=yes进行配置，默认是no,可以配置为true, 则配置过的 ACL将不再进行权限检测 ex： setAcl /test auth:yuvenhol:pwd:rwcd create /test xxdataxx ip:192.168.109.130:rw\n数据结构 //DataNode 是Zookeeper存储节点数据的最小单位 public class DataNode implements Record{ byte data[]; Long acl; public StatPersisted stat; private Set\u003cString\u003e children = null; } // public class DataTree{ private final ConcurrentHashMap\u003cString, DataNode\u003e nodes = new ConcurrentHashMap\u003cString, DataNode\u003e(); private final WatchManager dataWatches = new WatchManager(); private final WatchManager childWatches = new WatchManager(); } 事务日志\u0026数据快照 格式化后效果 事务日志： 针对每一次客户端的事务操作，Zookeeper都会将他们记录到事务日志中，当然，Zookeeper也 会将数据变更应用到内存数据库中。我们可以在zookeeper的主配置文件zoo.cfg 中配置内存中 的数据持久化目录，也就是事务日志的存储路径 dataLogDir. 如果没有配置dataLogDir(非必 填), 事务日志将存储到dataDir (必填项)目录 数据快照： 用于记录Zookeeper服务器上某一时刻的全量数据，并将其写入到指定的磁盘文件中。 可以通过配置snapCount配置每间隔事务请求个数，生成快照，数据存储在dataDir 指定的目录中\n事务日志文件名为: log.\u003c当时最大事务ID\u003e，应为日志文件时顺序写入的，所以这个最大事务 ID也将是整个事务日志文件中，最小的事务ID，日志满了即进行下一次事务日志文件的创建\n快照事务日志文件名为: snapshot.\u003c当时最大事务ID\u003e，日志满了即进行下一次事务日志文件的 创建\n",
    "description": "",
    "tags": null,
    "title": "zookeeper",
    "uri": "/%E5%88%86%E5%B8%83%E5%BC%8F/zookeeper/"
  },
  {
    "content": "1、字段意义不可分割，不能是数组等集合或者表达多个意义。 2、每个字段都依赖主键 3、依赖不可传递，比如 A-\u003eB-\u003eC 不行的，必须A-\u003eC,B-\u003eC。\n",
    "description": "",
    "tags": null,
    "title": "三大范式",
    "uri": "/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql/%E4%B8%89%E5%A4%A7%E8%8C%83%E5%BC%8F/"
  },
  {
    "content": "中间件是为应用提供通用服务和功能的软件。数据管理、应用服务、消息传递、身份验证和 API 管理通常都要通过中间件。\n中间件可以帮助开发人员更有效地构建应用。它就如同是应用、数据与用户之间的纽带。\n对于具有多云和容器化环境的企业而言，中间件可以助您大规模、经济高效地开发和运行应用。 一般而言中间件和框架的区别是，中间件是独立运行的用于处理某项专门业务的CS程序，会有配套的客户端和服务端，框架虽然也是处理某个专门业务的但是它不是独立程序，是寄宿在宿主程序进程内的一套类库。 作者：阿里巴巴淘系技术\n链接：https://www.zhihu.com/question/19730582/answer/1663627873\n来源：知乎\n著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。\n常用基础中间件 路由与web服务器：处理和转发其他服务器通信数据的服务器。 如被业界广泛使用的阿里基于 Nginx 研发的 Tengine、阿里内部的集中式路由服务 VipServer\nRPC框架：微服务时代的远程服务调用框架。如grpc, Thrift, 阿里的 HSF, Dubbo, SOFA-RPC\n消息中间件：支持在分布式系统之间发送和接收消息的软件。 如 Apache kafka, Apache RabbitMQ, NSQ, 阿里孵化开源的 Apache RocketMQ\n缓存服务: 分布式的高速数据存储层，一般是内存存储。如 阿里 Tair，业界的 Redis, Memcached, Ehcache\n配置中心：用来统一管理各个项目中所有配置的系统。如 阿里 Nacos、携程 Apollo、百度 Disconf\n分布式事务：事务的参与者、支持事务的服务器、资源服务器以及事务管理器分别位于不同的分布式系统的不同节点之上。 如 阿里 seata、腾讯 DTF\n任务调度：分布式环境下提供定时、任务编排、分布式跑批等功能的系统。如 阿里 SchedulerX、业界 xxl-job、当当 elastic-job、有赞 TSP\n数据库层 用于支持弹性扩容和分库分表的 TDDL，数据库连接池 Driud, Binlog 同步的 Canal 等。\n",
    "description": "",
    "tags": null,
    "title": "中间件的定义",
    "uri": "/%E4%B8%AD%E9%97%B4%E4%BB%B6/%E4%B8%AD%E9%97%B4%E4%BB%B6%E7%9A%84%E5%AE%9A%E4%B9%89/"
  },
  {
    "content": "事务的概念 事务的意义就是为了保证系统中所有数据的都是符合预期的，且相互关联的数据之间不会产生矛盾，即数据状态的一致性。\n经典数据库理论中，要达成这个目标，需要三方面共同努力来保障。\n原子性（Atomic）：在同一项业务处理过程中，事务保证了对多个数据的修改，要么同时成功，要么同时被撤销。 隔离性（Isolation）：在不同的业务处理过程中，事务保证了各自业务正在读、写的数据互相独立，不会彼此影响。 持久性（Durability）：事务应当保证所有成功被提交的数据修改都能够正确地被持久化，不丢失数据。 事务的四大特性ACID，纯属凑数😓 目前事务的概念已经不在局限于数据库方面了，延伸到所有涉及到保证一致性的场景，包括但不限于缓存、消息队列、分布式存储等。\n在使用单一数据源的情况下，使用A.I.D保证事务的做法比较容易，事务由数据源控制，被称作局部事务（也叫本地事务），一致性被称为“内部一致性”。 在使用多数据源的情况下，甚至多个服务多个数据源，这时要保证一致性被称为\"外部一致性\"。\n",
    "description": "",
    "tags": null,
    "title": "事务",
    "uri": "/%E6%95%B0%E6%8D%AE%E5%BA%93/%E4%BA%8B%E5%8A%A1/"
  },
  {
    "content": "据说人生清楚这四个问题，就不再迷茫。\n我喜欢什么 我适合什么 我想成为怎样的人 我想过什么样的生活 ",
    "description": "",
    "tags": null,
    "title": "人生四问",
    "uri": "/%E8%83%A1%E8%AF%8C%E5%85%AB%E6%89%AF%E5%A4%A7%E9%81%93%E7%90%86/%E4%BA%BA%E7%94%9F%E5%9B%9B%E9%97%AE/"
  },
  {
    "content": " 迟来的深情不如狗叫 —— jukie\n断臂求生——jukie\n",
    "description": "",
    "tags": null,
    "title": "人生大道理",
    "uri": "/%E8%83%A1%E8%AF%8C%E5%85%AB%E6%89%AF%E5%A4%A7%E9%81%93%E7%90%86/%E4%BA%BA%E7%94%9F%E5%A4%A7%E9%81%93%E7%90%86/"
  },
  {
    "content": "全局事务（Global Transaction） 全局事务仍然追求ACID的强一致性，适用于在使用多个数据源时。\n2PC 伪代码：\npublic void buyBook(PaymentBill bill) { userTransaction.begin(); warehouseTransaction.begin(); businessTransaction.begin(); try { userAccountService.pay(bill.getMoney()); warehouseService.deliver(bill.getItems()); businessAccountService.receipt(bill.getMoney()); userTransaction.commit(); warehouseTransaction.commit(); businessTransaction.commit(); } catch(Exception e) { userTransaction.rollback(); warehouseTransaction.rollback(); businessTransaction.rollback(); } } 准备阶段：又叫作投票阶段，在这一阶段，协调者询问事务的所有参与者是否准备好提交，参与者如果已经准备好提交则回复 Prepared，否则回复 Non-Prepared。这里所说的准备操作跟人类语言中通常理解的准备并不相同，对于数据库来说，准备操作是在重做日志中记录全部事务提交操作所要做的内容，它与本地事务中真正提交的区别只是暂不写入最后一条 Commit Record 而已，这意味着在做完数据持久化后并不立即释放隔离性，即仍继续持有锁，维持数据对其他非事务内观察者的隔离状态。 提交阶段：又叫作执行阶段，协调者如果在上一阶段收到所有事务参与者回复的 Prepared 消息，则先自己在本地持久化事务状态为 Commit，在此操作完成后向所有参与者发送 Commit 指令，所有参与者立即执行提交操作；否则，任意一个参与者回复了 Non-Prepared 消息，或任意一个参与者超时未回复，协调者将自己的事务状态持久化为 Abort 之后，向所有参与者发送 Abort 指令，参与者立即执行回滚操作。对于数据库来说，这个阶段的提交操作应是很轻量的，仅仅是持久化一条 Commit Record 而已，通常能够快速完成，只有收到 Abort 指令时，才需要根据回滚日志清理已提交的数据，这可能是相对重负载的操作。 以上这两个过程被称为“两段式提交”（2 Phase Commit，2PC）协议，而它能够成功保证一致性还需要一些其他前提条件。\n必须假设网络在提交阶段的短时间内是可靠的，即提交阶段不会丢失消息。同时也假设网络通信在全过程都不会出现误差，即可以丢失消息，但不会传递错误的消息，XA 的设计目标并不是解决诸如拜占庭将军一类的问题。两段式提交中投票阶段失败了可以补救（回滚），而提交阶段失败了无法补救（不再改变提交或回滚的结果，只能等崩溃的节点重新恢复），因而此阶段耗时应尽可能短，这也是为了尽量控制网络风险的考虑。 必须假设因为网络分区、机器崩溃或者其他原因而导致失联的节点最终能够恢复，不会永久性地处于失联状态。由于在准备阶段已经写入了完整的重做日志，所以当失联机器一旦恢复，就能够从日志中找出已准备妥当但并未提交的事务数据，并向协调者查询该事务的状态，确定下一步应该进行提交还是回滚操作。 存在的问题 单点问题：协调者在两段提交中具有举足轻重的作用，协调者等待参与者回复时可以有超时机制，允许参与者宕机，但参与者等待协调者指令时无法做超时处理。一旦宕机的不是其中某个参与者，而是协调者的话，所有参与者都会受到影响。如果协调者一直没有恢复，没有正常发送 Commit 或者 Rollback 的指令，那所有参与者都必须一直等待。 性能问题：两段提交过程中，所有参与者相当于被绑定成为一个统一调度的整体，期间要经过两次远程服务调用，三次数据持久化（准备阶段写重做日志，协调者做状态持久化，提交阶段在日志写入 Commit Record），整个过程将持续到参与者集群中最慢的那一个处理操作结束为止，这决定了两段式提交的性能通常都较差。 一致性风险：前面已经提到，两段式提交的成立是有前提条件的，当网络稳定性和宕机恢复能力的假设不成立时，仍可能出现一致性问题。宕机恢复能力这一点不必多谈，1985 年 Fischer、Lynch、Paterson 提出了“FLP 不可能原理”，证明了如果宕机最后不能恢复，那就不存在任何一种分布式协议可以正确地达成一致性结果。该原理在分布式中是与“CAP 不可兼得原理“齐名的理论。而网络稳定性带来的一致性风险是指：尽管提交阶段时间很短，但这仍是一段明确存在的危险期，如果协调者在发出准备指令后，根据收到各个参与者发回的信息确定事务状态是可以提交的，协调者会先持久化事务状态，并提交自己的事务，如果这时候网络忽然被断开，无法再通过网络向所有参与者发出 Commit 指令的话，就会导致部分数据（协调者的）已提交，但部分数据（参与者的）既未提交，也没有办法回滚，产生了数据不一致的问题。 3PC 3PC是针对2PC的优化，分为 Can、Pre、Do 三个阶段。新增了一个Can（询问阶段），如果数据库状态不能保证可以顺利完成，则不锁定资源。三阶段也解决了单点问题，如果协调者超时默认会提交事务。 ",
    "description": "",
    "tags": null,
    "title": "全局事务",
    "uri": "/%E6%95%B0%E6%8D%AE%E5%BA%93/%E5%85%A8%E5%B1%80%E4%BA%8B%E5%8A%A1/"
  },
  {
    "content": "逻辑划分：\nHot spot 实现\n虚拟机栈：\n每个方法被执行事会生成一个栈桢（Stack Frame）用于存储局部变量表，操作数栈、动态链接、方法出口等\n本地方法栈：\n与虚拟机栈功能相似，服务于native方法。Hot-spot把本地方法栈与虚拟机栈合二为一。\n堆：\n对象存储的地方，有些对象存储在栈上，依靠内存逃逸。\n方法区：\n存放类的信息，常量、静态变量、及时编译后的代码缓存。\n运行时常量池：\nJava程序要运行时，需要编译器先将源代码文件编译成字节码（.class)文件，然后在由JVM解释执行。\nclass文件中除了有类的版本、字段、方法、接口等描述信息外,还有一项信息是常量池(Constant pool table)，用于存放编译期生成的各种字面量和符号引用，这部分内容将在类加载后进入运行时常量池中存放。\n静态常量池就是上面说的class文件中的常量池。class常量池是在编译时每个class文件中都存在。不同的符号信息放置在不同标志的常量表中。\n",
    "description": "",
    "tags": null,
    "title": "内存结构",
    "uri": "/java/%E5%86%85%E5%AD%98%E7%BB%93%E6%9E%84/"
  },
  {
    "content": " 事务基本概念[[事务]]\n分布式事务 在分布式服务环境下的事务处理机制。\nCAP理论 分布式计算领域所公认的著名定理。这个定理里描述了一个分布式的系统中，涉及共享数据问题时，以下三个特性最多只能同时满足其中两个：\n一致性（Consistency）：代表数据在任何时刻、任何分布式节点中所看到的都是符合预期的。一致性在分布式研究中是有严肃定义、有多种细分类型的概念，以后讨论分布式共识算法时，我们还会再提到一致性，那种面向副本复制的一致性与这里面向数据库状态的一致性严格来说并不完全等同，具体差别我们将在后续分布式共识算法中再作探讨。 可用性（Availability）：代表系统不间断地提供服务的能力，理解可用性要先理解与其密切相关两个指标：可靠性（Reliability）和可维护性（Serviceability）。可靠性使用平均无故障时间（Mean Time Between Failure，MTBF）来度量；可维护性使用平均可修复时间（Mean Time To Repair，MTTR）来度量。可用性衡量系统可以正常使用的时间与总时间之比，其表征为：A=MTBF/（MTBF+MTTR），即可用性是由可靠性和可维护性计算得出的比例值，譬如 99.9999%可用，即代表平均年故障修复时间为 32 秒。 分区容忍性（Partition Tolerance）：代表分布式环境中部分节点因网络原因而彼此失联后，即与其他节点形成“网络分区”时，系统仍能正确地提供服务的能力。 对C、A、P三者的取舍，会产生不同取向的。\n如果放弃分区容忍性（CA without P），意味着我们将假设节点之间通信永远是可靠的。永远可靠的通信在分布式系统中必定不成立的，这不是你想不想的问题，而是只要用到网络来共享数据，分区现象就会始终存在。在现实中，最容易找到放弃分区容忍性的例子便是传统的关系数据库集群，这样的集群虽然依然采用由网络连接的多个节点来协同工作，但数据却不是通过网络来实现共享的。以 Oracle 的 RAC 集群为例，它的每一个节点均有自己独立的 SGA、重做日志、回滚日志等部件，但各个节点是通过共享存储中的同一份数据文件和控制文件来获取数据的，通过共享磁盘的方式来避免出现网络分区。因而 Oracle RAC 虽然也是由多个实例组成的数据库，但它并不能称作是分布式数据库。 如果放弃可用性（CP without A），意味着我们将假设一旦网络发生分区，节点之间的信息同步时间可以无限制地延长，此时，问题相当于退化到前面“全局事务”中讨论的一个系统使用多个数据源的场景之中，我们可以通过 2PC/3PC 等手段，同时获得分区容忍性和一致性。在现实中，选择放弃可用性的 CP 系统情况一般用于对数据质量要求很高的场合中，除了 DTP 模型的分布式数据库事务外，著名的 HBase 也是属于 CP 系统，以 HBase 集群为例，假如某个 RegionServer 宕机了，这个 RegionServer 持有的所有键值范围都将离线，直到数据恢复过程完成为止，这个过程要消耗的时间是无法预先估计的。 如果放弃一致性（AP without C），意味着我们将假设一旦发生分区，节点之间所提供的数据可能不一致。选择放弃一致性的 AP 系统目前是设计分布式系统的主流选择，因为 P 是分布式网络的天然属性，你再不想要也无法丢弃；而 A 通常是建设分布式的目的，如果可用性随着节点数量增加反而降低的话，很多分布式系统可能就失去了存在的价值，除非银行、证券这些涉及金钱交易的服务，宁可中断也不能出错，否则多数系统是不能容忍节点越多可用性反而越低的。目前大多数 NoSQL 库和支持分布式的缓存框架都是 AP 系统，以 Redis 集群为例，如果某个 Redis 节点出现网络分区，那仍不妨碍各个节点以自己本地存储的数据对外提供缓存服务，但这时有可能出现请求分配到不同节点时返回给客户端的是不一致的数据。 “选择放弃一致性的 AP 系统目前是设计分布式系统的主流选择”，“事务”原本的目的就是获得“一致性”，而在分布式环境中，“一致性”却不得不成为通常被牺牲、被放弃的那一项属性。但无论如何，我们建设信息系统，终究还是要确保操作结果至少在最终交付的时候是正确的，这句话的意思是允许数据在中间过程出错（不一致），但应该在输出时被修正过来。为此，人们又重新给一致性下了定义，将前面我们在 CAP、ACID 中讨论的一致性称为“强一致性”（Strong Consistency），有时也称为“线性一致性”（Linearizability，通常是在讨论共识算法的场景中），而把牺牲了 C 的 AP 系统又要尽可能获得正确的结果的行为称为追求“弱一致性”。不过，如果单纯只说“弱一致性”那其实就是“不保证一致性”的意思……人类语言这东西真的是博大精深。在弱一致性里，人们又总结出了一种稍微强一点的特例，被称为“最终一致性”（Eventual Consistency），它是指：如果数据在一段时间之内没有被另外的操作所更改，那它最终将会达到与强一致性过程相同的结果，有时候面向最终一致性的算法也被称为“乐观复制算法”。\n在本节讨论的主题“分布式事务”中，目标同样也不得不从之前三种事务模式追求的强一致性，降低为追求获得“最终一致性”。由于一致性的定义变动，“事务”一词的含义其实也同样被拓展了，人们把使用 ACID 的事务称为“刚性事务”，而把笔者下面将要介绍几种分布式事务的常见做法统称为“柔性事务”。\n实现柔性事务的方案 可靠事件队列 TCC SAGA ",
    "description": "",
    "tags": null,
    "title": "分布式事务",
    "uri": "/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E4%BA%8B%E5%8A%A1/"
  },
  {
    "content": "选举算法： paxos: 角色\nPaxos将系统中的角色分为提议者 (Proposer)，决策者 (Acceptor)，和最终决策学习者 (Learner):\n• Proposer: 提出提案 (Proposal)。Proposal信息包括提案编号 (Proposal ID) 和提议的值 (Value)。\n• Acceptor: 参与决策，回应Proposers的提案。收到Proposal后可以接受提案，若Proposal获得多数Acceptors的接受，则称该Proposal被批准。\n• Learner: 不参与决策，从Proposers/Acceptors学习最新达成一致的提案(Value)。\n在多副本状态机中，每个副本同时具有Proposer、Acceptor、Learner三种角色。\n三只蓝军攻打一只强大的红军\n第一阶段: Prepare阶段\nProposer向Acceptors发出Prepare请求，Acceptors针对收到的Prepare请求进行Promise承诺。\n• Prepare: Proposer生成全局唯一且递增的Proposal ID (可使用时间戳加Server ID)，向所有Acceptors发送Prepare请求，这里无需携带提案内容，只携带Proposal ID即可。\n• Promise: Acceptors收到Prepare请求后，做出“两个承诺，一个应答”。\n○ 承诺1: 不再接受Proposal ID小于等于(注意: 这里是\u003c= )当前请求的Prepare请求;\n○ 承诺2: 不再接受Proposal ID小于(注意: 这里是\u003c )当前请求的Propose请求;\n○ 应答: 不违背以前作出的承诺下，回复已经Accept过的提案中Proposal ID最大的那个提案的Value和Proposal ID，没有则返回空值。\n¶ 第二阶段: Accept阶段\nProposer收到多数Acceptors承诺的Promise后，向Acceptors发出Propose请求，Acceptors针对收到的Propose请求进行Accept处理。\n• Propose: Proposer 收到多数Acceptors的Promise应答后，从应答中选择Proposal ID最大的提案的Value，作为本次要发起的提案。如果所有应答的提案Value均为空值，则可以自己随意决定提案Value。然后携带当前Proposal ID，向所有Acceptors发送Propose请求。\n• Accept: Acceptor收到Propose请求后，在不违背自己之前作出的承诺下，接受并持久化当前Proposal ID和提案Value。\n¶ 第三阶段: Learn阶段\nProposer在收到多数Acceptors的Accept之后，标志着本次Accept成功，决议形成，将形成的决议发送给所有Learners。 一致性协议算法： ZAB： https://pdai.tech/md/algorithm/alg-domain-distribute-x-zab.html\n负载均衡算法 一致性hash https://blog.csdn.net/gonghaiyu/article/details/108375298\n传统hash算法的弊端 资源数据分布通常有哈希分区和顺序分区两种方式\n顺序分布：数据分散度易倾斜、键值业务相关、可顺序访问、不支持批量操作。 哈希分布：数据分散度高、键值分布业务无关、无法顺序访问、支持批量操作。 顺序分区\n顺序分区通常指顺序访问某个资源，如在RocketMQ中，Topic(消息主题)可能对应多个实际的消息队列，消息投递时，如果有5个消息，只有三个队列，消息按照1-2-3-1-2这样的投递顺序。\n哈希分区-节点取余分区\n对特定数据采用hash算法得到一个整数，再通过整数对分区数取余就可以得到资源的存储路由。如redis的键或用户ID，再根据节点数量N使用公式：hash(key)%N计算出哈希值，用来决定数据映射到哪个分区节点。\n优点\n这种方式的突出优点就是简单，且常用于数据库的分库分表。如京东某系统中采用shardingjdbc，用这种方式进行分库分表路由处理。 缺点\n当节点数量发生变化时，如扩容或收缩节点（没有遇到过），数据节点关系需要重新计算，会导致数据的重新迁移。所以扩容通常采用翻倍扩容，避免数据映射全部打乱而全部迁移，翻倍迁移只发生50%的数据迁移。如果不翻倍缩扩容，如某一台机器宕机，那么应该落在该机器的请求就无法得到正确的处理，这时需要将宕掉的服务器使用算法去除，此时候会有(N-1)/N的服务器的缓存数据需要重新进行计算；如果新增一台机器，会有N /(N+1)的服务器的缓存数据需要进行重新计算。对于系统而言，这通常是不可接受的颠簸（因为这意味着大量缓存的失效或者数据需要转移）。 传统求余做负载均衡算法，缓存节点数由3个变成4个，缓存不命中率为75%。计算方法：穷举hash值为1-12的12个数字分别对3和4取模，然后比较发现只有前3个缓存节点对应结果和之前相同，所以有75%的节点缓存会失效，可能会引起缓存雪崩。\n",
    "description": "",
    "tags": null,
    "title": "分布式算法",
    "uri": "/%E5%88%86%E5%B8%83%E5%BC%8F/%E5%88%86%E5%B8%83%E5%BC%8F%E7%AE%97%E6%B3%95/"
  },
  {
    "content": "动态规划问题的一般形式就是求最值。动态规划其实是运筹学的一种最优化方法，只不过在计算机问题上应用比较多，比如说让你求最长递增子序列呀，最小编辑距离呀等等。\n既然是要求最值，核心问题是什么呢？求解动态规划的核心问题是穷举。因为要求最值，肯定要把所有可行的答案穷举出来，然后在其中找最值呗。\n动态规划这么简单，就是穷举就完事了？我看到的动态规划问题都很难啊！\n首先，动态规划的穷举有点特别，因为这类问题存在「重叠子问题」，如果暴力穷举的话效率会极其低下，所以需要「备忘录」或者「DP table」来优化穷举过程，避免不必要的计算。\n而且，动态规划问题一定会具备「最优子结构」，才能通过子问题的最值得到原问题的最值。\n另外，虽然动态规划的核心思想就是穷举求最值，但是问题可以千变万化，穷举所有可行解其实并不是一件容易的事，只有列出正确的「状态转移方程」，才能正确地穷举。\n以上提到的重叠子问题、最优子结构、状态转移方程就是动态规划三要素。具体什么意思等会会举例详解，但是在实际的算法问题中，写出状态转移方程是最困难的，这也就是为什么很多朋友觉得动态规划问题困难的原因，我来提供我研究出来的一个思维框架，辅助你思考状态转移方程：\n明确 base case -\u003e 明确「状态」-\u003e 明确「选择」 -\u003e 定义 dp 数组/函数的含义。\n按上面的套路走，最后的结果就可以套这个框架：\n初始化 base case dp[0][0][…] = base\n进行状态转移 for 状态1 in 状态1的所有取值：\nfor 状态2 in 状态2的所有取值：\nfor …\ndp[状态1][状态2][…] = 求最值(选择1，选择2…)\n",
    "description": "",
    "tags": null,
    "title": "动态规划",
    "uri": "/%E7%AE%97%E6%B3%95%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/"
  },
  {
    "content": "保证测试用例顺序 @FixMethodOrder(MethodSorters.NAME_ASCENDING)\nMVC 1、使用ContextConfiguration 指定spring 配置文件 2、在spring配置文件内配置自己需要加载的bean\n@RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration(locations = {\"classpath:spring-test-config.xml\"}) public class DrugGuidelineRepositoryTest { } \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cbeans xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns=\"http://www.springframework.org/schema/beans\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd\"\u003e \u003cimport resource=\"classpath*:spring-datasource.xml\"/\u003e \u003cimport resource=\"classpath*:spring-bean.xml\"/\u003e \u003c/beans\u003e \u003c?xml version=\"1.0\" encoding=\"UTF-8\"?\u003e \u003cbeans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd\"\u003e \u003ccontext:component-scan base-package=\"com.benmu.mts.baseinfo.domain.drugguideline\"\u003e \u003c/context:component-scan\u003e \u003c/beans\u003e Spring boot @RunWith(SpringRunner.class) @ActiveProfiles(“justdb”)\n@SpringBootTest(classes = DrugTestApp.class, webEnvironment = SpringBootTest.WebEnvironment.NONE)\nSpringRunner is alias for the SpringJUnit4ClassRunner.\n",
    "description": "",
    "tags": null,
    "title": "单元测试",
    "uri": "/spring/%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95/"
  },
  {
    "content": " title: “链表反转” date: 2021-08-08T21:42:40+08:00 draft: false 链表反转 链表\n1-\u003e2-\u003e3-\u003e4\n翻转\n4-\u003e3-\u003e2-\u003e1\n主要难点是防止Next被替换，下一个节点无法访问\n方式1： 使用临时变量保存Last和Next\n/** * Definition for singly-linked list. * type ListNode struct { * Val int * Next *ListNode * } */ func reverseList(head *ListNode) *ListNode { var lastNode,nextNode *ListNode for(head!=nil){ nextNode=head.Next head.Next=lastNode lastNode=head head=nextNode } //注意这里是返回前一个节点，因为head最后指向了nextNode是空的 return lastNode } 方式2：递归 从最末尾开始递归交换 3-4-\u003e4-3，1，2，(4，3)-\u003e1,(4,3),2\n",
    "description": "",
    "tags": null,
    "title": "双向链表",
    "uri": "/%E7%AE%97%E6%B3%95%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E5%8F%8C%E5%90%91%E9%93%BE%E8%A1%A8/"
  },
  {
    "content": "\n",
    "description": "",
    "tags": null,
    "title": "双指针",
    "uri": "/%E7%AE%97%E6%B3%95%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E5%8F%8C%E6%8C%87%E9%92%88/"
  },
  {
    "content": "/etc/\n",
    "description": "",
    "tags": null,
    "title": "启动执行脚本",
    "uri": "/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/%E5%90%AF%E5%8A%A8%E6%89%A7%E8%A1%8C%E8%84%9A%E6%9C%AC/"
  },
  {
    "content": "\n",
    "description": "",
    "tags": null,
    "title": "回溯（DFS）",
    "uri": "/%E7%AE%97%E6%B3%95%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E5%9B%9E%E6%BA%AFdfs/"
  },
  {
    "content": "RAM（random-access machine）随机访问机\n假定了一种通用的单处理器处理模型，认为底层执行一条指令时间都是常量。\n指令不能太复杂（比如一条排序的指令），可以是场景的 算术指令、数据移动指令、控制指令。\n分治法：\n将原问题分解橙几个规模较小但类似的子问题，递归求解这些子问题，然后再合并这些子问题的解来建立原来的问题的解。\n三步走：分解-\u003e解决-\u003e合并\n分治可以降低时间复杂度，把大的问题化小可以使时间从，n^2 降低到nlogn，因为不在需要遍历全体数据求解。\n",
    "description": "",
    "tags": null,
    "title": "基本概念",
    "uri": "/%E7%AE%97%E6%B3%95%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5/"
  },
  {
    "content": "机械同感 (mechanical sympathy)来自于赛车比赛，它反映了车手对赛车有一种内在的感觉，所以他们能够赛车达到最佳状态。然而多数程序员缺少这种对编程与硬件交互的感同身受的情感。要么是没有，要么就是以为自己有，实际上却是基于很久以前硬件工作方式而建立的概念。这说得实在是太多，作为一个程序员，在写程序时是否考虑过自己的代码能否正确地运行在底层硬件上，又是否考虑过怎样榨干硬件性能让自己的代码跑得飞快，又是否考虑过自己的代码能否被人钻了空子发生安全问题。我想这三方面也许是学习硬件工作原理的最主要因素，即让自己的代码：正确、高效、安全地在硬件上跑。简单来说就是\n快准稳！\n5Why分析法 — 分析事故根本原因 角度一 “制造”，为什么会发生？\n问题 1：为什么数据库的线程数会增加？ 答：正在执行的SQL执行时间长。 问题 2：为什么正在执行的SQL执行时间长？ 答：因为正在执行的SQL发生了死锁。 问题 3：为什么SQL会发生死锁？ 答：同时删除相同的一批数据，而删除时出现乱序。 问题 4：为什么删除相同的一批数据？ 答：代码逻辑问题，不需要重复删除。 解决方案：更改代码逻辑，避免重复删除。\n角度二 “检验”，为什么没有发现？\n问题 1：为什么代码上线几个月都没有发现？ 答：未出现大量的死锁情况。 问题 2：为什么没有出现大量的死锁情况？ 答：未出现这种造成大量并发的数据，测试用例也未覆盖。 问题 3：在小量并发数据的情况也可能发生死锁，为什么没有发现该逻辑会产生死锁？ 答：未能及时从错误日志中发现问题。 问题 4：为什么未能及时从错误日志中发现问题？ 答：错误日志中有较多无用的日志，扰乱了日志分析。 解决方案：清理代码中无用的错误日志打印，及时检查错误日志，并解决问题。\n",
    "description": "",
    "tags": null,
    "title": "大概念",
    "uri": "/%E6%9D%82%E9%A1%B9/%E5%A4%A7%E6%A6%82%E5%BF%B5/"
  },
  {
    "content": "0day漏洞： 漏洞已被发现还没有发布解决补丁。\n桥接： 简单的说就是通过网桥可以把两个不同的物理局域网连接起来，是一种在链路层实现局域网互连的存储转发设备。网桥从一个局域网接收MAC帧，拆封、校对、校验之后 ，按另一个局域网的格式重新组装,发往它的物理层，通俗的说就是通过一台设备（可能不止一个）把几个网络串起来形成的连接，比如图中就是一种通过桥接来实现无路由双机上网的连接方案。 虚拟机中的网络模式 VMware 桥接模式 VMware桥接模式，也就是将虚拟机的虚拟网络适配器与主机的物理网络适配器进行交接，虚拟机中的虚拟网络适配器可通过主机中的物理网络适配器直接访问到外部网络(例如图中所示的局域网和Internet，下同)。简而言之，这就好像在上图所示的局域网中添加了一台新的、独立的计算机一样。因此，虚拟机也会占用局域网中的一个IP地址，并且可以和其他终端进行相互访问。桥接模式网络连接支持有线和无线主机网络适配器。如果你想把虚拟机当做一台完全独立的计算机看待，并且允许它和其他终端一样的进行网络通信，那么桥接模式通常是虚拟机访问网络的最简单途径。\nVMware NAT模式 NAT，是Network Address Translation的缩写，意即网络地址转换。NAT模式也是VMware创建虚拟机的默认网络连接模式。使用NAT模式网络连接时，VMware会在主机上建立单独的专用网络，用以在主机和虚拟机之间相互通信。虚拟机向外部网络发送的请求数据\"包裹\"，都会交由NAT网络适配器加上\"特殊标记\"并以主机的名义转发出去，外部网络返回的响应数据\"包裹\"，也是先由主机接收，然后交由NAT网络适配器根据\"特殊标记\"进行识别并转发给对应的虚拟机，因此，虚拟机在外部网络中不必具有自己的IP地址。从外部网络来看，虚拟机和主机在共享一个IP地址，默认情况下，外部网络终端也无法访问到虚拟机。\n",
    "description": "",
    "tags": null,
    "title": "奇怪的小知识",
    "uri": "/%E6%9D%82%E9%A1%B9/%E5%A5%87%E6%80%AA%E7%9A%84%E5%B0%8F%E7%9F%A5%E8%AF%86/"
  },
  {
    "content": "在线流程图 https://mermaid.live/\n正则可视化 https://tooltt.com/regulex/\npython官方学习文档 docs.python.org\n朗文词典 https://www.ldoceonline.com/\n",
    "description": "",
    "tags": null,
    "title": "好用的网站",
    "uri": "/%E6%9D%82%E9%A1%B9/%E5%A5%BD%E7%94%A8%E7%9A%84%E7%BD%91%E7%AB%99/"
  },
  {
    "content": "场景： 库里有10亿手机号，如何快速判断一个手机号是否在数据库中。 首先对这些数据进行缓存是肯定的，有没有什么更经济的方式缓存呢，这时候布隆举着盾牌就出现了。\n布隆过滤器 布隆过滤器（Bloom Filter）是由布隆在1970年提出的。它实际上是一个很长的二进制向量（位图）和一系列随机映射函数（哈希函数）。\n布隆过滤器可以用于检索一个元素是否在一个集合中。 优点：空间效率和查询时间都比一般的算法要好的多。\n缺点有2个：\n在判断元素在集合中有误差，只有判断元素不在集合中是准确的 删除比较困难 位图（Bitmap） Redis当中有一种数据结构就是位图，布隆过滤器其中重要的实现就是位图的实现，也就是位数组，并且在这个数组中每一个位置只有0和1两种状态，每个位置只占用1个 bit，其中0表示没有元素存在，1表示有元素存在。\n如下图所示就是一个简单的布隆过滤器示例（一个key值经过哈希运算和位运算就可以得出应该落在哪个位置）：\n哈希 上面我们发现，lonely和wolf落在了同一个位置，这种不同的key值经过哈希运算后得到相同值的现象就称之为哈希碰撞。发生哈希碰撞之后再经过位运算，那么最后肯定会落在同一个位置。\n如果发生过多的哈希碰撞，就会影响到判断的准确性，所以为了减少哈希碰撞，我们一般会综合考虑以下2个因素：\n增大位图数组的大小（位图数组越大，占用的内存越大）。 增加哈希函数的次数（同一个key值经过1个函数相等了，那么经过2个或者更多个哈希函数的计算，都得到相等结果的概率就自然会降低了）。 上面两个方法我们需要综合考虑：比如增大位数组，那么就需要消耗更多的空间，而经过越多的哈希计算也会消耗cpu影响到最终的计算时间，所以位数组到底多大，哈希函数次数又到底需要计算多少次合适需要具体情况具体分析。\n删除元素 布隆过滤器判断一个元素存在就是判断对应位置是否为1来确定的，但是如果要删除掉一个元素是不能直接把1改成0的，因为这个位置可能存在其它元素，所以如果要支持删除，那我们应该怎么做呢？\n最简单的做法就是加一个计数器，就是说位数组的每个位如果不存在就是0，存在几个元素就存具体的数字，而不仅仅只是存1。那么这就有一个问题，本来存1就是一位就可以满足了，但是如果要存具体的数字比如说2，那就需要2位了，所以带有计数器的布隆过滤器会占用更大的空间。\n",
    "description": "",
    "tags": null,
    "title": "布隆过滤器",
    "uri": "/%E4%B8%AD%E9%97%B4%E4%BB%B6/redis/%E5%B8%83%E9%9A%86%E8%BF%87%E6%BB%A4%E5%99%A8/"
  },
  {
    "content": "\n",
    "description": "",
    "tags": null,
    "title": "广度优先（BFS）",
    "uri": "/%E7%AE%97%E6%B3%95%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88bfs/"
  },
  {
    "content": "https://blog.51cto.com/u_3631118/3121421\n",
    "description": "",
    "tags": null,
    "title": "异步模式",
    "uri": "/spring/mvc/%E5%BC%82%E6%AD%A5%E6%A8%A1%E5%BC%8F/"
  },
  {
    "content": "\n",
    "description": "",
    "tags": null,
    "title": "微信授权登录",
    "uri": "/%E6%9D%82%E9%A1%B9/%E5%BE%AE%E4%BF%A1%E6%8E%88%E6%9D%83%E7%99%BB%E5%BD%95/"
  },
  {
    "content": "\n",
    "description": "",
    "tags": null,
    "title": "排序",
    "uri": "/%E7%AE%97%E6%B3%95%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%8E%92%E5%BA%8F/"
  },
  {
    "content": "https://www.yuque.com/books/share/227872c0-1f19-4c83-960e-5e13e39343c8/fi6mb2\n为了防止出现内存地址碰撞，操作系统引入了虚拟内存，进程持有的虚拟地址会通过 CPU 芯片中的内存管理单元（MMU）的映射关系，来转换变成物理地址，然后再通过物理地址访问内存。\n互斥与同步： 互斥：不能同时执行 同步：要求按照顺序执行\n系统调用： http://c.biancheng.net/view/1195.html\n",
    "description": "",
    "tags": null,
    "title": "操作系统",
    "uri": "/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"
  },
  {
    "content": "\n",
    "description": "",
    "tags": null,
    "title": "数据结构",
    "uri": "/%E7%AE%97%E6%B3%95%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"
  },
  {
    "content": "GMT时间： 格林威治时间，以本初子午线为0时区，每个时区调整时区显示。\nUTC时间： utc格式：UTC本地时间 = UTC标准时间 拼上 时间偏移量。 ex:若现在UTC时间是 10:30z（z表示偏移量=0，不可省略），则北京时间为 10:30 +0800、纽约时间为 10:30 -0500，分别表示同日下午6点半、同日上午五点半。\nISO8601标准时间格式： 基于utc时间，前端时间为时区时间方便使用，后段时间为时区偏移量，方便辨别。 ex:2021-03-01T18:03:24.208+08:00 java中的时间 可以用Instant代替 Date，LocalDateTime代替 Calendar，DateTimeFormatter 代替 SimpleDateFormat。\n",
    "description": "",
    "tags": null,
    "title": "时间",
    "uri": "/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/%E6%97%B6%E9%97%B4/"
  },
  {
    "content": "datetime 包 datetime类 根据String 生成datetime datetime.datetime.strptime('2017-3-22 15:25','%Y-%m-%d %H:%M') https://docs.python.org/3/library/datetime.html#examples-of-usage-datetime\n",
    "description": "",
    "tags": null,
    "title": "时间处理",
    "uri": "/python/%E6%97%B6%E9%97%B4%E5%A4%84%E7%90%86/"
  },
  {
    "content": "[[事务]]\n本地事务 Local Transaction 单一数据源，依赖数据库实现一致性。\n数据库实现方案 原子性\u0026持久性 众所周知，数据必须要成功写入磁盘、磁带等持久化存储器后才能拥有持久性，只存储在内存中的数据，一旦遇到应用程序忽然崩溃，或者数据库、操作系统一侧的崩溃，甚至是机器突然断电宕机等情况就会丢失，后文我们将这些意外情况都统称为“崩溃”（Crash）。实现原子性和持久性的最大困难是“写入磁盘”这个操作并不是原子的，不仅有“写入”与“未写入”状态，还客观地存在着“正在写”的中间状态。正因为写入中间状态与崩溃都不可能消除，所以如果不做额外保障措施的话，将内存中的数据写入磁盘，并不能保证原子性与持久性。下面通过具体事例来说明。\n未提交事务，写入后崩溃：程序还没修改完三个数据，但数据库已经将其中一个或两个数据的变动写入磁盘，此时出现崩溃，一旦重启之后，数据库必须要有办法得知崩溃前发生过一次不完整的购物操作，将已经修改过的数据从磁盘中恢复成没有改过的样子，以保证原子性。 已提交事务，写入前崩溃：程序已经修改完三个数据，但数据库还未将全部三个数据的变动都写入到磁盘，此时出现崩溃，一旦重启之后，数据库必须要有办法得知崩溃前发生过一次完整的购物操作，将还没来得及写入磁盘的那部分数据重新写入，以保证持久性。 为了能够顺利地完成崩溃恢复，在磁盘中写入数据就不能像程序修改内存中变量值那样，直接改变某表某行某列的某个值，而是必须将修改数据这个操作所需的全部信息，包括修改什么数据、数据物理上位于哪个内存页和磁盘块中、从什么值改成什么值，等等，以日志的形式——即仅进行顺序追加的文件写入的形式（这是最高效的写入方式）先记录到磁盘中。只有在日志记录全部都安全落盘，数据库在日志中看到代表事务成功提交的“提交记录”（Commit Record）后，才会根据日志上的信息对真正的数据进行修改，修改完成后，再在日志中加入一条“结束记录”（End Record）表示事务已完成持久化，这种事务实现方法被称为“Commit Logging”（提交日志）。\nCommit Logging 保障数据持久性、原子性的原理：首先，日志一旦成功写入 Commit Record，那整个事务就是成功的，即使真正修改数据时崩溃了，重启后根据已经写入磁盘的日志信息恢复现场、继续修改数据即可，这保证了持久性；其次，如果日志没有成功写入 Commit Record 就发生崩溃，那整个事务就是失败的，系统重启后会看到一部分没有 Commit Record 的日志，那将这部分日志标记为回滚状态即可，整个事务就像完全没好有发生过一样，这保证了原子性。\ncommit logging 在提交之前不允许写入磁盘会占用个过多内存缓冲区，性能不高。针对这个问题提出了Write-Ahead Logging方案。 Write-Ahead Logging： 所谓“提前写入”（Write-Ahead），就是允许在事务提交之前，提前写入变动数据的意思。 Write-Ahead Logging 先将何时写入变动数据，按照事务提交时点为界，划分为 FORCE 和 STEAL 两类情况。\nFORCE：当事务提交后，要求变动数据必须同时完成写入则称为 FORCE，如果不强制变动数据必须同时完成写入则称为 NO-FORCE。现实中绝大多数数据库采用的都是 NO-FORCE 策略，因为只要有了日志，变动数据随时可以持久化，从优化磁盘 I/O 性能考虑，没有必要强制数据写入立即进行。 STEAL：在事务提交前，允许变动数据提前写入则称为 STEAL，不允许则称为 NO-STEAL。从优化磁盘 I/O 性能考虑，允许数据提前写入，有利于利用空闲 I/O 资源，也有利于节省数据库缓存区的内存。 write-Ahead logging 恢复 分析阶段（Analysis）：该阶段从最后一次检查点（Checkpoint，可理解为在这个点之前所有应该持久化的变动都已安全落盘）开始扫描日志，找出所有没有 End Record 的事务，组成待恢复的事务集合，这个集合至少会包括 Transaction Table 和 Dirty Page Table 两个组成部分。 重做阶段（Redo）：该阶段依据分析阶段中产生的待恢复的事务集合来重演历史（Repeat History），具体操作为：找出所有包含 Commit Record 的日志，将这些日志修改的数据写入磁盘，写入完成后在日志中增加一条 End Record，然后移除出待恢复事务集合。 回滚阶段（Undo）：该阶段处理经过分析、重做阶段后剩余的恢复事务集合，此时剩下的都是需要回滚的事务，它们被称为 Loser，根据 Undo Log 中的信息，将已经提前写入磁盘的信息重新改写回去，以达到回滚这些 Loser 事务的目的。 - FORCE STEAL Commit Logging redo log x Write-Ahead Loggin redo log undo log 隔离性： 隔离性是保证，不同事务之间读和写之间不影响。这天生和并发有关，这时需要解决并发的重要手段：锁。 数据库为了隔离性一般会提供三种锁：\n写锁 -排它锁-exclusiveLock-XLock：如果数据加了写锁，只有持有写锁的事务才能对数据进行写操作，数据加锁时，其他事务不能写入也不能加读锁。 读锁-共享锁-ShareLock-SLock:多个事务可以对同一数据添加读锁，添加以后其他事务不能对其写入数据，但仍然可以对读取。对于持有读锁的事务，如果只有自己持有读锁那么允许升级为写锁，写入数据。 范围锁（RangeLock）：对于某个范围直接加排它锁，这个范围内的数据不能写入，和一组排它锁不一样，在这个范围不可新增和删除数据。 隔离级别 存在问题 描述 读取未提交 脏读+之后 会读到其他事务未提交的事务 读取已提交 不可重复读+之后 对同一行数据的两次查询得到了不同的结果。 可重复读 幻读\u0026write skew 两个完全相同的范围查询得到了不同的结果集。 串行化 对读和写入的数据全部加上读锁、写锁、范围锁，可实现串行化，性能比较差，相当于一条一条执行。 除了都以锁来实现外，以上四种隔离级别还有另一个共同特点，就是幻读、不可重复读、脏读等问题都是由于一个事务在读数据过程中，受另外一个写数据的事务影响而破坏了隔离性，针对这种“一个事务读+另一个事务写”的隔离问题，近年来有一种名为“多版本并发控制”（Multi-Version Concurrency Control，MVCC）的无锁优化方案被主流的商业数据库广泛采用。MVCC 是一种读取优化策略，它的“无锁”是特指读取时不需要加锁。MVCC 的基本思路是对数据库的任何修改都不会直接覆盖之前的数据，而是产生一个新版副本与老版本共存，以此达到读取时可以完全不加锁的目的。在这句话中，“版本”是个关键词，你不妨将版本理解为数据库中每一行记录都存在两个看不见的字段：CREATE_VERSION 和 DELETE_VERSION，这两个字段记录的值都是事务 ID，事务 ID 是一个全局严格递增的数值，然后根据以下规则写入数据\n插入数据时：CREATE_VERSION 记录插入数据的事务 ID，DELETE_VERSION 为空。 删除数据时：DELETE_VERSION 记录删除数据的事务 ID，CREATE_VERSION 为空。 修改数据时：将修改数据视为“删除旧数据，插入新数据”的组合，即先将原有数据复制一份，原有数据的 DELETE_VERSION 记录修改数据的事务 ID，CREATE_VERSION 为空。复制出来的新数据的 CREATE_VERSION 记录修改数据的事务 ID，DELETE_VERSION 为空。 此时，如有另外一个事务要读取这些发生了变化的数据，将根据隔离级别来决定到底应该读取哪个版本的数据。\n隔离级别是可重复读：总是读取 CREATE_VERSION 小于或等于当前事务 ID 的记录，在这个前提下，如果数据仍有多个版本，则取最新（事务 ID 最大）的。 隔离级别是读已提交：总是取最新的版本即可，即最近被 Commit 的那个版本的数据记录。 另外两个隔离级别都没有必要用到 MVCC，因为读未提交直接修改原始数据即可，其他事务查看数据的时候立刻可以看到，根本无须版本字段。可串行化本来的语义就是要阻塞其他事务的读取操作，而 MVCC 是做读取时无锁优化的，自然就不会放到一起用。\nMVCC 是只针对“读+写”场景的优化，如果是两个事务同时修改数据，即“写+写”的情况，那就没有多少优化的空间了，此时加锁几乎是唯一可行的解决方案，\nMySQL：\nPostgreSQL：\n关于 MySQL Repeatable Read Isolation 常见的三个误区 https://cloud.tencent.com/developer/article/1676633\n",
    "description": "",
    "tags": null,
    "title": "本地事务",
    "uri": "/%E6%95%B0%E6%8D%AE%E5%BA%93/%E6%9C%AC%E5%9C%B0%E4%BA%8B%E5%8A%A1/"
  },
  {
    "content": "删除用户 先用命令 cat /etc/passwd 查看一下所有的用户 可以看到你需要删除的用户名 用命令 who 查询当前登录的用户 用命令 ps -u 用户名 查看该用户的pid 用命令 kill pid 杀掉他的sshd或者是shell进程 再用命令 userdel -r 用户名 删除用户 ",
    "description": "",
    "tags": null,
    "title": "用户",
    "uri": "/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/%E7%94%A8%E6%88%B7/"
  },
  {
    "content": "个人信息 于文浩/男/1994\n本科/泰山学院自动化专业\n籍贯：山东\n住址：朝阳-酒仙桥\n工作年限：5年\n求职方向：java服务端开发\n手机：18612836421\nEmail: yuvenhol@email.cn\n技能清单 后端框架：Spring Boot +Spring Cloud\n开发环境：Linux、Windows、MacOS\n消息队列：Kafka\n数据库：MySQL/ES/MongoDB/Redis\n版本管理：Svn/Git\n其他语言：Python、GO\n个人优点 有着良好的团队精神，积极参与需求讨论，能从用户角度考虑问题，并给予技术实现方案。\n能够主动承担任务，有较强执行力，及时为运营解决问题，与产品探讨优化方案，保证又快又好上线。\n工作经历 完美世界控股集团有限公司 （ 2018年8月 ~ 至今 ） 全未来项目（2020.3~至今） 所用技术： SpringCloud、MySQL、ElasticSearch、Kafka、Redis\n项目介绍： 全未来项目是一个为用户提供安排未来生活的资讯平台，包括剧本杀、密室逃脱等活动的组团约玩，演唱会、脱口秀、漫展、特殊影厅等活动门票售卖，以及线上线下的抽奖活动。基于SpringCloud，分为客户端主服务、社区服务、商城主服务、商城后台、运营后台、以及第三方服务等几个微服务系统。主要业务数据存储于MySQL中，复杂查询、基于位置信息查询、大文本的数据从MySQL中抽取聚合再刷到ES中，使用Redis做缓存和分布式锁，Kafka做消息队列对复杂处理削峰。\n工作内容： 主要负责app、小程序和中台接口的开发，第三方接口对接，以及工作任务的安排。\napp\u0026小程序:首页、附近页、详情页、客户端内容生产、发帖与评论相关接口。\n内容生成平台：主体内容生产、机器审核、人工审核，权限校验，个人信息与社区内容的审核。\n内容管理平台：运营工具、数据分发标签，地区、场所、商圈、品牌等基础数据管理，后台用户权限管理。\n商城后台：商品管理、订单管理、商家管理、用户权限管理。\n收获： 在这个项目中，我提升了视野，学会了从团队的角度思考问题。通过对业务的深度参与得到了更深的理解，这有助于对更精准的抽象数据结构和写出贴合实际的业务代码，减少与产品反复沟通，提高整体团队效率。我因此受益匪浅，也赢得了产品和领导们的一致好评。\n全历史项目（2018.8~2020~3） 所用技术： SpringCloud、MySQL、MongoDB、ElasticSearch、Kafka、Redis\n项目介绍： 全历史是一个为历史爱好者学习交流分享的平台，包含关系图谱、疆域变迁、历史规律、各种专业史、以及艺术作品等。项目基于SpringCloud，大文本和爬虫数据存住在MongoDB中，业务数据主要存住在MySQL，有复杂查询需求会同步数据到ES中，频繁访问以及处理时间较长的数据使用Redis做缓存，使用Kafka做消息队列对复杂处理削峰。\n工作内容： 我主要负责app和中台接口的开发，以及数据的爬取和清洗。项目的数据由运营人员编写和网络抓取数据组成。在爬虫开发资源不够的时候，我负责了网络数据爬取解析存储。后来开发了科技史、战争史、美术史等专业史的内容生产平台、外包审核系统、app端接口，以及一些文字转语音、音视频拼接、地理位置信息查询等第三方服务的对接。项目起初是单体服务，随着业务的发展逐渐显得过于臃肿对开发调试部署都带来了不便，我接手以后率先进行了微服务改造，梳理可拆分业务，旧服务代码剥离，切换到新服务。\n收获： 上手掌握了SpringCloud相关技术栈，养成了较良好的开发习惯，与各端开发人员、产品运营形成了默契的配合。\n北京康健德科技有限公司 （ 2018年4月 ~ 2018年8月 ） 健康评估项目 所用技术： SpringCloud、MySQL、Redis\n项目介绍： 与各大体检机构合作，对用户历年体检数据进行比对得到结合专业医师对用户身体发展状况进行评估，根据评估结果推送相关产品。项目是基于SpringBoot单体应用，使用mysql作为数据库，redis做缓存。\n工作内容： 数据评估工具开发，计算身体状况得分，推荐对应商品。\n浩鸿达科技发展股份公司 （ 2016年7月 ~ 2018年3月 ） 电子会计档案系统： 项目介绍： 开发专业具有收集归档、档案管理、保管、检索利⽤、鉴定销毁、统计、系统管理等模块 在内的功能完善的会计档案系统。并针不同财务系统开发数据抽取接口，对数据进行ETL，整理到档案系统⽣成PDF⽂件，加盖数字签章。\n工作内容： 针对各财务系统对接接口开发，数据库设计，⽂档维护，数据进行ETL，生成PDF文件加盖数字签章。\n— 致谢 感谢您花时间阅读我的简历，期待能有机会和您共事。\n",
    "description": "",
    "tags": null,
    "title": "简历",
    "uri": "/%E9%9D%A2%E8%AF%95/%E7%AE%80%E5%8E%86/"
  },
  {
    "content": "PUSH模式 为每个订阅的用户推消息 缺点：大V推送的用户太多\nPULL模式 用户上线以后去拉去新消息 缺点：比较复杂，而且要多次查询再排序\n",
    "description": "",
    "tags": null,
    "title": "类微博feed流",
    "uri": "/%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/%E7%B1%BB%E5%BE%AE%E5%8D%9Afeed%E6%B5%81/"
  },
  {
    "content": "埃筛法 ",
    "description": "",
    "tags": null,
    "title": "素数计算",
    "uri": "/%E7%AE%97%E6%B3%95%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/%E7%B4%A0%E6%95%B0%E8%AE%A1%E7%AE%97/"
  },
  {
    "content": "基础信息 名字解释 mat = matrix (矩阵) 制图时常常需要使用到运算，同理matlab中的mat也是这个意思。 plot= 绘制\n官方网站： https://matplotlib.org/stable/index.html\n概念： import matplotlib as mpl import matplotlib.pyplot as plt import numpy as np figure 画板，包含多个axes和artists\nfig = plt.figure() # an empty figure with no Axes\nfig, ax = plt.subplots() # a figure with a single Axes fig, axs = plt.subplots(2, 2) # a figure with a 2x2 grid of Axes axes 轴集合, 可以是x轴y轴，3d的会有z轴。\naxis 轴\nartist everything visible on the Figure is an Artist\n相关问题 中文显示问题 1、先输出所有字体，找到中文字体\nimport matplotlib.font_manager a = sorted([f.name for f in matplotlib.font_manager.fontManager.ttflist]) for i in a: print(i) 2、设置对应字体\nplt.rcParams[\"font.sans-serif\"] = [\"Songti SC\"] # 设置字体 ",
    "description": "",
    "tags": null,
    "title": "绘图库 matplotlib",
    "uri": "/python/%E7%BB%98%E5%9B%BE%E5%BA%93-matplotlib/"
  },
  {
    "content": "缓存雪崩 原因：\n大量缓存数据同时失效，导致某一瞬间之后，相当于没有缓存。\n解决：\n缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。 设置热点数据永远不过期。 缓存击穿 原因：\n从击穿这个字眼上来看，是有瞬间大量的请求过来，访问同一资源。这时候会有大量请求直接访问db。\n解决：\n设置热点数据永远不过期。 加互斥锁。 缓存穿透 原因：\n大量请求绕过缓存访问db里面不存在的数据，例如访问id=-1的数据，这时候也会给db造成较大压力。\n解决：\n接口对参数进行基本的校验id\u003e0 短时间缓存null值数据 ",
    "description": "",
    "tags": null,
    "title": "缓存雪崩、缓存击穿、缓存穿透",
    "uri": "/%E4%B8%AD%E9%97%B4%E4%BB%B6/redis/%E7%BC%93%E5%AD%98%E9%9B%AA%E5%B4%A9%E7%BC%93%E5%AD%98%E5%87%BB%E7%A9%BF%E7%BC%93%E5%AD%98%E7%A9%BF%E9%80%8F/"
  },
  {
    "content": "\n",
    "description": "",
    "tags": null,
    "title": "自动配置",
    "uri": "/spring/springboot/%E8%87%AA%E5%8A%A8%E9%85%8D%E7%BD%AE/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "限流",
    "uri": "/%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/%E9%99%90%E6%B5%81/"
  },
  {
    "content": "Redis 缓存雪崩、缓存击穿、缓存穿透的概念和解决方案 缓存雪崩： 描述： 大量缓存集中失效，查询数据量很大，引起数据库压力过大。 解决方案：\n缓存数据的过期时间设置随机，防止同一时间大量数据过期现象发生。 设置热点数据永远不过期。 缓存击穿： 描述: 缓存击穿是指缓存中没有但数据库中有的数据（一般是缓存时间到期），这时由于并发用户特别多，同时读缓存没读到数据，又同时去数据库去取数据，引起数据库压力瞬间增大，造成过大压力 解决方案：\n设置热点数据永远不过期。 加互斥锁，解锁后重入。 缓存穿透： 描述 大量访问数据库中不存在缓存中也不存在的数据，导致数据库压力过大，也是攻击的一种手段。 解决方案：\n接口层增加校验，如用户鉴权校验，id做基础校验，id\u003c=0的直接拦截； 从缓存取不到的数据，在数据库中也没有取到，这时也可以将key-value对写为key-null，缓存有效时间可以设置短点，如30秒（设置太长会导致正常情况也没法使用）。这样可以防止攻击用户反复用同一个id暴力攻击 如何实现接口幂等 token方式 先下发token，完成之后再清除token\n乐观锁 基于乐观锁来控制版本\n分布式事务 1、2pc\n死锁 如果在一个系统中以下四个条件同时成立，那么就能引起死锁：\n互斥：至少有一个资源必须处于非共享模式，即一次只有一个进程可使用。如果另一进程申请该资源，那么申请进程应等到该资源释放为止。 占有并等待：—个进程应占有至少一个资源，并等待另一个资源，而该资源为其他进程所占有。 非抢占：资源不能被抢占，即资源只能被进程在完成任务后自愿释放。 循环等待：有一组等待进程 {P0，P1，…，Pn}，P0 等待的资源为 P1 占有，P1 等待的资源为 P2 占有，……，Pn-1 等待的资源为 Pn 占有，Pn 等待的资源为 P0 占有。 解决死锁： 1、打破四个必要条件之一即可，比如检测是否会产生循环，长时间获取不到资源就失败等等 2、在产生死锁后，检测然后回复。\n大多数程序都不会考虑死锁问题\n",
    "description": "",
    "tags": null,
    "title": "面试题整理",
    "uri": "/%E9%9D%A2%E8%AF%95/%E9%9D%A2%E8%AF%95%E9%A2%98%E6%95%B4%E7%90%86/"
  },
  {
    "content": "MySQL PREPARE 语句简介 在MySQL 4.1版之前，查询以文本格式发送到MySQL服务器。反过来，MySQL使用文本协议将数据返回给客户端。MySQL必须 完全 解析查询并将结果集转换为字符串，然后再将其返回给客户端。\n文本协议具有严重的性能影响。为了解决这个问题，MySQL从4.1版开始添加了一个名为prepared的新功能。\n准备好的语句利用客户端/服务器二进制协议。它将包含占位符（？）的查询传递给MySQL服务器，如下例所示：\nSELECT * FROM products WHERE productCode = ?;\n当MySQL使用不同的productcode值执行此查询时，它不必完全解析查询。因此，这有助于MySQL更快地执行查询，尤其是当MySQL多次执行查询时。因为预准备语句使用占位符（？），这有助于避免SQL注入的许多变体，从而使您的应用程序更安全。\nMySQL PREPARE 语句用法 为了使用MySQL预处理语句，您需要使用其他三个MySQL语句，如下所示：\nPREPARE - 准备要执行的语句。 EXECUTE - 执行由PREPARE语句准备的预准备语句。 DEALLOCATE PREPARE - 发布准备好的声明。 下图说明了如何使用预准备语句：\nMySQL编写了语句实例 让我们看一下使用MySQL预处理语句的示例。\nPREPARE stmt1 FROM ‘SELECT productCode, productName FROM products WHERE productCode = ?’;\nSET @pc = ‘S10_1678’; EXECUTE stmt1 USING @pc;\nDEALLOCATE PREPARE stmt1;\n首先，我们使用PREPARE语句准备执行语句。我们使用 SELECT语句根据指定的产品代码查询products表中的产品数据 。我们使用问号（？）作为产品代码的占位符。\n接下来，我们声明了一个产品代码变量 @pc并将其值设置为S10_1678。\n然后，我们使用EXECUTE语句用产品代码变量执行预准备语句@pc。\n最后，我们用它 DEALLOCATE PREPARE来发布准备好的声明。\n",
    "description": "",
    "tags": null,
    "title": "预处理",
    "uri": "/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql/%E9%A2%84%E5%A4%84%E7%90%86/"
  },
  {
    "content": "费曼学习法 计划制定 决策时需要消耗很多意志力，最后通常只会选择最舒适的事。避免避免决策疲劳。\n前一天晚上想好第二天要干啥 不重要事情 养成习惯在碎片化的时间完成不重要的事情，买东西、背单词、等在公交车上、午饭时等时间完成。\n核心任务化繁为简 普通人集中精力完成任务大概6小时：\n3+2原则：3个大任务 1-2小时。2个小任务半小时 135原则：1个大任务、3个中任务、5个小任务。 自己设定，根据自己实际情况来，如果任务太多就适当减少。 分解任务更具有执行性 任务如果很大，那么这个任务通常很难启动，那就拆分任务，那么任务将更具有执行性。\n",
    "description": "",
    "tags": null,
    "title": "高效人生",
    "uri": "/%E8%83%A1%E8%AF%8C%E5%85%AB%E6%89%AF%E5%A4%A7%E9%81%93%E7%90%86/%E9%AB%98%E6%95%88%E4%BA%BA%E7%94%9F/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "高效开发",
    "uri": "/%E6%9D%82%E9%A1%B9/%E9%AB%98%E6%95%88%E5%BC%80%E5%8F%91/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "Categories",
    "uri": "/categories/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "content",
    "uri": "/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "docker\u0026k8s",
    "uri": "/dockerk8s/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "golang",
    "uri": "/golang/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "java",
    "uri": "/java/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "jvm",
    "uri": "/java/jvm/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "linux",
    "uri": "/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/linux/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "mvc",
    "uri": "/spring/mvc/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "mysql",
    "uri": "/%E6%95%B0%E6%8D%AE%E5%BA%93/mysql/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "office",
    "uri": "/office/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "python",
    "uri": "/python/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "redis",
    "uri": "/%E4%B8%AD%E9%97%B4%E4%BB%B6/redis/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "spring",
    "uri": "/spring/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "springboot",
    "uri": "/spring/springboot/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "Tags",
    "uri": "/tags/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "中间件",
    "uri": "/%E4%B8%AD%E9%97%B4%E4%BB%B6/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "分布式",
    "uri": "/%E5%88%86%E5%B8%83%E5%BC%8F/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "工具",
    "uri": "/%E5%B7%A5%E5%85%B7/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "操作系统",
    "uri": "/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "数据库",
    "uri": "/%E6%95%B0%E6%8D%AE%E5%BA%93/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "杂项",
    "uri": "/%E6%9D%82%E9%A1%B9/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "权限控制",
    "uri": "/%E6%9D%83%E9%99%90%E6%8E%A7%E5%88%B6/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "算法\u0026数据结构",
    "uri": "/%E7%AE%97%E6%B3%95%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "类库\u0026框架",
    "uri": "/%E7%B1%BB%E5%BA%93%E6%A1%86%E6%9E%B6/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "胡诌八扯大道理",
    "uri": "/%E8%83%A1%E8%AF%8C%E5%85%AB%E6%89%AF%E5%A4%A7%E9%81%93%E7%90%86/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "解决方案",
    "uri": "/%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "计算机基础",
    "uri": "/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9F%BA%E7%A1%80/"
  },
  {
    "content": "",
    "description": "",
    "tags": null,
    "title": "面试",
    "uri": "/%E9%9D%A2%E8%AF%95/"
  }
]
